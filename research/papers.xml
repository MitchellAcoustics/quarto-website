<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Andrew Mitchell</title>
<link>https://drandrewmitchell.com/research/papers.html</link>
<atom:link href="https://drandrewmitchell.com/research/papers.xml" rel="self" type="application/rss+xml"/>
<description>Personal website of Andrew Mitchell</description>
<generator>quarto-1.5.57</generator>
<lastBuildDate>Thu, 07 Nov 2024 12:59:28 GMT</lastBuildDate>
<item>
  <title>Supplementary Material for: Soundscape Perception Indices (SPI)</title>
  <dc:creator>Andrew Mitchell</dc:creator>
  <dc:creator>Francesco Aletta</dc:creator>
  <link>https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/TargetOptimization.html</link>
  <description><![CDATA[ 





<p>The method is based on the optimization of a set of objective functions that are designed to capture the most important aspects of soundscape perception. The optimization is performed using a genetic algorithm, which is a stochastic optimization method that is well-suited to the multi-objective optimization problem of deriving SPI targets.</p>
<section id="role-of-a-priori-rankings-in-target-definition" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Role of <em>a priori</em> rankings in target definition</h1>
<p>The core challenge in developing a reference SPI target is determining what constitutes an “ideal” soundscape perception distribution for a given context. While we can directly specify MSN parameters to create bespoke targets based on theoretical expectations or design goals, developing empirically-grounded reference targets requires a more systematic approach.</p>
<p>The a priori ranking serves as a bridge between existing knowledge about soundscape quality and the mathematical framework of the SPI. By starting with a ranking of soundscapes whose relative quality has been assessed through some external measure (in this demonstration, mean SSS01 scores, though other metrics could be used), we can use optimization techniques to derive MSN parameters that:</p>
<ol type="1">
<li>When used as an SPI target, produce scores that result in the same ranking order</li>
<li>Generate high SPI scores for the highly-ranked soundscapes</li>
<li>Define a distribution in the circumplex space that captures the perceptual characteristics common to high-quality soundscapes in this context</li>
</ol>
<p>This approach allows us to work backwards from known good (and poor) examples to define what the target distribution should look like. For instance, if we know that location A has a better soundscape than location B for our purposes, the optimal target distribution should result in location A receiving a higher SPI score than location B.</p>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import libraries</span></span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> soundscapy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sspy</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> soundscapy.surveys.survey_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LANGUAGE_ANGLES, PAQ_IDS</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> scripts.optimize_target <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> ot</span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scripts.MultiSkewNorm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MultiSkewNorm</span>
<span id="cb1-13"></span>
<span id="cb1-14">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span>)</span></code></pre></div>
</div>
<section id="example-using-park-soundscapes-from-the-isd" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="example-using-park-soundscapes-from-the-isd"><span class="header-section-number">1.1</span> Example using park soundscapes from the ISD</h2>
<p>To demonstrate the method of deriving an SPI target from empirical data, we used a subset of locations from the International Soundscape Database (ISD) (Mitchell et al., 2024) that were classified as parks or park-like spaces.</p>
<div id="cell-4" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load latest ISD dataset</span></span>
<span id="cb2-2"></span>
<span id="cb2-3">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.isd.load()</span>
<span id="cb2-4">data, excl_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.isd.validate(data)</span>
<span id="cb2-5">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Language != 'cmn'"</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Exclude RegentsParkJapan outliers (the below code resulted in the `excl_id` list)</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># excl_id = list(data.query(</span></span>
<span id="cb2-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># "LocationID == 'RegentsParkJapan'"</span></span>
<span id="cb2-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ).query("ISOEventful &gt; 0.72 | ISOEventful &lt; -0.5").index)</span></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Excluded RegentsParkFields outliers</span></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># excl_id = excl_id + list(data.query(</span></span>
<span id="cb2-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># "LocationID == 'RegentsParkFields' and ISOPleasant &lt; 0").index) # Helicopters</span></span>
<span id="cb2-14">excl_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">652</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">706</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">548</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">550</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">551</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">553</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">569</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">580</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">609</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">618</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">623</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">636</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">643</span>]</span>
<span id="cb2-15">data.drop(excl_id, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-16"></span>
<span id="cb2-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate ISOPleasant and ISOEventful</span></span>
<span id="cb2-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Here we use the adjusted angles from Aletta et al. (2024) for each language included.</span></span>
<span id="cb2-19"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data.iterrows():</span>
<span id="cb2-20">    lang <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Language"</span>]</span>
<span id="cb2-21">    angles <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LANGUAGE_ANGLES[lang]</span>
<span id="cb2-22">    iso_pl, iso_ev <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb2-23">        sspy.surveys.processing._adj_iso_pl(row[PAQ_IDS], angles, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>),</span>
<span id="cb2-24">        sspy.surveys.processing._adj_iso_ev(row[PAQ_IDS], angles, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>),</span>
<span id="cb2-25">    )</span>
<span id="cb2-26">    data.loc[i, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iso_pl</span>
<span id="cb2-27">    data.loc[i, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iso_ev</span></code></pre></div>
</div>
<p>The following locations were identified as parks and included:</p>
<div id="cell-6" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Separate out parks</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">parks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb3-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RegentsParkFields"</span>,</span>
<span id="cb3-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RegentsParkJapan"</span>,</span>
<span id="cb3-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Noorderplantsoen"</span>,</span>
<span id="cb3-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"StPaulsCross"</span>,</span>
<span id="cb3-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MiradorSanNicolas"</span>,</span>
<span id="cb3-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RussellSq"</span>,</span>
<span id="cb3-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Noorderplantsoen"</span>,</span>
<span id="cb3-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MonumentoGaribaldi"</span>,</span>
<span id="cb3-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CampoPrincipe"</span>,</span>
<span id="cb3-13">]</span>
<span id="cb3-14"></span>
<span id="cb3-15">park_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID in @parks"</span>)</span></code></pre></div>
</div>
<p>An initial ranking of these locations was created based on their mean SSS01 scores (overall soundscape quality rating) from the survey responses in the ISD:</p>
<div id="cell-8" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Creating a somewhat arbitrary ranking of parks</span></span>
<span id="cb4-2">rank_on <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sss01"</span></span>
<span id="cb4-3">park_quality <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb4-4">    park_data.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>)[rank_on].mean().sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb4-5">)</span>
<span id="cb4-6">park_quality[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Rank"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(park_quality) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-7">park_quality.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sss01</th>
<th data-quarto-table-cell-role="th">Rank</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">LocationID</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">RegentsParkJapan</td>
<td>4.617978</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RegentsParkFields</td>
<td>4.467290</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CampoPrincipe</td>
<td>4.345455</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MonumentoGaribaldi</td>
<td>4.156250</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">RussellSq</td>
<td>4.020548</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MiradorSanNicolas</td>
<td>3.964286</td>
<td>6</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">StPaulsCross</td>
<td>3.803030</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Noorderplantsoen</td>
<td>2.412371</td>
<td>8</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>It’s important to note that, as stated in the main paper, this ranking is used primarily to demonstrate the methodology of deriving a target from a pre-existing ranking. While based on real survey data, this particular ranking should not be considered a definitive assessment of these spaces’ soundscape quality, due to the mono-dimensional nature of the SSS01 question. To develop a true reference target, the ranking would need to be arrived at through more rigorous empirical methods such as paired-choice comparisons or other experimental protocols. The purpose of using this ranking is twofold:</p>
<ol type="1">
<li>To demonstrate that the SPI framework can incorporate existing knowledge or preferences about soundscape quality into the target definition process</li>
<li>To show how multi-objective optimization can be used to derive MSN parameters that produce an SPI scoring system aligned with predetermined quality assessments</li>
</ol>
</section>
</section>
<section id="optimisation-task-formulation" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Optimisation Task Formulation</h1>
<section id="sec-targets" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-targets"><span class="header-section-number">2.1</span> SPI Targets</h2>
<p>To set up the optimisation task, we first need to express the parameter space and any constraints. The SPI target is a set of parameters that define the distribution of soundscape perception in a given soundscape. The target is defined as a multivariate skew-normal (MSN) distribution with the following parameters:</p>
<p><span id="eq-target"><img src="https://latex.codecogs.com/png.latex?%0AY%20%5Csim%20MSN(%5Cxi,%20%5COmega,%20%5Calpha)%0A%5Ctag%7B1%7D"></span></p>
<p>where:</p>
<p><span id="eq-target-xi"><img src="https://latex.codecogs.com/png.latex?%0A%5Cxi%20=%20(%5Cxi_x,%20%5Cxi_y),%20-1%20%5Cleq%20%5Cxi%20%5Cleq%201%0A%5Ctag%7B2%7D"></span></p>
<p>is the location parameter, which defines the mean of the distribution in the x and y dimensions. The location parameter is constrained to lie within the range <img src="https://latex.codecogs.com/png.latex?-1%20%5Cleq%20%5Cxi%20%5Cleq%201"> to ensure that the target distribution is within the range of possible soundscape perceptions (i.e.&nbsp;within the circumplex).</p>
<p><span id="eq-target-omega"><img src="https://latex.codecogs.com/png.latex?%0A%5COmega%20=%20%5Cbegin%7Bpmatrix%7D%20var(x)%20&amp;%20cov(x,%20y)%20%5C%5C%20cov(y,%20x)%20&amp;%20var(y)%20%5Cend%7Bpmatrix%7D%0A%5Ctag%7B3%7D"></span></p>
<p>and</p>
<p><span id="eq-target-omega-constraints"><img src="https://latex.codecogs.com/png.latex?%0A0%20%5Cleq%20var()%20%5Cleq%201;%20-1%20%5Cleq%20cov()%20%5Cleq%201%0A%5Ctag%7B4%7D"></span></p>
<p>is the covariance matrix, which defines the shape of the distribution. The covariance matrix must be symmetric <img src="https://latex.codecogs.com/png.latex?(cov(x,y)%20=%20cov(y,x))"> and positive definite to ensure that the distribution is well-defined. These requirements arise from the mathematical properties needed for a valid probability distribution. The variance and covariance parameters are constrained within realistic ranges based on observed soundscape distributions in the ISD.</p>
<p><span id="eq-target-alpha"><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha%20=%20(%5Calpha_x,%20%5Calpha_y),%20-5%20%5Cleq%20%5Calpha%20%5Cleq%205%0A%5Ctag%7B5%7D"></span></p>
<p>is the skewness parameter, which defines the skewness of the distribution in the x and y dimensions. The skewness parameter range is chosen to allow for meaningful asymmetry while preventing extreme or unrealistic distributions.</p>
</section>
<section id="objective-functions" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="objective-functions"><span class="header-section-number">2.2</span> Objective Functions</h2>
<p>Our optimization problem requires carefully chosen objective functions that can effectively translate an ordinal ranking of soundscape quality into meaningful MSN parameters. Two competing objectives are defined to ensure the resulting target distribution is both valid and useful:</p>
<ol type="1">
<li><p>Rank Correlation Objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_1%20=%20r(ranks_%7Bquality%7D,%20ranks_%7Btarget%7D)%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?r"> is the Spearman rank correlation coefficient. This objective ensures the derived target preserves the original quality ordering of the soundscapes. A high rank correlation indicates that when the target is used to calculate SPI scores for each location, those scores produce a similar ranking to our <em>a priori</em> assessment.</p></li>
<li><p>Weighted SPI Objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_2%20=%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Cfrac%7B1%7D%7Brank_i%7D%20%5Ccdot%20SPI_i%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?m"> is the number of locations and <img src="https://latex.codecogs.com/png.latex?rank_i"> is the <em>a priori</em> rank of location <img src="https://latex.codecogs.com/png.latex?i">. This objective addresses several important aspects:</p>
<ul>
<li>It ensures the target produces meaningfully scaled scores, not just correct rankings</li>
<li>The weighting (<img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7Brank_i%7D">) prioritizes high SPI scores for locations ranked as high quality</li>
<li>It prevents solutions that achieve the correct ranking but with compressed or arbitrary score ranges</li>
<li>It helps anchor the target distribution in regions of the circumplex space associated with positive soundscape experiences for this context.</li>
</ul></li>
</ol>
<p>The two objectives work together to resolve key challenges in target derivation:</p>
<ul>
<li>Rank correlation alone could produce valid but impractical targets (e.g., targets that correctly rank soundscapes but give very low scores to all locations)</li>
<li>Weighted scores alone might maximize scores without preserving the relative quality relationships</li>
<li>Together, they ensure the target both discriminates between soundscape quality levels and produces scores that reflect absolute quality judgments</li>
</ul>
<p>In <code>pymoo</code>, each objective function is supposed to be minimized. Therefore, in the code implementation these objectives are negated to convert them into minimization problems. For each step in the algorithm with a given trial set of parameters, a target distribution will be produced, the SPI for each test location assessed according to the protocol described in the full paper, and the resulting set of SPI scores and ranking will be scored using the objective functions.</p>
</section>
<section id="nsga-ii-problem-definition-in-pymoo" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="nsga-ii-problem-definition-in-pymoo"><span class="header-section-number">2.3</span> NSGA-II Problem Definition in <code>pymoo</code> <sup>1</sup></h2>
<div id="cell-13" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pathos</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.core.callback <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Callback</span>
<span id="cb5-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.core.problem <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ElementwiseProblem, StarmapParallelization</span>
<span id="cb5-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.visualization.scatter <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Scatter</span>
<span id="cb5-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pyrecorder.recorder <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Recorder</span>
<span id="cb5-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pyrecorder.writers.streamer <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Streamer</span>
<span id="cb5-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pyrecorder.writers.video <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Video</span>
<span id="cb5-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.decomposition.asf <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ASF</span>
<span id="cb5-9"></span>
<span id="cb5-10"></span>
<span id="cb5-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> MyProblem(ElementwiseProblem):</span>
<span id="cb5-12">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, data, ranking, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb5-13">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(</span>
<span id="cb5-14">            n_var<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,</span>
<span id="cb5-15">            n_obj<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb5-16">            n_constr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb5-17">            xl<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>]),</span>
<span id="cb5-18">            xu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>]),</span>
<span id="cb5-19">            n_eq_constr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb5-20">            elementwise_evaluation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb5-21">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs,</span>
<span id="cb5-22">        )</span>
<span id="cb5-23"></span>
<span id="cb5-24">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data</span>
<span id="cb5-25">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.ranking <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ranking</span>
<span id="cb5-26"></span>
<span id="cb5-27">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _evaluate(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, out, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb5-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the matrix is positive definite</span></span>
<span id="cb5-29">        h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(</span>
<span id="cb5-30">            np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>(np.linalg.eigvals(np.array([[X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]], [X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>], X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]]])) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb5-31">        )</span>
<span id="cb5-32">        out[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"H"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> h</span>
<span id="cb5-33">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb5-34">            out[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.column_stack([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb5-35">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span></span>
<span id="cb5-36">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb5-37">            tgt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb5-38">            tgt.define_dp(</span>
<span id="cb5-39">                np.array([X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]]),</span>
<span id="cb5-40">                np.array([[X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]], [X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>], X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]]]),</span>
<span id="cb5-41">                np.array([X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>], X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>]]),</span>
<span id="cb5-42">            )</span>
<span id="cb5-43">            tgt.sample()</span>
<span id="cb5-44">            r, wspi, spi_ranks, target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ot.target_success(tgt, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.ranking, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.data)</span>
<span id="cb5-45"></span>
<span id="cb5-46">            f1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>r[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb5-47">            f2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>wspi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb5-48"></span>
<span id="cb5-49">            out[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.column_stack([f1, f2])</span>
<span id="cb5-50"></span>
<span id="cb5-51"></span>
<span id="cb5-52"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> VideoCallback(Callback):</span>
<span id="cb5-53">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb5-54">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb5-55">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Recorder(Streamer(sleep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>))</span>
<span id="cb5-56"></span>
<span id="cb5-57">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> notify(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, algorithm):</span>
<span id="cb5-58">        sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Scatter(</span>
<span id="cb5-59">            title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gen </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%s</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> algorithm.n_gen,</span>
<span id="cb5-60">            labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"spearman"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"WSPI"</span>],</span>
<span id="cb5-61">        )</span>
<span id="cb5-62">        sc.add(algorithm.pop.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>))</span>
<span id="cb5-63">        sc.do()</span>
<span id="cb5-64">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.rec.record()</span></code></pre></div>
</div>
<p>The optimization problem described above presents significant computational challenges. A naive approach might involve systematically sampling the parameter space through a grid search, evaluating both objective functions at each point. However, with seven parameters to optimize and the need for fine granularity to capture optimal solutions, the search space becomes prohibitively large. Additionally, the requirement that the covariance matrix must be positive definite creates irregular boundaries in the parameter space that make systematic searching impractical.</p>
<p>We therefore employ the Non-dominated Sorting Genetic Algorithm II (NSGA-II), which uses principles from evolutionary computation to search the parameter space efficiently. The algorithm maintains a population of potential solutions, where each solution represents a complete set of MSN parameters (ξ, Ω, α). In our implementation, we use a population of 150 solutions, initialized randomly within the parameter constraints defined in Section&nbsp;2.1.</p>
<div id="cell-15" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.algorithms.moo.nsga2 <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> NSGA2</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.operators.crossover.sbx <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SBX</span>
<span id="cb6-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.operators.mutation.pm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PM</span>
<span id="cb6-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.operators.sampling.rnd <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> FloatRandomSampling</span>
<span id="cb6-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.optimize <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> minimize</span>
<span id="cb6-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.termination.default <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DefaultMultiObjectiveTermination</span>
<span id="cb6-7"></span>
<span id="cb6-8">algorithm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NSGA2(</span>
<span id="cb6-9">    pop_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>,</span>
<span id="cb6-10">    sampling<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>FloatRandomSampling(),</span>
<span id="cb6-11">    crossover<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>SBX(),</span>
<span id="cb6-12">    mutation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>PM(),</span>
<span id="cb6-13">    eliminate_duplicates<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># callback=VideoCallback()</span></span>
<span id="cb6-15">)</span>
<span id="cb6-16"></span>
<span id="cb6-17">termination <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DefaultMultiObjectiveTermination(n_max_gen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span></code></pre></div>
</div>
<p>The algorithm proceeds iteratively, with each iteration (or generation) involving four main steps:</p>
<p>First, the algorithm evaluates both objective functions (rank correlation and weighted scores) for each solution in the current population. Since we have multiple objectives, there is rarely a single “best” solution. Instead, solutions are ranked based on dominance - solution A dominates solution B if it performs at least as well on both objectives and better on at least one. Solutions that are not dominated by any other solutions form the first front, those only dominated by solutions in the first front form the second front, and so on.</p>
<p>Second, to maintain diversity in the population, the algorithm calculates a “crowding distance” for each solution. This distance measures how close a solution is to its neighbors in terms of objective function values. Solutions that are more isolated (have larger crowding distances) are preferred to prevent the population from clustering too tightly around local optima.</p>
<p>Third, new solutions are generated through crossover and mutation operations. Crossover combines parameters from two parent solutions to create offspring solutions, while mutation introduces small random changes to parameter values. These operations are controlled to ensure new solutions remain within the valid parameter ranges and covariance matrix constraints.</p>
<p>Finally, the algorithm selects solutions to form the next generation’s population. Solutions are chosen primarily based on their front ranking (lower/better fronts are preferred), and within the same front, solutions with larger crowding distances are preferred. This selection process ensures both convergence toward better solutions and maintenance of diversity in the population.</p>
<p>The algorithm runs for 100 generations, producing a set of solutions known as the Pareto front - solutions representing different trade-offs between our two objectives. From this front, we select a final solution using an Augmented Scalarizing Function with weights [0.48, 0.52], indicating a slight preference for the weighted score objective while maintaining strong rank correlation.</p>
</section>
<section id="park-quality-optimization" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="park-quality-optimization"><span class="header-section-number">2.4</span> Park Quality optimization</h2>
<div id="cell-18" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># initialize the thread pool and create the runner</span></span>
<span id="cb7-2">mp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pathos.helpers.mp</span>
<span id="cb7-3">n_process <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span></span>
<span id="cb7-4">pool <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mp.Pool(n_process)</span>
<span id="cb7-5">runner <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StarmapParallelization(pool.starmap)</span>
<span id="cb7-6"></span>
<span id="cb7-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the NSGA problem</span></span>
<span id="cb7-8">park_problem <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MyProblem(</span>
<span id="cb7-9">    data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>park_data, ranking<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>park_quality.sort_index()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Rank"</span>], elementwise_runner<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>runner</span>
<span id="cb7-10">)</span>
<span id="cb7-11"></span>
<span id="cb7-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run the optimization</span></span>
<span id="cb7-13">park_res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> minimize(</span>
<span id="cb7-14">    park_problem, algorithm, termination, seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>, save_history<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb7-15">)</span>
<span id="cb7-16"></span>
<span id="cb7-17">pool.close()</span>
<span id="cb7-18"></span>
<span id="cb7-19">park_F <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> park_res.F</span>
<span id="cb7-20">park_X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> park_res.X</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
n_gen  |  n_eval  | n_nds  |     cv_min    |     cv_avg    |      eps      |   indicator  
==========================================================================================
     1 |      150 |      2 |  0.000000E+00 |  0.7599240000 |             - |             -
     2 |      300 |      3 |  0.000000E+00 |  0.3266340000 |  0.2105263158 |         ideal
     3 |      450 |      4 |  0.000000E+00 |  0.000000E+00 |  0.0952380952 |         ideal
     4 |      600 |      8 |  0.000000E+00 |  0.000000E+00 |  0.0800000000 |         ideal
     5 |      750 |      9 |  0.000000E+00 |  0.000000E+00 |  0.1636581122 |         ideal
     6 |      900 |      6 |  0.000000E+00 |  0.000000E+00 |  0.2610291163 |         ideal
     7 |     1050 |      7 |  0.000000E+00 |  0.000000E+00 |  0.0100949471 |         ideal
     8 |     1200 |      8 |  0.000000E+00 |  0.000000E+00 |  0.2791679754 |         nadir
     9 |     1350 |      9 |  0.000000E+00 |  0.000000E+00 |  0.0677871357 |         nadir
    10 |     1500 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0448274156 |             f
    11 |     1650 |      9 |  0.000000E+00 |  0.000000E+00 |  0.2175688552 |         nadir
    12 |     1800 |      9 |  0.000000E+00 |  0.000000E+00 |  0.0108078898 |         ideal
    13 |     1950 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0090588603 |         ideal
    14 |     2100 |     13 |  0.000000E+00 |  0.000000E+00 |  0.0195416881 |             f
    15 |     2250 |      9 |  0.000000E+00 |  0.000000E+00 |  0.0092897651 |         ideal
    16 |     2400 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0907216495 |         nadir
    17 |     2550 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0131681841 |             f
    18 |     2700 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0139413302 |         ideal
    19 |     2850 |      9 |  0.000000E+00 |  0.000000E+00 |  0.0141060839 |             f
    20 |     3000 |      7 |  0.000000E+00 |  0.000000E+00 |  0.2007393457 |         nadir
    21 |     3150 |      9 |  0.000000E+00 |  0.000000E+00 |  0.0306288032 |         ideal
    22 |     3300 |      9 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    23 |     3450 |      9 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    24 |     3600 |      8 |  0.000000E+00 |  0.000000E+00 |  0.0191657272 |         ideal
    25 |     3750 |      8 |  0.000000E+00 |  0.000000E+00 |  0.0002901386 |             f
    26 |     3900 |      9 |  0.000000E+00 |  0.000000E+00 |  0.0073727865 |         ideal
    27 |     4050 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0180452362 |             f
    28 |     4200 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0012573234 |             f
    29 |     4350 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0096722952 |             f
    30 |     4500 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    31 |     4650 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    32 |     4800 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    33 |     4950 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    34 |     5100 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0142081336 |             f
    35 |     5250 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    36 |     5400 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0051046972 |             f
    37 |     5550 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    38 |     5700 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0037222997 |             f
    39 |     5850 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    40 |     6000 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    41 |     6150 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    42 |     6300 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    43 |     6450 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0039437227 |             f
    44 |     6600 |     12 |  0.000000E+00 |  0.000000E+00 |  0.0066673510 |             f
    45 |     6750 |     13 |  0.000000E+00 |  0.000000E+00 |  0.0370370370 |         ideal
    46 |     6900 |     12 |  0.000000E+00 |  0.000000E+00 |  0.0197881466 |         ideal
    47 |     7050 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0008477680 |             f
    48 |     7200 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0008477680 |             f
    49 |     7350 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0008477680 |             f
    50 |     7500 |     12 |  0.000000E+00 |  0.000000E+00 |  0.0030245429 |             f
    51 |     7650 |     12 |  0.000000E+00 |  0.000000E+00 |  0.0003980374 |             f
    52 |     7800 |     12 |  0.000000E+00 |  0.000000E+00 |  0.0003980374 |             f
    53 |     7950 |     12 |  0.000000E+00 |  0.000000E+00 |  0.0003980374 |             f
    54 |     8100 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0050895621 |             f
    55 |     8250 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0010811258 |             f
    56 |     8400 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0010811258 |             f
    57 |     8550 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0053158305 |             f
    58 |     8700 |     10 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    59 |     8850 |     10 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    60 |     9000 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0139405078 |             f
    61 |     9150 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0013257083 |             f
    62 |     9300 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0048810789 |             f
    63 |     9450 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0103048824 |             f
    64 |     9600 |     10 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    65 |     9750 |     10 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    66 |     9900 |     10 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    67 |    10050 |     10 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    68 |    10200 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    69 |    10350 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    70 |    10500 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    71 |    10650 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    72 |    10800 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    73 |    10950 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    74 |    11100 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    75 |    11250 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0010657655 |             f
    76 |    11400 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0022744996 |             f
    77 |    11550 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0093796797 |             f
    78 |    11700 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0030602358 |             f
    79 |    11850 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    80 |    12000 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0017368906 |             f
    81 |    12150 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0017368906 |             f
    82 |    12300 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0017368906 |             f
    83 |    12450 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0017368906 |             f
    84 |    12600 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0035387669 |             f
    85 |    12750 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    86 |    12900 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    87 |    13050 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    88 |    13200 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    89 |    13350 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    90 |    13500 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    91 |    13650 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    92 |    13800 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    93 |    13950 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004548999 |             f
    94 |    14100 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0004637616 |             f
    95 |    14250 |     11 |  0.000000E+00 |  0.000000E+00 |  0.0035476286 |             f
    96 |    14400 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    97 |    14550 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    98 |    14700 |     11 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f
    99 |    14850 |     10 |  0.000000E+00 |  0.000000E+00 |  0.0054360541 |             f
   100 |    15000 |     10 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f</code></pre>
</div>
</div>
</section>
<section id="selecting-the-best-solution" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="selecting-the-best-solution"><span class="header-section-number">2.5</span> Selecting the best solution</h2>
<p>The optimization produces a set of non-dominated solutions forming a Pareto front, where each point represents a different set of MSN parameters. However, selecting a single solution from this front requires careful consideration of the relative scales of our objective functions. The rank correlation objective (f₁) typically ranges from -1 to 1, while the weighted SPI score objective (f₂) can range from 0 to 100. This difference in scales means we cannot directly compare or combine these objectives without normalization.</p>
<p>To address this scale disparity, we first approximate the boundaries of our objective space using the best and worst values found for each objective during the optimization process. These boundary points (called the ideal and nadir points) allow us to normalize both objectives to a common scale ranging from 0 to 1. The normalized front maintains the same trade-off relationships between solutions but allows for fair weighting in the final selection process.</p>
<p>To select a single solution from this normalized front, we employ the Augmented Scalarization Function (ASF). The ASF combines multiple objectives into a single metric while maintaining Pareto optimality. We assign equal weights [0.5, 0.5] to both objectives, indicating no preference between ranking accuracy and score distribution. The ASF also includes a small augmentation term that ensures we select solutions that perform reasonably well on both objectives rather than extremely well on one but poorly on the other.</p>
<p>The solution minimizing the ASF yields the following MSN parameters:</p>
<div id="park_tgt" class="cell" data-caption="The target MSN distribution for the park optimization." data-execution_count="9">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pymoo.decomposition.asf <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ASF</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the approximated ideal and nadir points</span></span>
<span id="cb9-4">approx_ideal <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> park_res.F.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb9-5">approx_nadir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> park_res.F.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb9-6"></span>
<span id="cb9-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Normalize the obtained front</span></span>
<span id="cb9-8">nF <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (park_res.F <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> approx_ideal) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (approx_nadir <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> approx_ideal)</span>
<span id="cb9-9"></span>
<span id="cb9-10">weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>])</span>
<span id="cb9-11">decomp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ASF()</span>
<span id="cb9-12"></span>
<span id="cb9-13">park_I <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> decomp(nF, weights).argmin()</span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># print("Best regarding decomposition: Point %s - %s" % (park_I, park_res.F[park_I]))</span></span>
<span id="cb9-15"></span>
<span id="cb9-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(park_tgt.summary())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitted from direct parameters.
Direct Parameters:
xi:    [0.637 0.403]
omega: [[0.131 0.018]
 [0.018 0.262]]
alpha: [  2.502 -11.987]


None
None</code></pre>
</div>
</div>
<p>These parameters define a target distribution that achieves a rank correlation of 0.714 with the a priori ranking while maintaining meaningfully scaled SPI scores. The location parameters (<img src="https://latex.codecogs.com/png.latex?%5Cxi">) place the distribution’s center in the vibrant quadrant of the circumplex, while the covariance matrix (<img src="https://latex.codecogs.com/png.latex?%5COmega">) describes a moderately spread distribution with positive correlation between pleasantness and eventfulness. The skewness parameters (<img src="https://latex.codecogs.com/png.latex?%5Calpha">) indicate strong negative skew, particularly in the eventfulness dimension, suggesting the target favors soundscapes that avoid high eventfulness while maintaining moderate to high pleasantness.</p>
</section>
<section id="resulting-target-distribution" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="resulting-target-distribution"><span class="header-section-number">2.6</span> Resulting Target Distribution</h2>
<p>Figure&nbsp;1 (a) shows the Pareto front obtained from the optimization process, where each point represents a different set of MSN parameters and their corresponding objective function values. The x-axis shows the negative rank correlation (-f₁) and the y-axis shows the negative weighted SPI score (-f₂). The selected solution using the ASF with equal weights is highlighted in red. The spread of solutions along the front illustrates the fundamental trade-off between achieving perfect rank correlation and maximizing SPI scores.</p>
<p>Figure&nbsp;1 (b) shows the resulting target distribution in the soundscape circumplex model, sampled from the MSN parameters of our selected solution. The distribution is centered in the pleasant-eventful quadrant but shows clear asymmetry, with a longer tail extending into the calm quadrant. This shape suggests that while the target generally favors pleasant soundscapes, it is more tolerant of variation in eventfulness than in pleasantness. The moderate spread of the distribution indicates that the target allows for some natural variation in perception while still maintaining clear preferences for certain regions of the circumplex.</p>
<p>Together, these visualizations demonstrate both the optimization process (through the Pareto front) and its outcome (through the target distribution). The selected solution represents a balanced compromise between maintaining ranking accuracy and producing meaningful score distributions, while the resulting target distribution aligns with theoretical expectations about high-quality park soundscapes.</p>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb11-2"></span>
<span id="cb11-3">park_X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> park_res.X[park_I]</span>
<span id="cb11-4">park_tgt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb11-5">park_tgt.define_dp(</span>
<span id="cb11-6">    np.array([park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]]),</span>
<span id="cb11-7">    np.array([[park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]], [park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>], park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]]]),</span>
<span id="cb11-8">    np.array([park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>], park_X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>]]),</span>
<span id="cb11-9">)</span>
<span id="cb11-10">park_tgt.sample()</span>
<span id="cb11-11"></span>
<span id="cb11-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># print(park_tgt.summary())</span></span>
<span id="cb11-13"></span>
<span id="cb11-14">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Scatter()</span>
<span id="cb11-15">plot.add(park_res.F, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"blue"</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb11-16">plot.add(park_res.F[park_I], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red"</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb11-17">plot.do()</span>
<span id="cb11-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot.apply(lambda ax: ax.arrow(0, 0, 0.5, 0.5, color='black',</span></span>
<span id="cb11-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#                                head_width=0.01, head_length=0.01, alpha=0.4))</span></span>
<span id="cb11-20">plot.show()</span>
<span id="cb11-21">plt.show()</span>
<span id="cb11-22"></span>
<span id="cb11-23"></span>
<span id="cb11-24"></span>
<span id="cb11-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># park_tgt.sspy_plot()</span></span>
<span id="cb11-26">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(park_tgt.sample_data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span>
<span id="cb11-27">sspy.plotting.density_plot(</span>
<span id="cb11-28">    df, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb11-29">)</span>
<span id="cb11-30">plt.show()</span></code></pre></div>
<div id="fig-pymoo-parks" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pymoo-parks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-pymoo-parks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-pymoo-parks-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-pymoo-parks-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/TargetOptimization_files/figure-html/fig-pymoo-parks-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-pymoo-parks">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-pymoo-parks-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Multi-objective optimization Pareto front. The selected solution is indicated in red.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-pymoo-parks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-pymoo-parks-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-pymoo-parks-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/TargetOptimization_files/figure-html/fig-pymoo-parks-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-pymoo-parks">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-pymoo-parks-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) SCM distribution of the derived target distribution.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pymoo-parks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: NSGA-II optimization to learn the MSN parameters which produce the Park ranking.
</figcaption>
</figure>
</div>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Disclosure: The LLM ‘Claude Sonnet’ was used to assist in writing the explanation and code in this section.↩︎</p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{mitchell2024,
  author = {Mitchell, Andrew and Mitchell, Andrew and Aletta, Francesco},
  title = {Supplementary {Material} for: {Soundscape} {Perception}
    {Indices} {(SPI)}},
  date = {2024-11-07},
  url = {https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/TargetOptimization.html},
  langid = {en},
  abstract = {This document provides additional detail for the
    multi-objective optimization method of deriving Soundscape
    Perception Indices (SPI) from soundscape data presented in Section
    IV.B.1 of *Soundscape Perception Indices (SPI): Developing
    context-dependent single value scores of multidimensional soundscape
    perceptual quality*}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-mitchell2024" class="csl-entry quarto-appendix-citeas">
Mitchell, Andrew, Andrew Mitchell, and Francesco Aletta. 2024.
<span>“Supplementary Material for: Soundscape Perception Indices (SPI)
.”</span> November 7, 2024. <a href="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/TargetOptimization.html">https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/TargetOptimization.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/TargetOptimization.html</guid>
  <pubDate>Thu, 07 Nov 2024 12:59:28 GMT</pubDate>
</item>
<item>
  <title>Soundscape Perception Indices (SPI): Developing context-dependent single value scores of multidimensional soundscape perceptual quality</title>
  <dc:creator>Andrew Mitchell</dc:creator>
  <dc:creator>Francesco Aletta</dc:creator>
  <dc:creator>Tin Oberman</dc:creator>
  <dc:creator>Jian Kang</dc:creator>
  <link>https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/</link>
  <description><![CDATA[ 





<section id="sec-introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>The EU Green Paper on Future Noise Policy indicates that 80 million EU citizens are suffering from potentially harmful environmental noise levels, according to the World Health Organization (WHO) recommendations <span class="citation" data-cites="Berglund1999Guidelines">(Berglund, Lindvall, and Schwela 1999)</span>. The publication of the EU Directive Relating to the Assessment and Management of Environmental Noise (END) <span class="citation" data-cites="EuropeanUnion2002Directive">(European Union 2002)</span> more than two decades ago has led to major actions across Europe, with reducing noise levels as their main focus, for which billions of Euros are being spent. However, it is widely recognised that solely reducing sound level in people’s living environments is not always feasible or cost-effective and, more importantly, with only 30% of environmental noise annoyance depending on physical aspects of the signal such as acoustic energy <span class="citation" data-cites="Guski1997Psychological">(Guski 1997)</span>, sound level reduction will not necessarily lead to improved quality of life. For this reason, from a public health point of view, it is necessary to explore alternative management and design strategies for acoustic environments that rely on more positive soundscapes, rather than merely environments not affected by noise pollution <span class="citation" data-cites="Aletta2018Associations Kang2023Soundscape Kang2023Supportive">(Aletta, Oberman, and Kang 2018; Kang 2023; Kang et al. 2023)</span>.</p>
<p>Soundscape design, separate from (and complementary to) noise control engineering, is about the relationships between human physiology, perception, the sound environment, and its socio-cultural context <span class="citation" data-cites="Kang2006Urban">(Kang 2006)</span>. Soundscape research represents a paradigm shift in that it combines physical, social, and psychological approaches and considers environmental sounds as a ‘resource’ rather than ‘waste’ <span class="citation" data-cites="Kang2016Soundscape">(Kang and Schulte-Fortkamp 2016)</span> relating to perceptual constructs rather than just physical phenomena. However, the current research is still at the stage of describing and identifying the problems and tends to be fragmented and focussed on only special cases e.g.~subjective evaluations of soundscapes for residential areas <span class="citation" data-cites="SchulteFortkamp2013Introduction Chen2023Natural">(Schulte-Fortkamp and Kang 2013; Chen and Kang 2023)</span>. In the movement from noise control to soundscape creation <span class="citation" data-cites="Aletta2015Soundscape">(Aletta and Kang 2015)</span>, a vital step is the standardisation of methods to assess soundscape quality.</p>
<p>A common aim for implementing soundscape assessment in practice is to compare the quality of different soundscapes. Often (but not always) the goal is to identify a ‘good’ soundscape compared to a ‘bad’ soundscape. However, this presents several challenges:</p>
<ul>
<li>What makes a soundscape good or bad is highly contextual; that is, the same acoustic environment may result in different appreciations and perceptual outcomes, depending on where/when it is happening, and what groups of individuals are there to experience it.</li>
<li>On what metric should the quality rating be based? Previous attempts at defining objective metrics of “soundscape quality” assessment have fallen short of capturing the multidimensionality of people’s perception of surrounding acoustic environments.</li>
<li>How can we deal with different requirements and definitions of how a soundscape should be perceived? Soundscape constructs are normally seen as highly individualised, while designing the soundscapes of public spaces should look at accommodating the needs of a given community of a space as a whole.</li>
</ul>
<p>In many cases, the ultimate aim is to be able to rank soundscapes based on their quality. There is pressure from stakeholders and policymakers to move towards such simplified assessment protocols. However, any ranking metric should be flexible and be able to handle a variety of contexts and definitions of what a `good’ soundscape is for a given purpose. To address this, we will propose the Soundscape Perception Index (SPI) framework, a flexible method for defining single value indices of soundscape quality based on distributions within the Soundscape Circumplex Model (SCM) <span class="citation" data-cites="Axelsson2012Swedish Mitchell2022How Axelsson2010principal">(Östen Axelsson, Nilsson, and Berglund 2012; Mitchell, Aletta, and Kang 2022; Ö. Axelsson, Nilsson, and Berglund 2010)</span>. As previously suggested, the primary motivation behind the development of the Soundscape Perception Indices (SPI) framework stems from the need to address the existing gap in quantifying and comparing soundscape quality across diverse contexts and applications. By creating a unified framework for defining these indices, the aim is to is to empower stakeholders, decision-makers, and researchers with the ability to create tailored indices that align with their specific objectives and design goals, while simultaneously enabling cross-comparisons and benchmarking against empirically-defined reference soundscapes. This dual approach not only acknowledges the context-dependent nature of soundscape perception but also fosters a common language and understanding, facilitating knowledge sharing and collaborative efforts within the field. This paper will demonstrate the SPI framework and test whether it is capable of both scoring soundscape quality and generating consistent rankings of soundscapes across different contexts.</p>
</section>
<section id="sec-theoretical-background" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Theoretical Background</h1>
<p>In <span class="citation" data-cites="Aletta2016Soundscape">Aletta, Kang, and Axelsson (2016)</span>, the authors defined a framework for categorising the components of a soundscape assessment. They define three aspects: soundscape descriptors, soundscape indicators, and soundscape indices. Soundscape descriptors are defined as ‘measures of how people perceive the acoustic environment’ and soundscape indicators as ‘measures used to predict the value of a soundscape descriptor’. The relationship between soundscape indicator(s) and a soundscape descriptor effectively defines what has been previously referred to as a “predictive soundscape model” <span class="citation" data-cites="Aletta2016Soundscape Mitchell2022Predictive">(Aletta, Kang, and Axelsson 2016; Mitchell 2022)</span>. There are primarily two rationales for modeling the relationship between the physical attributes and the perceived (i.e., soundscape) qualities of the acoustic environment. Firstly, a predictive model can forecast how individuals would perceive the acoustic environment, eliminating the need for labour-intensive surveys <span class="citation" data-cites="Mitchell2023conceptual">(Mitchell et al. 2023)</span>. Secondly, a precise predictive model may unveil the root causes of these perceived qualities, thereby serving as a valuable tool for design. <span class="citation" data-cites="Lionello2020systematic">Lionello, Aletta, and Kang (2020)</span> provided a review of such models and concluded contextual features play an important role in increasing the quality of the model. Indices on the other hand, the primary focus of this article, are single numerical values that combine multiple indicators or descriptors to provide a comprehensive representation of the overall soundscape perception and allow for comparison between soundscapes.</p>
<p>The earliest and most commonly used scientific index measuring sound level is the Decibel (dB). To represent the overall level of sound with a single value on one scale, as the Decibel index does, is often desirable. For this purpose, a number of different values representing sounds at various frequencies must be combined. Several frequency weighting networks have been developed since the 1930s, considering typical human responses to sound based on equal-loudness-level contours <span class="citation" data-cites="Fletcher1933Loudness">(Fletcher and Munson 1933)</span> and, among them, the A-weighting network, with resultant decibel values called dBA, has been commonly used in almost all the national/international regulations <span class="citation" data-cites="Kryter1994Handbook">(Kryter 1994)</span>. However, there have been numerous criticisms on its effectiveness <span class="citation" data-cites="Parmanen2007weighted">(Parmanen 2007)</span> as the correlations between dBA and perceived sound quality (e.g.~noise annoyance) are often low <span class="citation" data-cites="Hellman1987Why">(Hellman and Zwicker 1987)</span>.</p>
<p>Another set of indices is psychoacoustic magnitudes, including loudness, fluctuation strength or roughness, sharpness, and pitch strength, developed through sound quality studies of industrial products since the 1980’s <span class="citation" data-cites="Zwicker2007Psychoacoustics">(Zwicker and Fastl 2007)</span>. These emerged when it was conceived that acoustic emissions can be characterised beyond just sound level <span class="citation" data-cites="Blauert1997Sound">(Blauert and Jekosch 1997)</span>. But while psychoacoustic magnitudes have proven to be successful for the assessment of product sound quality, in the field of environmental acoustics, their applicability has been limited <span class="citation" data-cites="Fastl2006Psychoacoustic">(Fastl 2006)</span>, since a significant feature of environmental acoustics is that there are multiple/dynamic sound sources. Additionally, while pyschoacoustic magnitudes incorporate perceptual aspects, both dB based and pyschoacoustic indicies are ultimately describing the acoustic signal and not the soundscape perception and may therefore be more accurately described as indicators rather than soundscape indices <span class="citation" data-cites="Mitchell2023conceptual">(Mitchell et al. 2023)</span>.</p>
<p>When applied to urban sound and specifically to noise pollution, the soundscape approach introduces three key considerations beyond traditional noise control methods:</p>
<ol type="1">
<li>considering all aspects of the environment which may influence perception, not just the sound level and spectral content (e.g., visual setting, odour environment, spatial layout, etc.);</li>
<li>an increased and integrated consideration of the varying impacts which different sound sources and sonic characteristics have on perception; and</li>
<li>a consideration of both the positive and negative dimensions of soundscape perception.</li>
</ol>
<p>This approach can enable better outcomes by identifying positive soundscapes (in line with the END’s mandate to “preserve environmental noise quality where it is good” <span class="citation" data-cites="EuropeanUnion2002Directive">(European Union 2002)</span>), better identifying specific sources of noise which impact soundscape quality and pinpointing the characteristics which may need to be decreased, and illuminating alternative methods which could be introduced to improve a soundscape where a reduction of noise is impractical <span class="citation" data-cites="Fiebig2018Does Kang2018Impact">(Fiebig 2018; Kang and Aletta 2018)</span>. Factors such as the presence of natural or human-made sounds, their temporal patterns, and the overall contextual meaning ascribed to these sounds all contribute to the holistic perception of a soundscape.</p>
<section id="sec-existing-soundscape-indices" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-existing-soundscape-indices"><span class="header-section-number">2.1</span> Existing ‘Soundscape Indices’</h2>
<p>While the field of soundscape research has witnessed substantial progress, the development of standardized indices for evaluating and comparing soundscapes across diverse contexts has been relatively limited. Existing indices can be broadly seen as arising from two domains: soundscape ecology and soundscape perception.</p>
<section id="sec-soundscape-ecology-and-bioacoustics" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="sec-soundscape-ecology-and-bioacoustics"><span class="header-section-number">2.1.1</span> Soundscape Ecology and Bioacoustics</h3>
<p>Within the realm of soundscape ecology, indices such as the Acoustic Diversity Index (ADI) and Frequency-dependent Acoustic Diversity Index (FADI) <span class="citation" data-cites="Xu2023frequency">(Xu et al. 2023)</span> have been developed to quantify the diversity and complexity of acoustic signals within a given soundscape. Similar indices (e.g.&nbsp;ADI, NDSI, ACI) have also been developed to analyse the acoustic signal of complex acoustic environments and indicate the richness and diversity of biophonic (natural) and anthrophonic (human-made) sound sources. However, while these indices contribute valuable insights into the ecological aspects of soundscapes, they do not directly address the perceptual dimensions that are central to the soundscape approach <span class="citation" data-cites="SchulteFortkamp2023Soundscapes">(Schulte-Fortkamp et al. 2023)</span>. The multi-dimensional nature of soundscape perception, encompassing factors such as pleasantness, eventfulness, and familiarity, necessitates a more comprehensive and context-sensitive approach.</p>
</section>
<section id="sec-soundscape-perception" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="sec-soundscape-perception"><span class="header-section-number">2.1.2</span> Soundscape Perception</h3>
<p>In the domain of soundscape perception, several indices have emerged as attempts to quantify the perceived quality of soundscapes, particularly in urban environments.</p>
<p>The Green Soundscape Index (GSI) <span class="citation" data-cites="Kogan2018Green">(Kogan et al. 2018)</span> incorporates factors such as the presence and levels of natural sounds and human-made sounds, and their respective contributions to the overall soundscape perception. The GSI is defined as the ratio of the perceived extent of natural sounds (PNS) to the perceived extent of traffic noise (PTN), ranging between 1/5 and 5. Subsequently, Cao and colleagues <span class="citation" data-cites="Cao2020Red Yang2022Effects">(Cao, Meng, and Kang 2020; Yang, Cao, and Meng 2022)</span> proposed the Red Soundscape Index (<img src="https://latex.codecogs.com/png.latex?RSI">), defined as the ratio of the perceived extent of human sounds to the perceived extent of either natural sounds (<img src="https://latex.codecogs.com/png.latex?RSI_n">) or traffic sounds (<img src="https://latex.codecogs.com/png.latex?RSI_t">), arguing that the GSI alone was not suitable for all urban soundscape design applications.</p>
<p>Building on ecological diversity concepts, <span class="citation" data-cites="Liu2014Effects">Liu et al. (2014)</span> introduced the Soundscape Diversity Index (SDI), which quantifies the probability of two randomly selected sounds in a soundscape belonging to different categories, providing a measure of soundscape complexity. Expanding on this approach, <span class="citation" data-cites="Xiang2023Soundscape">Xiang et al. (2023)</span> defined an expanded set of soundscape diversity indices, including the SDI, the Soundscape Richness Index (SRI), the Soundscape Dominance Index (SDO), and the Soundscape Evenness Index (SEI). These indices, adapted from species diversity measures in ecology, offer a more nuanced approach to quantifying aspects of soundscape perception. <span class="citation" data-cites="Xiang2023Soundscape">Xiang et al. (2023)</span> demonstrated that these indices could be partially explained by existing acoustic indicators and were more suitable for evaluating urban green spaces than traditional acoustic indices.</p>
<p><span class="citation" data-cites="Guo2023Harmonious">Guo et al. (2023)</span> proposed the Harmonious Degree of Sound Sources (SHD) index, which combines perceived loudness, occurrence, and preference for sound sources. The SHD assess how well the dominance of a sound aligns with visitors’ preferences, aiming to reflect the harmonious status of sounds in a soundscape.</p>
<p>In 2019, <span class="citation" data-cites="Kang2019Towards">Kang et al. (2019)</span> proposed the development of a set of soundscape indices (SSID) which might take the form <img src="https://latex.codecogs.com/png.latex?SSID%20=%20f(%5Ctext%7Bphysical%20factors%7D)%20+%20f(%5Ctext%7Bcontextual%20factors%7D)%20+%20%5Cldots"> where the functions and weights of each aspect influencing soundscape perception (i.e.&nbsp;physical/acoustic parameters, contextual and visual factors, personal factors, etc.) could be derived statistically from a large dataset of soundscape surveys. The work presented here represents a development of this thinking which has grown out of the SSID project, where the analysis and indexing of perception data and the connection between soundscape indicators and perception have been separated <span class="citation" data-cites="Mitchell2023conceptual">(Mitchell et al. 2023)</span>. This modularization of perception prediction based on objective factors and soundscape index creation should enable more sophisticated and thoughtful index creation and more advanced and updateable prediction models.</p>
<p>While these indices offer valuable insights into specific aspects of soundscape perception, they are limited in their ability to capture the full multidimensionality of soundscape experienve across diverse contexts. The Soundscape Perception Index (SPI) framework presented in this paper builds upon these efforts by providing a flexible, context-sensitive approach to soundscape assessment. Unlike many previous indices, the SPI is not an analysis of an acoustic signal but rather is an index of perception based on soundscape descriptors. Furthermore, it does not represent a single target in a particular context, but is a generalisable, extensible, and adaptable framework for scoring soundscapes against any goal defined by the user.</p>
<p>The remainder of the paper will introduce and demonstrate this framework, providing a case study of defining an appropriate target.</p>
</section>
</section>
</section>
<section id="sec-method" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Establishing the SPI Framework</h1>
<p>The index framework, ‘Soundscape Perception Indices (SPI)’ introduced in this paper is defined here as the agreement between an observed or modelled soundscape perception distribution and a target soundscape perception distribution. Its goal is to determine whether a soundscape - whether it be a real-world location, a proposed design, or a hypothetical scenario - aligns with the desired (or reference) perception of that soundscape. This is achieved by first defining the target distribution, which could represent what is considered to be the ‘ideal’ soundscape perception for a given context or application. The test distribution is then compared to the target distribution using a distance metric, which quantifies the deviation between the two distributions. The resulting distance value serves as the basis for calculating the SPI, with smaller distances indicating a closer alignment between the perceived soundscape and the target soundscape perception.</p>
<p>We refer to this as an index framework rather than a single index, as the SPI can be tailored to specific contexts and applications by defining a range of target distributions. A single index is thus created for each target distribution. An SPI value therefore does not represent a ‘good’ or ‘bad’ soundscape, but rather a measure of how closely the perceived soundscape aligns with the desired target soundscape perception. This approach allows for the development of bespoke indices tailored to specific design goals and objectives, while also enabling cross-comparisons and benchmarking against empirically-defined reference soundscape targets.</p>
<section id="sec-core-method" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-core-method"><span class="header-section-number">3.1</span> Core Method</h2>
<p>SPI is grounded in the soundscape circumplex model (SCM) <span class="citation" data-cites="Axelsson2010principal Axelsson2012Swedish">(Ö. Axelsson, Nilsson, and Berglund 2010; Östen Axelsson, Nilsson, and Berglund 2012)</span>, a robust theoretical foundation for understanding and representing the multi-dimensional nature of soundscape perception. The reason for grounding the SPI in the soundscape circumplex is that we have observed this model to become the most prevalent assessment model in soundscape literature <span class="citation" data-cites="Aletta2023Adoption">(Aletta and Torresin 2023)</span>. The SCM is built on a series of descriptors referred to as the Perceived Affective Quality (PAQ), proposed by <span class="citation" data-cites="Axelsson2010principal">(Ö. Axelsson, Nilsson, and Berglund 2010)</span>. These PAQs are based on the pleasantness-eventfulness paradigm adopted in research on emotions and environmental psychology (and its original version, conceptualized as valence-arousal paradigm), in particular Russell’s circumplex model of affect <span class="citation" data-cites="Russell1980circumplex">(Russell 1980)</span>. As summarised by <span class="citation" data-cites="Axelsson2010principal">Ö. Axelsson, Nilsson, and Berglund (2010)</span>: “Russell’s model identifies two dimensions related to the perceived pleasantness of environments and how activating or arousing the environment is.”</p>
<p>One benefit of the circumplex model is that, as a whole, it encapsulates several of the other proposed soundscape descriptors - in particular, annoyance, pleasantness, tranquillity, and possibly restorativeness <span class="citation" data-cites="Aletta2016Soundscape">(Aletta, Kang, and Axelsson 2016)</span>. According to <span class="citation" data-cites="Axelsson2015How">Ö. Axelsson (2015)</span>, the two-dimensional circumplex model of perceived affective quality provides the most comprehensive information for soundscape assessment. It is also possible that the overall soundscape quality could itself be derived from the pleasant-eventful scores derived for a soundscape. The circumplex also lends itself well to questionnaire-based methods of data collection, as proposed in <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span>. In contrast to methods such as soundwalks, interviews, and lab experiments, questionnaires are able to provide the quality and amount of data which is necessary for statistical modelling. Combined, these factors make the circumplex most appropriate for a single index as it provides a comprehensive summary of soundscape perception.</p>
<p>There are four steps involved in calculating the SPI, as shown in Figure&nbsp;1:</p>
<ol type="1">
<li>Define and parameterise the target circumplex distribution;</li>
<li>Sample the target distribution and prepare the test distribution;</li>
<li>Compare test and target distributions using the distance metric (two-dimensional Kolmogorov-Smirnov distance <img src="https://latex.codecogs.com/png.latex?D_%7BBKS%7D">);</li>
<li>Calculate <img src="https://latex.codecogs.com/png.latex?SPI%20=%20100%20*%20(1%20-%20D_%7BBKS%7D)">.</li>
</ol>
<div id="fig-bespoke-spi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bespoke-spi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/figures/SPI-framework.drawio.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bespoke-spi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Steps for calculating the SPI.
</figcaption>
</figure>
</div>
<p>These steps and their required background are discussed in detail in the following sections. Section&nbsp;4.2.1 will then present strategies for defining targets and their applications. Throughout this paper, we use the data contained in the International Soundscape Database (ISD) <span class="citation" data-cites="Mitchell2024International">(Mitchell et al. 2024)</span>, which includes 1300+ individual responses on the PAQ scales collected across 13 locations in London and Venice, according to the SSID Protocol <span class="citation" data-cites="Mitchell2020Soundscape">(Mitchell et al. 2020)</span>.</p>
</section>
<section id="sec-circumplex-distribution" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-circumplex-distribution"><span class="header-section-number">3.2</span> Define and Parameterise a Soundscape Circumplex Distribution</h2>
<p>To move the eight-item PAQ responses into the two-dimensional circumplex space, we use the projection method first presented in ISO/TS 12913-3:2018 <span class="citation" data-cites="ISO12913Part3">(ISO/TS 12913-3:2019 2019)</span>. This projection method and its associated formulae were recently updated further in <span class="citation" data-cites="Aletta2024Soundscape">Aletta et al. (2024)</span> to include a correction for the language in which the survey was conducted. <span class="citation" data-cites="Aletta2024Soundscape">Aletta et al. (2024)</span> also provides adjusted angles for translations of the circumplex attributes to be used in calculating the <img src="https://latex.codecogs.com/png.latex?P_%7BISO%7D"> and <img src="https://latex.codecogs.com/png.latex?E_%7BISO%7D"> coordinates. Once the individual perceptual responses are projected into the circumplex space, the resulting data for each location is treated as a circumplex distribution. There are several advancements in considering circumplex distributions compared to the discussions originally given in <span class="citation" data-cites="Mitchell2022How">Mitchell, Aletta, and Kang (2022)</span> which are necessary for SPI. Before exploring the SPI method and target setting more specifically, we will first address these developments.</p>
<p>The circumplex is defined by two axes: <img src="https://latex.codecogs.com/png.latex?P_%7BISO%7D"> and <img src="https://latex.codecogs.com/png.latex?E_%7BISO%7D">, which are limited to the range <img src="https://latex.codecogs.com/png.latex?%5B-1,%20+1%5D">. Typically, data in the soundscape circumplex is treated as a combination of two independent normal distributions, one for each axis <span class="citation" data-cites="Mitchell2022How Ooi2022Probably">(Mitchell, Aletta, and Kang 2022; Ooi et al. 2022)</span>. In some applications this approach is sufficient for capturing the distribution of soundscape perception, however defining a target distribution for SPI requires a more precise approach. The independent normal distribution approach relies on three key assumptions:</p>
<ol type="1">
<li>The two axes are normally distributed.</li>
<li>The two axes are symmetrically distributed.</li>
<li>The two axes are independent of each other.</li>
</ol>
<p>While the first assumption is generally valid, the second and third assumptions are not always met in practice. In particular, the distribution of soundscape perception responses in the circumplex is often characterised by a high degree of skewness, which can lead to inaccuracies in the calculation of the SPI. Soundscape circumplex distributions are most appropriately described as a bivariate skew-normal distribution <span class="citation" data-cites="Azzalini2005Skew">(Adelchi Azzalini 2005)</span> which accurately reflects the relationship between the two dimensions of the circumplex and the fact that real-world perceptual distributions have been consistently observed to not be strictly symmetric.</p>
<p>The skew-normal distribution is defined by three parameters: location (<img src="https://latex.codecogs.com/png.latex?%5Cmu">), scale (<img src="https://latex.codecogs.com/png.latex?%5Csigma">), and shape (<img src="https://latex.codecogs.com/png.latex?%5Calpha">). The location parameter defines the centre of the distribution, the scale parameter defines the spread of the distribution and the shape parameter defines the skew of the distribution. The one-dimensional skew-normal distribution is defined as <span class="citation" data-cites="Azzalini1996Multivariate">(A. Azzalini and Valle 1996)</span>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cphi(z;%20%5Calpha)%20=%202%20%5Cphi(z)%20%5CPhi(%5Calpha%20z)%20%5Cquad%20%5Ctext%7Bfor%7D%20%5Cquad%20z%20%5Cin%20%5Cmathbb%7BR%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cphi"> and <img src="https://latex.codecogs.com/png.latex?%5CPhi"> are the standard normal probability density function and distribution function, respectively, and <img src="https://latex.codecogs.com/png.latex?%5Calpha"> is a shape variable which regulates the skewness. The distribution reduces to a standard normal density when <img src="https://latex.codecogs.com/png.latex?%5Calpha%20=%200">. The bivariate skew-normal distribution extends this concept to two dimensions, allowing for the modelling of asymmetric and skewed distributions in a two-dimensional space such as the soundscape circumplex. The multivariate skew-normal (MSN) distribution including scale and location parameters is given by combining the normal density and distribution functions <span class="citation" data-cites="Azzalini1999Statistical">(A. Azzalini and Capitanio 1999)</span>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY%20=%202%20%5Cphi_k%20(y-%5Cxi;%20%5COmega)%20%5CPhi%5C%7B%5Calpha%5ET%5Comega%5E%7B-1%7D(y-%5Cxi)%5C%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cphi_k"> is the <em>k</em>-dimensional normal density with location <img src="https://latex.codecogs.com/png.latex?%5Cxi">, shape <img src="https://latex.codecogs.com/png.latex?%5Calpha">, and covariance matrix <img src="https://latex.codecogs.com/png.latex?%5COmega">. <img src="https://latex.codecogs.com/png.latex?%5CPhi%20%5C%7B%20%5Cdot%20%5C%7D"> is the normal distribution function and <img src="https://latex.codecogs.com/png.latex?%5Calpha"> is a <em>k</em>-dimensional shape vector. When <img src="https://latex.codecogs.com/png.latex?%5Calpha%20=%200">, <img src="https://latex.codecogs.com/png.latex?Y"> reduces to the standard multivariate normal <img src="https://latex.codecogs.com/png.latex?N_k(%5Cxi,%20%5COmega)"> density. A circumplex distribution can therefore be parameterised<sup>1</sup> with a 2x2 covariance matrix <img src="https://latex.codecogs.com/png.latex?%5COmega">, a 2x1 location vector <img src="https://latex.codecogs.com/png.latex?%5Cxi">, and a 2x1 shape vector <img src="https://latex.codecogs.com/png.latex?%5Calpha">, written as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY%20%5Csim%20MSN%20(%5Cxi,%20%5COmega,%20%5Calpha)%0A"></p>
<p>By fitting an MSN distribution to empirical soundscape perception responses, it becomes possible to accurately capture the asymmetry and skewness of the distribution. A bivariate skew-normal distribution can be summarised as a set of these three parameters. Once parameterised, the distribution can then be sampled from to generate a synthetic distribution of soundscape perception responses.</p>
<p>Soundscape targets can thus be set by defining the desired MSN distribution. To demonstrate this, we will construct three arbitrary targets which will be used later to score three SPIs. The parameters chosen for the example targets are given in Table&nbsp;1.</p>
<div id="tbl-target-params" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-target-params-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: The MSN direct parameterizations for three arbitrary example target distributions. <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_1"> is located in the pleasant half, with a wide variance, and a positive skew along the pleasantness axis. <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_2"> is located in the calm quadrant, with a typical variance, and a negative skew along the pleasantness axis and a positive skew along the eventful axis. <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_3"> is located in the vibrant quadrant, with a moderate variance, and a negative skew along the eventfulness axis.
</figcaption>
<div aria-describedby="tbl-target-params-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 56%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Target</th>
<th style="text-align: center;">Location <img src="https://latex.codecogs.com/png.latex?%5Cxi"></th>
<th style="text-align: center;">Covariance Matrix <img src="https://latex.codecogs.com/png.latex?%5COmega"></th>
<th style="text-align: center;">Shape <img src="https://latex.codecogs.com/png.latex?%5Calpha"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_1"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5B0.5,%200.0%5D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200.2%20&amp;%200.0%20%5C%5C%200.0%20&amp;%200.2%20%5Cend%7Bbmatrix%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5B1,%200%5D"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_2"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5B1.0,%20-0.4%5D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200.18%20&amp;%20-0.04%20%5C%5C%20-0.04%20&amp;%200.09%20%5Cend%7Bbmatrix%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5B-8,%201%5D"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_3"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5B0.5,%200.7%5D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200.1%20&amp;%200.05%20%5C%5C%200.05%20&amp;%200.1%20%5Cend%7Bbmatrix%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?%5B0,%20-5%5D"></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-sample-a-target-distribution" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="sec-sample-a-target-distribution"><span class="header-section-number">3.3</span> Sample a Target Distribution</h2>
<p>Once the parameters for an MSN are defined (i.e., the target), the MSN is then sampled using the <code>sn</code> package <span class="citation" data-cites="Azzalini2021R">(A. Azzalini 2021)</span> in <code>R</code> <span class="citation" data-cites="RCT2018R">(R Core Team 2018)</span>. This is to prepare the target distribution to be compared with the empirical test distribution. Several restrictions to the possible parameter values apply, most importantly the covariance matrix <img src="https://latex.codecogs.com/png.latex?%5COmega"> must be a positive-definite matrix. In depth discussions of how these parameterizations should be defined and their restrictions can be found in <span class="citation" data-cites="Azzalini2016How">Adelchi Azzalini (2016)</span>. Figure&nbsp;2 shows the result of sampling (n=1000) the three example distributions given in Table&nbsp;1 and plotting them as soundscape distributions.</p>
<div class="quarto-embed-nb-cell">
<div id="cell-fig-targets" class="cell" data-execution_count="48">
<div class="cell-output cell-output-display">
<div id="fig-targets" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/index_files/figure-html/notebooks-SingleIndex-Code-fig-targets-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Example of defining and sampling from three arbitrary bespoke targets.
</figcaption>
</figure>
</div>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-1" href="notebooks/SingleIndex-Code-preview.html#cell-fig-targets">Source: Exploring defining single value indices - SPI</a></div>
</section>
<section id="compare-the-target-and-test-soundscape-assessment-distributions" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="compare-the-target-and-test-soundscape-assessment-distributions"><span class="header-section-number">3.4</span> Compare the target and test soundscape assessment distributions</h2>
<p>Central to the SPI framework is the concept of a distance metric, which quantifies the deviation of a given soundscape from a desired target soundscape. This distance metric serves as the basis for calculating the SPI value, with smaller distances indicating a closer alignment between the perceived soundscape and the target soundscape perception. The distance between the test and target soundscape distributions is calculated using a two-dimensional Kolmogorov-Smirnov distance <img src="https://latex.codecogs.com/png.latex?D_%7BBKS%7D">} <span class="citation" data-cites="Fasano1987multidimensional">(Fasano and Franceschini 1987)</span>. The KS distance is a non-parametric metric of the equality of continuous distributions which is sensitive to both the location and shape of the distributions <span class="citation" data-cites="Chakravati1967Handbook">(Chakravati, Laha, and Roy 1967)</span>.</p>
<p>Essentially, we approach this as a problem of (dis)similarity between soundscapes. The <img src="https://latex.codecogs.com/png.latex?D_%7BBKS%7D"> distance metric is then proposed to assess how similar any two given soundscapes distributions are within the circumplex. Taken to the extreme, two perfectly matching distributions in the soundscape circumplex would return a 100% SPI value, while two completely dissimilar distributions would return a 0% SPI value. In practical terms, for the former, this will never be achieved in real world scenarios; for the latter, it is also difficult to estimate how low the SPI value could actually go, and it should be considered that the distance may happen in different directions within the circumplex space. For instance, if a distribution for a vibrant soundscape was taken as a reference, a compared soundscape distribution may exhibit low SPI values for being located in the calm, OR monotonous, OR chaotic regions of the model.</p>
<p>Using the data from one location in the ISD (Piazza San Marco) as the test distribution, the <img src="https://latex.codecogs.com/png.latex?D_%7BBKS%7D"> statistic is calculated for each of the target distributions defined above, shown in Table&nbsp;2 and <span class="citation" data-cites="fig">(<strong>fig?</strong>)</span>–targets.</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-execution_count="50">
<div id="tbl-ks-test" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="50">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ks-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Kolmogorov-Smirnov test comparing the empirical test distribution (Piazza San Marco) against three soundscape target distributions.
</figcaption>
<div aria-describedby="tbl-ks-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="50">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 15%">
<col style="width: 9%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Target</th>
<th>D</th>
<th><pre><code>      p</code></pre></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>tgt_1</td>
<td>0.66</td>
<td>6.94745e-25</td>
</tr>
<tr class="even">
<td>tgt_2</td>
<td>0.83</td>
<td>8.96388e-39</td>
</tr>
<tr class="odd">
<td>tgt_3</td>
<td>0.28</td>
<td>8.96388e-39</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</div>
</section>
<section id="calculate-the-spi-score" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="calculate-the-spi-score"><span class="header-section-number">3.5</span> Calculate the SPI score</h2>
<p>The final step is to convert <img src="https://latex.codecogs.com/png.latex?D_%7BBKS%7D"> into a more interpretable form to use as a comparison across soundscapes. Since the KS distance is a measure of dissimilarity, we first subtract it from one to give a measure of similarity between the test distribution and the target distribution. This is then scaled to produce a score which ranges from 0 to 100, giving the final SPI formula:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSPI%7D%20=%20100%20*%20(1%20-%20D_%7BBKS%7D%5C%7B%5Ctext%7BMSN%7D_%7Btest%7D,%20%5Ctext%7BMSN%7D_%7Btgt%7D%5C%7D)%0A"></p>
<p>To show the usefulness of the test-target paradigm, we calculated the SPIs for each of the three target distributions for all the locations included in the ISD, as shown in Table&nbsp;3. Since each location is now assigned an SPI, this makes it possible to effectively produce three separate rankings of soundscape quality for these locations, depending on which target is considered the goal.</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-execution_count="54">
<div id="tbl-ex-spis" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="54">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ex-spis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: SPI scores and rankings for the soundscapes of locations included in the International Soundscape Database (ISD).
</figcaption>
<div aria-describedby="tbl-ex-spis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="54">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">Ranking</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?SPI_1"> (pleasant)</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?SPI_2"> (calm)</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?SPI_3"> (vibrant)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">70 RegentsParkFields</td>
<td style="text-align: left;">61 CampoPrincipe</td>
<td style="text-align: left;">71 SanMarco</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: left;">69 CarloV</td>
<td style="text-align: left;">52 CarloV</td>
<td style="text-align: left;">62 TateModern</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: left;">65 RegentsParkJapan</td>
<td style="text-align: left;">50 PlazaBibRambla</td>
<td style="text-align: left;">60 StPaulsCross</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: left;">62 CampoPrincipe</td>
<td style="text-align: left;">49 RegentsParkFields</td>
<td style="text-align: left;">58 Noorderplantsoen</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: left;">61 PlazaBibRambla</td>
<td style="text-align: left;">45 MarchmontGarden</td>
<td style="text-align: left;">55 PancrasLock</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: left;">61 RussellSq</td>
<td style="text-align: left;">44 MonumentoGaribaldi</td>
<td style="text-align: left;">54 TorringtonSq</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: left;">61 MarchmontGarden</td>
<td style="text-align: left;">40 RussellSq</td>
<td style="text-align: left;">48 StPaulsRow</td>
</tr>
<tr class="even">
<td style="text-align: right;">8</td>
<td style="text-align: left;">61 MonumentoGaribaldi</td>
<td style="text-align: left;">38 RegentsParkJapan</td>
<td style="text-align: left;">48 RussellSq</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9</td>
<td style="text-align: left;">59 PancrasLock</td>
<td style="text-align: left;">38 PancrasLock</td>
<td style="text-align: left;">47 MiradorSanNicolas</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: left;">53 StPaulsCross</td>
<td style="text-align: left;">32 MiradorSanNicolas</td>
<td style="text-align: left;">43 CamdenTown</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11</td>
<td style="text-align: left;">49 TateModern</td>
<td style="text-align: left;">30 TateModern</td>
<td style="text-align: left;">40 CarloV</td>
</tr>
<tr class="even">
<td style="text-align: right;">12</td>
<td style="text-align: left;">48 StPaulsRow</td>
<td style="text-align: left;">30 StPaulsCross</td>
<td style="text-align: left;">36 MonumentoGaribaldi</td>
</tr>
<tr class="odd">
<td style="text-align: right;">13</td>
<td style="text-align: left;">43 MiradorSanNicolas</td>
<td style="text-align: left;">28 TorringtonSq</td>
<td style="text-align: left;">34 MarchmontGarden</td>
</tr>
<tr class="even">
<td style="text-align: right;">14</td>
<td style="text-align: left;">38 Noorderplantsoen</td>
<td style="text-align: left;">28 StPaulsRow</td>
<td style="text-align: left;">33 PlazaBibRambla</td>
</tr>
<tr class="odd">
<td style="text-align: right;">15</td>
<td style="text-align: left;">35 TorringtonSq</td>
<td style="text-align: left;">17 SanMarco</td>
<td style="text-align: left;">33 CampoPrincipe</td>
</tr>
<tr class="even">
<td style="text-align: right;">16</td>
<td style="text-align: left;">33 SanMarco</td>
<td style="text-align: left;">16 Noorderplantsoen</td>
<td style="text-align: left;">32 EustonTap</td>
</tr>
<tr class="odd">
<td style="text-align: right;">17</td>
<td style="text-align: left;">21 CamdenTown</td>
<td style="text-align: left;">15 CamdenTown</td>
<td style="text-align: left;">27 RegentsParkFields</td>
</tr>
<tr class="even">
<td style="text-align: right;">18</td>
<td style="text-align: left;">15 EustonTap</td>
<td style="text-align: left;">13 EustonTap</td>
<td style="text-align: left;">27 RegentsParkJapan</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="expanding-the-spi-framework" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Expanding the SPI framework</h1>
<p>Section&nbsp;3 has defined and demonstrated the foundational methodology for calculating an SPI score. This included how to: define and sample a target distribution; prepare the test and target distributions for comparison using the KS distance metric; and convert this into an SPI score. To expand this methodology into an applicable framework, we define two distinct types of targets: bespoke targets and reference targets, each serving a unique purpose in the index development process.</p>
<section id="bespoke-targets" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="bespoke-targets"><span class="header-section-number">4.1</span> Bespoke Targets</h2>
<p>Bespoke targets are essentially a direct application of the foundational method described above. Bespoke targets are tailor-made for specific projects, reflecting the desired soundscape perception for a particular application. These targets can be defined by stakeholders, designers, policymakers, or decision-makers based on their unique requirements, objectives, and constraints. This flexibility allows the SPI for a specific project to be tailored to the desire of the stakeholders for how that specific soundscape should function. It can also provide a consistent and quantifiable baseline for scenarios like a soundscape design contest wherein a target is specified and provided to all participants in the contest and the winning proposal is the design with the highest SPI score when assessed against that target. Stakeholders could use various methods to decide on a target, subject to the requirements of their project or use case. For example, it could be co-created with other stakeholders or space users, based on trying to match the soundscape of a previous project, or entirely arbitrary.</p>
</section>
<section id="reference-targets" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="reference-targets"><span class="header-section-number">4.2</span> Reference Targets</h2>
<p>In contrast to bespoke targets, reference targets represent generalized, widely recognized soundscape archetypes which transcend specific applications or projects. These archetypes serve as reference points and enable comparisons across different domains and use cases. Essentially a reference target is a target that has been <em>empirically defined</em> to encapsulate the ideal of a particular type of soundscape (e.g.&nbsp;for a park, for an urban square, for a particular group of users, etc.).</p>
<section id="sec-targets" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-targets"><span class="header-section-number">4.2.1</span> Deriving a target based on a priori rankings</h3>
<p>Absent from the above methodology has been an exploration of how to actually arrive at a target based on empirical evidence; i.e., not a target specified <em>ad hoc</em>, but rather an “absolute” target, based on type of space, use case, or similar. While arbitrary targets make the SPI framework incredibly flexible, able to score against an effectively infinite set of design goals, often targets should have some sort of systematic foundation, especially when defining a Reference Target. To enable this approach, we therefore present one method of systematically deriving a target distribution based on a given ranking of soundscape quality. Just as one primary goal of the SPI framework is to enable soundscape rankings to be produced from SPI scores, this method allows for rankings which were arrived at separately to produce an optimised SPI target.</p>
<p>The core challenge in developing a reference SPI target is determining what constitutes an “ideal” soundscape perception distribution for a given context. While we can directly specify MSN parameters to create bespoke targets based on theoretical expectations or design goals, developing empirically-grounded reference targets requires a more systematic approach.</p>
<p>To enable this approach, we therefore present one method of systematically deriving a target distribution based on a given ranking of soundscape quality. The <em>a priori</em> ranking serves as a bridge between existing knowledge about soundscape quality and the mathematical framework of the SPI. By starting with a ranking of soundscapes whose relative quality has been assessed through some external measure, we can use optimization techniques to derive MSN parameters that:</p>
<ol type="1">
<li>When used as an SPI target, produce scores that result in the same ranking order</li>
<li>Generate high SPI scores for the highly-ranked soundscapes</li>
<li>Define a distribution in the circumplex space that captures the perceptual characteristics common to high-quality soundscapes in this context.</li>
</ol>
<p>This approach allows us to work backwards from known good (and poor) examples to define what the target distribution should look like. For instance, if we know that location A has a better soundscape than location B for our purposes, the optimal target distribution should result in location A receiving a higher SPI score than location B.</p>
<p>In this case study, we will examine a possible ranking from the ISD park locations produced by the authors (shown in Table&nbsp;4).</p>
<div id="tbl-isd-ranking" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-isd-ranking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: A pre-defined ranking of soundscape quality of the park locations included in the International Soundscape Database (ISD). An SPI target will be derived which aims to reproduce this same ranking when applied to circumplex data from these locations.
</figcaption>
<div aria-describedby="tbl-isd-ranking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Rank</th>
<th style="text-align: center;">Location</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">RegentsParkJapan</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">RegentsParkFields</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">CampoPrincipe</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">MonumentoGaribaldi</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">RussellSq</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">MiradorSanNicolas</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">StPaulsCross</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">Noorderplantsoen</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Effectively, this is an optimisation task to determine the MSN parameters which best achieve the above goals. Parameter optimisation refers to the process of adjusting the parameters of a system, model, or algorithm to achieve the best possible performance according to one or more objectives. To set up the optimisation task, we first need to express the parameter space and any constraints. Since our goal is to identify an optimised soundscape target distribution, the parameters we will search over are:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cxi%20=%20(%5Cxi_x,%20%5Cxi_y)">, <img src="https://latex.codecogs.com/png.latex?-1%20%5Cleq%20%5Cxi%20%5Cleq%201"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5COmega%20=%20%5Cbegin%7Bpmatrix%7D%20var(x)%20&amp;%20cov(x,%20y)%20%5C%5C%20cov(y,%20x)%20&amp;%20var(y)%20%5Cend%7Bpmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?0%20%5Cleq%20var()%20%5Cleq%201"></li>
<li><img src="https://latex.codecogs.com/png.latex?-1%20%5Cleq%20cov()%20%5Cleq%201"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5COmega"> must be symmetric and positive definite</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha%20=%20(%5Calpha_x,%20%5Calpha_y)">, <img src="https://latex.codecogs.com/png.latex?-5%20%5Cleq%20%5Calpha%20%5Cleq%205"></li>
</ul>
<p>We then define the objective functions based on the two goals given above. For each step in the algorithm with a given trial set of parameters, a target distribution will be produced, the SPI for each test location assessed according to the protocol described in Section&nbsp;3, and the resulting set of SPI scores and ranking will be scored using the objective functions. Goal (1) is assessed by calculating the Spearman rank correlation between the <em>a priori</em> ranking and the SPI ranking:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_1%20=%20r_%7Bs%7D(R(%5Ctext%7Bprior%7D),%20R(%5Ctext%7Btarget%7D))%0A"></p>
<p>Goal (2) is scored by calculating a weighted sum of the produced SPIs. To prioritise a target which provides high SPI scores for highly ranked soundscapes, we weight according to the ranking position:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_2%20=%20%5Csum_%7Bi=1%7D%5Em%20%5Cfrac%7B1%7D%7B%5Ctext%7Brank%7D_i%7D%20%5Ccdot%20SPI_i%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?m"> is the number of included locations, <img src="https://latex.codecogs.com/png.latex?SPI_i"> is the calculated SPI score for the <img src="https://latex.codecogs.com/png.latex?i">-th location assessed against a trial target, and <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D_i"> is the calculated rank value of the <img src="https://latex.codecogs.com/png.latex?i">-th location.</p>
<p>Through our testing, optimising only on the rank correlation regularly produced targets which, while they did result in the desired ranking, were in no way representative of the soundscapes in question. We therefore aim to optimise for both a consistent soundscape ranking and for a high SPI score for the top-ranked soundscapes. Optimising these parameters with respect to multiple objectives ensures a more holistic approach to system improvement, acknowledging the trade-offs and interactions between different goals.</p>
<p>We apply the nondominated sorting genetic algorithm (NSGA-II) <span class="citation" data-cites="Deb2002fast">(Deb et al. 2002)</span> to optimise our target distribution parameters. NSGA-II is a popular and efficient multi-objective evolutionary algorithm that is well-suited for problems with multiple, potentially conflicting objectives.</p>
<p>The algorithm works as follows<sup>2</sup>:</p>
<ol type="1">
<li>Initialize a population of candidate solutions, each representing a set of target distribution parameters <img src="https://latex.codecogs.com/png.latex?(%5Cxi,%20%5COmega,%20%5Calpha)">.</li>
<li>Evaluate each candidate solution using the two objective functions defined above.</li>
<li>Perform non-dominated sorting to rank the solutions based on Pareto dominance.</li>
<li>Calculate crowding distance for each solution to maintain diversity in the population.</li>
<li>Select parent solutions using tournament selection based on non-domination rank and crowding distance.</li>
<li>Create offspring solutions using crossover and mutation operators, ensuring that the constraints on the parameters are maintained.</li>
<li>Combine parent and offspring populations and select the best solutions to form the next generation.</li>
<li>Repeat steps 2-7 for a specified number of generations or until a termination criterion is met.</li>
</ol>
<p>The NSGA-II algorithm is implemented using the Python library <code>pymoo v0.6.1.3</code> <span class="citation" data-cites="pymoo">(Blank and Deb 2020)</span>. The population size is set to 150, and the algorithm runs for 100 generations. In <code>pymoo</code>, each objective function is supposed to be minimised, so when implementing the algorithm and in the results, <img src="https://latex.codecogs.com/png.latex?-f_1"> and <img src="https://latex.codecogs.com/png.latex?-f_2"> are used. After running the NSGA-II algorithm, we obtain a set of non-dominated solutions representing the Pareto front, shown in Figure&nbsp;3 (a). Each solution on the Pareto front represents a trade-off between the two objectives: maximising the rank correlation (<img src="https://latex.codecogs.com/png.latex?f_1">) and maximising the weighted sum of SPI scores (<img src="https://latex.codecogs.com/png.latex?f_2">). The Pareto front allows us to visualise and analyse the range of possible solutions, from those that prioritise ranking consistency to those that emphasise high-SPI scores for top-ranked soundscapes.</p>
<div class="quarto-embed-nb-cell">
<div id="fig-pymoo-parks" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pymoo-parks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-pymoo-parks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-pymoo-parks-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-pymoo-parks-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/index_files/figure-html/notebooks-TargetOptimization-fig-pymoo-parks-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-pymoo-parks">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-pymoo-parks-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Multi-objective optimization Pareto front. The selected solution is indicated in red.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-pymoo-parks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-pymoo-parks-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-pymoo-parks-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/index_files/figure-html/notebooks-TargetOptimization-fig-pymoo-parks-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-pymoo-parks">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-pymoo-parks-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) SCM distribution of the derived target distribution.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pymoo-parks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: NSGA-II optimization to learn the MSN parameters which produce the Park ranking.
</figcaption>
</figure>
</div>
<a class="quarto-notebook-link" id="nblink-2" href="notebooks/TargetOptimization-preview.html#cell-fig-pymoo-parks">Source: Supplementary Material for: Soundscape Perception Indices (SPI) </a></div>
<p>For this demonstration, we opt for the second method, selecting the solution closest to the ideal point in the normalised objective space. This approach provides a balance between ranking consistency and high SPI scores for top-ranked soundscapes. Once the optimal solution is selected, we can sample from the MSN distribution and plot the derived target distribution, shown in Figure&nbsp;3.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctextup%7Btgt%7D_%7B%5Ctextup%7Bpark%7D%7D%20%5Csim%20%20%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%0A%20%20%20%20%5Cxi&amp;=&amp;%5B0.694,%200.406%5D%20%5C%5C%0A%20%20%20%20%5COmega&amp;=&amp;%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%20%20%200.157%20&amp;%200.040%20%5C%5C%0A%20%20%20%20%20%20%20%200.040%20&amp;%200.255%0A%20%20%20%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A%20%20%20%20%5Calpha&amp;=&amp;%5B5.054,%20-37.671%5D%0A%5Cend%7Bmatrix%7D%5Cright.%0A"></p>
<p>The resulting <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_%7B%5Ctext%7Bpark%7D%7D">, with the MSN parameters given above, exhibits some expected characteristics: it is almost entirely pleasant, with a long uneventful tail into the calm quadrant, but somewhat unexpectedly the mode is slightly vibrant. What should be made clear about this demonstration is that we are not presenting this as a reference target to be used in the future - this section is meant as a demonstration of a method which can be used to derive a target from an <em>a priori</em> ranking. In this case, the <em>a priori</em> ranking was created by the authors from their experience of the locations in the ISD. To truly be called an empirical reference target, the ranking would need to be arrived at empirically, via some other metric (e.g.&nbsp;health or productivity ratings of the areas) or through an experiment such as paired-choice comparisons.</p>
<p>It is these reference targets with an empirical backing which would ideally form agreed upon standards and benchmarks in the field against which new soundscapes would be compared. The best methods for empirically determining the ideal soundscape distribution for a given context will no doubt remain a topic of debate and development in the coming years.</p>
</section>
</section>
</section>
<section id="sec-discussion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Discussion</h1>
<p>The development of Bespoke and Reference context-dependent SPIs represents a significant step towards enabling more comprehensive and effective applications of the soundscape approach. By providing a unified framework for defining these indices, the potential for quantifying and comparing soundscape quality across diverse contexts and applications is unlocked, while still ensuring that the multi-dimensional and context-driven aspects of soundscape quality are considered.</p>
<section id="applications-of-the-spi-framework" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="applications-of-the-spi-framework"><span class="header-section-number">5.1</span> Applications of the SPI framework</h2>
<p>The proposed framework offers several key advantages. First, it acknowledges the inherent context-dependent nature of soundscape perception, allowing for the creation of indices tailored to specific use cases or design goals through the use of bespoke targets. This flexibility ensures that the resulting SPIs accurately capture the desired soundscape perception for the given application, enabling targeted interventions and optimisations.</p>
<p>Second, the inclusion of reference targets facilitates cross-comparisons and benchmarking, enabling a common language and understanding of soundscape quality across different domains. By calculating the distance between a given soundscape and these widely recognized references, stakeholders can identify areas for improvement and prioritize interventions accordingly, aligning their efforts with collectively recognized standards of desirable or undesirable soundscapes.</p>
<p>We expect that this would then expand into collections of SPI targets. As an example, imagine trying to define a soundscape perception index that could be applied across an entire city. A single index is insufficient, because each type of place within the city (e.g.&nbsp;parks, plazas, residential areas) has different requirements for its soundscape. Therefore, each place type would need its own soundscape target.</p>
<p>In this example, these sets of targets would correspond to different types of places within the city (e.g.&nbsp;a single target for parks, a target for plazas etc.). When applying this “urban typology” set of targets, the soundscape of each location being assessed would be scored against its relevant target (i.e how well does a specific park perform in comparison to a reference park target). This results in a single score for each location that can be compared against all other locations, regardless of whether or not they are the same type of place, allowing for different soundscapes to be compared on a common scale. This system ensures that context (in this case, the typology of a space) is brought into the assessment, allowing soundscapes to be scored against the most appropriate target. Enabling these context dependent assessments to be expressed on a common scale can facilitate additional use cases such as soundscape mapping, which requires a single scale to be applied across an entire city.</p>
<p>This set of targets made up of e.g.&nbsp;parks, plazas etc. is just one example of an application of reference SPIs. Other examples could include a demographics SPI, where different targets are set for respondents from different demographic groups, or a “use case” SPI with different targets set for different intended purposes of spaces (e.g.&nbsp;recreation, restoration, socialising). We encourage users of the SPI to define both their own single reference targets that can be added these suites of targets for use by others, and their own new sets of reference.</p>
<p><span class="citation" data-cites="Kogan2018Green">(Kogan et al. 2018, fig. 6)</span>, in fact displays a startlingly similar concept, showing the locations of the three categories of traffic noise dominance (‘traffic noise’, ‘balanced’, and ‘natural’) plotted in the circumplex perceptual model. It can be clearly seen in this plot that the GSI categories create their own clusters within the circumplex.</p>
<p>Although it is expected that the target distribution would usually represent the ideal or goal soundscape perception, it is also possible to define target distributions that represent undesirable or suboptimal soundscape perceptions. For instance, in a soundscape mapping context, it may be beneficial to map and identify chaotic soundscapes across a city in order to better target areas for soundscape interventions. In this case, the target distribution would be set in the chaotic quadrant and a higher SPI would indicate a closer alignment with the target distribution. This flexibility allows the SPI to be applied to a wide range of contexts and applications, enabling the quantification and comparison of soundscape quality across diverse scenarios.</p>
</section>
<section id="connecting-with-soundscape-data" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="connecting-with-soundscape-data"><span class="header-section-number">5.2</span> Connecting with soundscape data</h2>
<p>Unlike previous soundscape indices (see Section&nbsp;2.1), SPI does not include any direct connection to soundscape indicators such as the sound level, spectral content, etc. Its basis in perceptual descriptor data effective allows the analysis and quantification of soundscape information to be modularised, separating the task of calculating a single index from the complex task of predicting soundscape perception from objective data. The modularisation of soundscape data analysis allows the entire pipeline from environmental data collection through to soundscape index scoring to remain flexible. Following the soundscape engineering paradigm laid out in <span class="citation" data-cites="Mitchell2023conceptual">Mitchell et al. (2023)</span>, the connection between soundscape indicators, through descriptors, to indices can be made by predictive soundscape models. These models are trained on increasingly large scale datasets and generally designed to predict soundscape descriptors, including the SCM attributes <span class="citation" data-cites="Ooi2022Probably">Hou et al. (2024)</span>. With the complex and multidimensional nature of soundscape perception and with the rapid progression in machine learning techniques and applications, an index framework should be able to integrate new and improved models. By separating the prediction of perceptual descriptors based on objective metrics from the calculation of the single value index itself, the SPI framework allows for these predictive models and for the creation of new indices to advance independently.</p>
</section>
<section id="comparison-with-existing-soundscape-indices" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="comparison-with-existing-soundscape-indices"><span class="header-section-number">5.3</span> Comparison with existing soundscape indices</h2>
<p>The SPI framework represents a unique approach to soundscape assessment, building upon and differentiating itself from previous indices in several key ways. Firstly, the SPI framework is fundamentally perception-focused. By referring to the “Soundscape Perception Index”, we aim to highlight the unique and perception-focussed nature of this index framework. The SPI core method operates entirely within the perception data space, with no direct reference to acoustic or other indicators. Perceptual data (or predicted perceptual data) are the only operant factors of the SPI method. The aim of SPI is to combine multidimensional perception data and context (including design goals) into a single metric.</p>
<p>The SPI framework shares this important characteristic with indices like the Soundscape Diversity Index (SDI) <span class="citation" data-cites="Liu2014Effects">(Liu et al. 2014)</span> and the Harmonious Degree of Sound Sources (SHD) <span class="citation" data-cites="Guo2023Harmonious">(Guo et al. 2023)</span> in that they all prioritize perception as the primary input for assessment. Both SDI and SHD, however, focus on the perception of sound sources that can be observed in an acoustic environment, and their relationships. While these indices offer valuable insights into specific aspects of soundscape perception, they are somewhat limited in their scope and adaptability. The SPI framework builds upon these efforts by incorporating the full dimensionality of the soundscape circumplex model and allowing for context-sensitive assessments through bespoke and reference targets. This approach enables the SPI to address a wider range of soundscape evaluation needs while maintaining the crucial focus on perceptual data that distinguishes these methods from purely acoustic measurements.</p>
<p>Furthermore, the SPI framework is designed to be generalisable, extensible, and adaptable. Unlike previous indices that often represent a single target in a particular context, the SPI framework allows for scoring soundscapes against any goal defined by the user. This flexibility makes it applicable across a wide range of contexts and design objectives, from urban planning and acoustic design to research and policy development.</p>
</section>
<section id="limitations" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="limitations"><span class="header-section-number">5.4</span> Considerations and future work</h2>
<p>Several considerations should be noted when defining an SPI target. First, the target distribution should be representative of the desired soundscape perception for the given application. This requires a clear understanding of the context, objectives, and constraints of the project, as well as the preferences and expectations of stakeholders and end-users. Second, the temporal and spatial scales of the target distribution should align with the soundscape assessment being conducted. What constitutes the actual spatial bounds of ‘a soundscape’, or indeed of ‘a place’, is a complex question which will depend on the context of the assessment. For example, a park soundscape may be defined by the boundaries of the park itself, or it may extend to include the surrounding urban environment or be restricted to a certain distance from a feature of interest in the park<sup>3</sup>. The temporal scale of the assessment is also important, as soundscape quality can vary throughout the day and across different seasons. Increasing the spatial bounds of what is considered the soundscape under examination (e.g.&nbsp;a single position vs a 25<img src="https://latex.codecogs.com/png.latex?m%5E2"> area vs an entire park) or extending the temporal scale will almost certainly result in a distribution with a larger variance. What scales are appropriate for a given assessment will depend on the context and objectives of the project, but they should be considered when defining the target distribution. Applying a target distribution that is too broad or too narrow for the context of the assessment may result in inaccurate or misleading SPI scores. As the circumplex distribution first described in <span class="citation" data-cites="Mitchell2022How">Mitchell, Aletta, and Kang (2022)</span> and further formalised here develops, we are hopeful that a better understanding of the relationship between temporal and spatial scales and the parameters of the distribution will emerge and will contribute to an increased understanding of what constitutes `the soundscape of a place’ and how this should be reflected in its ideal perception distribution.</p>
<p>Various other distance metrics were considered when developing the SPI method. The simplest method is to define a single point target, rather than a target distribution, and calculate a normalized mean Euclidean distance between points in the test distribution and the target point. While this is conceptually simple and requires defining only a single coordinate point as a target, rather than the MSN parameters described in Section&nbsp;3.2, the shape and spread of a soundscape distribution is itself an important factor in describing the collective perception of a soundscape and would not be captured by this method <span class="citation" data-cites="Mitchell2022How">(Mitchell, Aletta, and Kang 2022)</span>.</p>
<p>An additional method which was considered, was to consider a target as an ellipse (or, indeed any other shape) drawn in the circumplex space (similar to the simplified median decile curves proposed in <span class="citation" data-cites="Mitchell2022How">Mitchell, Aletta, and Kang (2022)</span>). An SPI score would then be calculated based on the percentage of responses which fall within the space defined by the ellipse. Again, this is conceptually quite simple and defining the ellipse targets is straightforward. However, this method has an important flaw - it is easy to artificially inflate or deflate the scores merely by changing the area of the ellipse. The larger the ellipse, the higher all SPI scores will be, regardless of whether the sample distribution is wide or narrow. This would also limit cross-comparability between targets. As can be seen in Table&nbsp;3, defining a target distribution with a larger spread (i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?%5Ctext%7Btgt%7D_1">) does not automatically result in higher SPI scores across the board as it would with the ellipse target method. By defining the SPI as a true target-test distribution comparison we ensure that the SPI always accurately reflects the similarity between the perception of a soundscape and its target, both in terms of its location in the circumplex and the shape of the data.</p>
<p>As noted in Section&nbsp;4.2.1, although a methodology for deriving targets is presented, the <em>a priori</em> ranking we use for the demonstration was not itself arrived at empirically. Hence the park target cannot be considered a true reference target. A key piece of future work is to use experimental methods such as paired-choice comparisons to arrive at a well-defined ranking which can then produce a true reference target.</p>
</section>
</section>
<section id="conclusion" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Conclusion</h1>
<p>The ERC-funded Soundscape Indices (SSID) project was started mostly with the ambition to derive soundscape indices that could serve as numerical/quantifiable tools <span class="citation" data-cites="Kang2019Towards">(Kang et al. 2019)</span>, to better inform urban sound planning and design decisions. Any soundscape researcher having ever made an attempt at defining “the” soundscape quality index will know what a challenging, even impossible, task this is. Some may even argue that trying to reduce soundscape quality to a single-value quantity, and deriving any soundscape index, could be what philosophers would call a <em>contradictio in adjecto</em>, as the soundscape approach intrinsically advocates for a multi-dimensional characterization of the acoustic environments that we experience in our lives. For these reasons, we felt that it was necessary to take a step back and create instead a framework tailored for the field specifically that could easily be adapted to different contexts and capture the multi-faceted aspects of the soundscape of a place.</p>
<p>The proposed framework addresses the existing gap in quantifying multi-dimensional soundscape perception, facilitating a broader application of the soundscape approach in areas such as urban planning, environmental management, acoustic design, and policy development. Through the creation of bespoke indices tailored to specific design goals and the utilization of reference targets for benchmarking, this framework empowers stakeholders and decision-makers to make informed choices and prioritize soundscape improvements aligned with their unique objectives and constraints.</p>
<p>Furthermore, the grounding of the SPI framework in the soundscape circumplex model ensures a robust theoretical foundation, capturing the multi-dimensional nature of soundscape perception. The use of a distance metric enables quantitative assessments and comparisons, fostering a common language and understanding of soundscape quality across different domains. This shared understanding facilitates knowledge exchange, collaborative efforts, and the development of best practices within the field. As the SPI framework continues to be explored and refined, future research should focus on validating and expanding the range of reference targets, as well as investigating the potential for incorporating additional dimensions and factors that influence soundscape perception. The integration of emerging technologies (such as virtual, mixed, and augmented reality) may also provide new avenues for immersive soundscape evaluation and index development. Additionally, the application of the framework in diverse real-world scenarios, ranging from urban planning and environmental management to acoustic design and policy development, will provide valuable insights and contribute to the ongoing refinement and adaptation of the SPI framework.</p>
<p>In many ways, the proposed SPI framework is not so conceptually different from the whole idea of decibel-based set of indicators that the Soundscape Indices (SSID) project itself is trying to “overcome”. There is no such thing as a single noise indicator (<em>L</em>) to univocally describe sound levels in all circumstances; rather, different noise indicators are defined for different scenarios and temporal or spectral requirements (e.g., <img src="https://latex.codecogs.com/png.latex?L_%7Bden%7D">, <img src="https://latex.codecogs.com/png.latex?L_%7BAeq,%20T%7D">, etc.), based on testing needs. The decibel (dB) is the unit for all of them, but A-weighted equivalent sound levels for a one-hour interval cannot be directly compared with whole-day indicators with penalties. We are trying to achieve the same with the SPI to provide a way of defining different indices for different contexts, while maintaining a consistent framework.</p>
<p>Ultimately, for the SPI approach to succeed, collaboration with stakeholders, end-users, and experts from various domains will be crucial in ensuring the framework’s relevance and applicability across a wide range of contexts.</p>
</section>
<section id="acknowledgements" class="level1 unnumbered">
<h1 class="unnumbered">Acknowledgements</h1>
<p>This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (Grant No.&nbsp;740696, project title Soundscape Indices - SSID). More information and related publications can be found at the CORDIS webpage of the project<sup>4</sup></p>
</section>
<section id="data-and-code-availability" class="level1 unnumbered">
<h1 class="unnumbered">Data and Code Availability</h1>
<p>The data used in this paper are drawn from the publicly available International Soundscape Database (ISD v1.0.1-alpha.1) <span class="citation" data-cites="Mitchell2024International">Mitchell et al. (2024)</span> available on Zenodo<sup>5</sup>. The code to recreate the figures in this paper can be found on this paper’s Github page<sup>6</sup>.</p>
</section>
<section id="author-contributions" class="level1 unnumbered">
<h1 class="unnumbered">Author contributions</h1>
<p><strong>AM</strong>: Conceptualization, Methodology, Software, Writing-Original Draft, Writing-Review &amp; Editing, Visualization. <strong>FA</strong>: Conceptualization, Methodology, Writing-Review &amp; Editing. <strong>TO</strong>: Conceptualization, Writing-Review &amp; Editing. <strong>JK</strong>: Conceptualization, Supervision, Funding acquisition.</p>
</section>
<section id="references" class="level1" data-number="7">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">7 References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-Aletta2015Soundscape" class="csl-entry">
Aletta, Francesco, and Jian Kang. 2015. <span>“<span class="nocase">Soundscape approach integrating noise mapping techniques: a case study in Brighton, UK</span>.”</span> <em>Noise Mapping</em> 2 (1): 1–12. <a href="https://doi.org/10.1515/noise-2015-0001">https://doi.org/10.1515/noise-2015-0001</a>.
</div>
<div id="ref-Aletta2016Soundscape" class="csl-entry">
Aletta, Francesco, Jian Kang, and Östen Axelsson. 2016. <span>“<span class="nocase">Soundscape descriptors and a conceptual framework for developing predictive soundscape models</span>.”</span> <em>Landscape and Urban Planning</em> 149 (July): 65–74. <a href="https://doi.org/10.1016/j.landurbplan.2016.02.001">https://doi.org/10.1016/j.landurbplan.2016.02.001</a>.
</div>
<div id="ref-Aletta2024Soundscape" class="csl-entry">
Aletta, Francesco, Andrew Mitchell, Tin Oberman, Jian Kang, Sara Khelil, Tallal Abdel Karim Bouzir, Djihed Berkouk, et al. 2024. <span>“Soundscape Descriptors in Eighteen Languages: Translation and Validation Through Listening Experiments.”</span> <em>Applied Acoustics</em>. https://doi.org/<a href="https://doi.org/10.1016/j.apacoust.2024.110109">https://doi.org/10.1016/j.apacoust.2024.110109</a>.
</div>
<div id="ref-Aletta2018Associations" class="csl-entry">
Aletta, Francesco, Tin Oberman, and Jian Kang. 2018. <span>“<span class="nocase">Associations between Positive Health-Related Effects and Soundscapes Perceptual Constructs : A Systematic Review</span>.”</span> <em>International Journal of Environmental Research and Public Health</em> 15 (October): 1–15. <a href="https://doi.org/10.3390/ijerph15112392">https://doi.org/10.3390/ijerph15112392</a>.
</div>
<div id="ref-Aletta2023Adoption" class="csl-entry">
Aletta, Francesco, and Simone Torresin. 2023. <span>“Adoption of <span>ISO/TS</span> 12913-2:2018 Protocols for Data Collection from Individuals in Soundscape Studies: <span>A</span>n Overview of the Literature.”</span> <em>Current Pollution Reports</em>, October. <a href="https://doi.org/10.1007/s40726-023-00283-6">https://doi.org/10.1007/s40726-023-00283-6</a>.
</div>
<div id="ref-Axelsson2015How" class="csl-entry">
Axelsson, Östen. 2015. <span>“How to Measure Soundscape Quality.”</span> In <em>Proceedings of Euronoise 2015 :</em>, 1477–81. Stockholm University, Perception; psychophysics; Nederlands Akoestisch Genootschap; ABAV - Belgian Acoustical Society.
</div>
<div id="ref-Axelsson2010principal" class="csl-entry">
Axelsson, Östen, Mats E. Nilsson, and Birgitta Berglund. 2010. <span>“<span class="nocase">A principal components model of soundscape perception</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 128 (5): 2836–46. <a href="https://doi.org/10.1121/1.3493436">https://doi.org/10.1121/1.3493436</a>.
</div>
<div id="ref-Axelsson2012Swedish" class="csl-entry">
Axelsson, Östen, Mats E. Nilsson, and Birgitta Berglund. 2012. <span>“The <span>S</span>wedish Soundscape-Quality Protocol.”</span> In <em>The Journal of the Acoustical Society of America</em>, 131:3476–76. 4. Acoustical Society of America (<span>ASA</span>). <a href="https://doi.org/10.1121/1.4709112">https://doi.org/10.1121/1.4709112</a>.
</div>
<div id="ref-Azzalini2021R" class="csl-entry">
Azzalini, A. 2021. <span>“<span class="nocase">The R package sn: The Skew-Normal and Related Distributions such as the Skew-t and the SUN</span>.”</span> Università degli Studi di Padova, Italia. <a href="https://cran.r-project.org/package=sn">https://cran.r-project.org/package=sn</a>.
</div>
<div id="ref-Azzalini1999Statistical" class="csl-entry">
Azzalini, A., and A. Capitanio. 1999. <span>“Statistical Applications of the Multivariate Skew Normal Distribution.”</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 61 (3): 579–602. <a href="https://doi.org/10.1111/1467-9868.00194">https://doi.org/10.1111/1467-9868.00194</a>.
</div>
<div id="ref-Azzalini2005Skew" class="csl-entry">
Azzalini, Adelchi. 2005. <span>“The Skew-Normal Distribution and Related Multivariate Families.”</span> <em>Scandinavian Journal of Statistics</em> 32 (2): 159–88. <a href="https://doi.org/10.1111/j.1467-9469.2005.00426.x">https://doi.org/10.1111/j.1467-9469.2005.00426.x</a>.
</div>
<div id="ref-Azzalini2016How" class="csl-entry">
———. 2016. <span>“How to Sample from the <span>SN</span> and Related Distributions When We Want to Fix Skewness and Other Cumulants.”</span> <a href="http://azzalini.stat.unipd.it/SN/how_to_sample.pdf">http://azzalini.stat.unipd.it/SN/how_to_sample.pdf</a>.
</div>
<div id="ref-Azzalini1996Multivariate" class="csl-entry">
Azzalini, A., and A. Dalla Valle. 1996. <span>“The Multivariate Skew-Normal Distribution.”</span> <em>Biometrika</em> 83 (4): 715–26. <a href="http://www.jstor.org/stable/2337278">http://www.jstor.org/stable/2337278</a>.
</div>
<div id="ref-Berglund1999Guidelines" class="csl-entry">
Berglund, Birgitta, Thomas Lindvall, and Dietrich H. Schwela. 1999. <span>“Guidelines for Community Noise.”</span> Research report. World Health Organization; World Health Organization, Geneva.
</div>
<div id="ref-pymoo" class="csl-entry">
Blank, J., and K. Deb. 2020. <span>“Pymoo: Multi-Objective Optimization in Python.”</span> <em>IEEE Access</em> 8: 89497–509.
</div>
<div id="ref-Blauert1997Sound" class="csl-entry">
Blauert, Jens, and Ute Jekosch. 1997. <span>“Sound-Quality Evaluation a Multi-Layered Problem.”</span> <em>Acta Acustica United with Acustica</em> 83 (5): 747–53. <a href="https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00005">https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00005</a>.
</div>
<div id="ref-Cao2020Red" class="csl-entry">
Cao, Xinhao, Qi Meng, and Jian Kang. 2020. <span>“Red Soundscape Index (RSI): An Index with the Potential to Assess Soundscape Quality.”</span> In <em>INTER-NOISE and NOISE-CON Congress and Conference Proceedings</em>, 261:3527–39. 3. Institute of Noise Control Engineering.
</div>
<div id="ref-Chakravati1967Handbook" class="csl-entry">
Chakravati, Laha, and Roy. 1967. <em>Handbook of Methods of Applied Statistics</em>. Vol. 1. John Wiley; Sons.
</div>
<div id="ref-Chen2023Natural" class="csl-entry">
Chen, Xiaochao, and Jian Kang. 2023. <span>“Natural Sounds Can Encourage Social Interactions in Urban Parks.”</span> <em>Landscape and Urban Planning</em> 239 (November): 104870. <a href="https://doi.org/10.1016/j.landurbplan.2023.104870">https://doi.org/10.1016/j.landurbplan.2023.104870</a>.
</div>
<div id="ref-Deb2002fast" class="csl-entry">
Deb, Kalyanmoy, Amrit Pratap, Sameer Agarwal, and T. Meyarivan. 2002. <span>“A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II.”</span> Article. <em>IEEE Transactions on Evolutionary Computation</em> 6 (2): 182–97. <a href="https://doi.org/10.1109/4235.996017">https://doi.org/10.1109/4235.996017</a>.
</div>
<div id="ref-EuropeanUnion2002Directive" class="csl-entry">
European Union. 2002. <em><span class="nocase">Directive 2002/49/EC of the European Parliament and of the Council of 25 June 2002 relating to the assessment and management of environmental noise</span></em>.
</div>
<div id="ref-Fasano1987multidimensional" class="csl-entry">
Fasano, G., and A. Franceschini. 1987. <span>“A Multidimensional Version of the Kolmogorov–Smirnov Test.”</span> <em>Monthly Notices of the Royal Astronomical Society</em> 225 (1): 155–70. <a href="https://doi.org/10.1093/mnras/225.1.155">https://doi.org/10.1093/mnras/225.1.155</a>.
</div>
<div id="ref-Fastl2006Psychoacoustic" class="csl-entry">
Fastl, Hugo. 2006. <span>“Psychoacoustic Basis of Sound Quality Evaluation and Sound Engineering.”</span> In <em>The Thirteenth International Congress on Sound and Vibration</em>. Vienna.
</div>
<div id="ref-Fiebig2018Does" class="csl-entry">
Fiebig, André. 2018. <span>“<span class="nocase">Does it make a difference to have soundscape standards ?</span>”</span> <em>Proceedings - Euronoise 2018</em>, no. June (June): 6. <a href="https://www.euronoise2018.eu/docs/papers/482_Euronoise2018.pdf">https://www.euronoise2018.eu/docs/papers/482_Euronoise2018.pdf</a>.
</div>
<div id="ref-Fletcher1933Loudness" class="csl-entry">
Fletcher, Harvey, and W. A. Munson. 1933. <span>“Loudness, Its Definition, Measurement and Calculation*.”</span> <em>Bell System Technical Journal</em> 12 (4): 377–430. <a href="https://doi.org/10.1002/j.1538-7305.1933.tb00403.x">https://doi.org/10.1002/j.1538-7305.1933.tb00403.x</a>.
</div>
<div id="ref-Guo2023Harmonious" class="csl-entry">
Guo, Xuan, Jiang Liu, Zhu Chen, and Xin-Chen Hong. 2023. <span>“Harmonious Degree of Sound Sources Influencing Visiting Experience in Kulangsu Scenic Area, China.”</span> <em>Forests</em> 14 (1): 138. <a href="https://doi.org/10.3390/f14010138">https://doi.org/10.3390/f14010138</a>.
</div>
<div id="ref-Guski1997Psychological" class="csl-entry">
Guski, Rainer. 1997. <span>“Psychological Methods for Evaluating Sound Quality and Assessing Acoustic Information.”</span> <em>Acta Acustica United with Acustica</em> 83 (5): 765–74. <a href="https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00007">https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00007</a>.
</div>
<div id="ref-Hellman1987Why" class="csl-entry">
Hellman, Rhona, and Eberhard Zwicker. 1987. <span>“Why Can a Decrease in dB(a) Produce an Increase in Loudness?”</span> <em>The Journal of the Acoustical Society of America</em> 82 (5): 1700–1705. <a href="https://doi.org/10.1121/1.395162">https://doi.org/10.1121/1.395162</a>.
</div>
<div id="ref-Hou2024Soundscape" class="csl-entry">
Hou, Yuanbo, Qiaoqiao Ren, Andrew Mitchell, Wenwu Wang, Jian Kang, Tony Belpaeme, and Dick Botteldooren. 2024. <span>“Soundscape Captioning Using Sound Affective Quality Network and Large Language Model.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.2406.05914">https://doi.org/10.48550/ARXIV.2406.05914</a>.
</div>
<div id="ref-ISO12913Part2" class="csl-entry">
ISO/TS 12913-2:2018. 2018. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 2: <span>Data</span> Collection and Reporting Requirements.”</span>
</div>
<div id="ref-ISO12913Part3" class="csl-entry">
ISO/TS 12913-3:2019. 2019. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 3: <span>Data</span> Analysis.”</span>
</div>
<div id="ref-Kang2006Urban" class="csl-entry">
Kang, Jian. 2006. <em>Urban <span>S</span>ound <span>E</span>nvironment</em>. <span>CRC</span> Press. <a href="https://doi.org/10.1201/9781482265613">https://doi.org/10.1201/9781482265613</a>.
</div>
<div id="ref-Kang2023Soundscape" class="csl-entry">
———. 2023. <span>“Soundscape in City and Built Environment: Current Developments and Design Potentials.”</span> <em>City and Built Environment</em> 1 (1): 1.
</div>
<div id="ref-Kang2018Impact" class="csl-entry">
Kang, Jian, and Francesco Aletta. 2018. <span>“<span class="nocase">The Impact and Outreach of Soundscape Research</span>.”</span> <em>Environments</em> 5 (5): 58. <a href="https://doi.org/10.3390/environments5050058">https://doi.org/10.3390/environments5050058</a>.
</div>
<div id="ref-Kang2019Towards" class="csl-entry">
Kang, Jian, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Andrew Mitchell. 2019. <span>“<span class="nocase">Towards soundscape indices</span>.”</span> In <em>Proceedings of the 23rd International Congress on Acoustics</em>, integrating 4th EAA Euroregio 2019 : 9-13 September 2019:2488–95. Aachen: RWTH Aachen University. <a href="https://doi.org/10.18154/RWTH-CONV-239249">https://doi.org/10.18154/RWTH-CONV-239249</a>.
</div>
<div id="ref-Kang2023Supportive" class="csl-entry">
Kang, Jian, Francesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Huan Tong, Simone Torresin, Chunyang Xu, Tingting Yang, and Xiaochao Chen. 2023. <span>“Supportive Soundscapes Are Crucial for Sustainable Environments.”</span> <em>Science of The Total Environment</em> 855 (January): 158868. <a href="https://doi.org/10.1016/j.scitotenv.2022.158868">https://doi.org/10.1016/j.scitotenv.2022.158868</a>.
</div>
<div id="ref-Kang2016Soundscape" class="csl-entry">
Kang, Jian, and Brigitte Schulte-Fortkamp, eds. 2016. <em>Soundscape and the <span>B</span>uilt <span>E</span>nvironment</em>. Boca Raton, FL: CRC Press.
</div>
<div id="ref-Kogan2018Green" class="csl-entry">
Kogan, Pablo, Jorge P. Arenas, Fernando Bermejo, María Hinalaf, and Bruno Turra. 2018. <span>“<span class="nocase">A Green Soundscape Index (GSI): The potential of assessing the perceived balance between natural sound and traffic noise</span>.”</span> <em>Science of The Total Environment</em> 642 (November): 463–72. <a href="https://doi.org/10.1016/j.scitotenv.2018.06.023">https://doi.org/10.1016/j.scitotenv.2018.06.023</a>.
</div>
<div id="ref-Kryter1994Handbook" class="csl-entry">
Kryter, Karl D. 1994. <em>The <span>H</span>andbook of <span>H</span>earing and the <span>E</span>ffects of <span>N</span>oise</em>. London, UK: Academic Press.
</div>
<div id="ref-Lionello2020systematic" class="csl-entry">
Lionello, Matteo, Francesco Aletta, and Jian Kang. 2020. <span>“<span class="nocase">A systematic review of prediction models for the experience of urban soundscapes</span>.”</span> <em>Applied Acoustics</em> 170 (June). <a href="https://doi.org/10.1016/j.apacoust.2020.107479">https://doi.org/10.1016/j.apacoust.2020.107479</a>.
</div>
<div id="ref-Liu2014Effects" class="csl-entry">
Liu, Jiang, Jian Kang, Holger Behm, and Tao Luo. 2014. <span>“Effects of Landscape on Soundscape Perception: Soundwalks in City Parks.”</span> <em>Landscape and Urban Planning</em> 123 (March): 30–40. <a href="https://doi.org/10.1016/j.landurbplan.2013.12.003">https://doi.org/10.1016/j.landurbplan.2013.12.003</a>.
</div>
<div id="ref-Mitchell2022Predictive" class="csl-entry">
Mitchell, Andrew. 2022. <span>“Predictive <span>M</span>odelling of <span>C</span>omplex <span>U</span>rban <span>S</span>oundscapes: <span>E</span>nabling an Engineering Approach to Soundscape Design.”</span> PhD Thesis, University College London. <a href="https://doi.org/10.13140/RG.2.2.15590.50245">https://doi.org/10.13140/RG.2.2.15590.50245</a>.
</div>
<div id="ref-Mitchell2022How" class="csl-entry">
Mitchell, Andrew, Francesco Aletta, and Jian Kang. 2022. <span>“How to Analyse and Represent Quantitative Soundscape Data.”</span> <em>JASA Express Letters</em> 2 (3): 037201. <a href="https://doi.org/10.1121/10.0009794">https://doi.org/10.1121/10.0009794</a>.
</div>
<div id="ref-Mitchell2023conceptual" class="csl-entry">
Mitchell, Andrew, Francesco Aletta, Tin Oberman, Mercede Erfanian, and Jian Kang. 2023. <span>“A Conceptual Framework for the Practical Use of Predictive Models and <span>S</span>oundscape <span>I</span>ndices: <span>G</span>oals, Constraints, and Applications.”</span> In <em>INTER-NOISE 2023 Conference</em>. Chiba, Greater Tokyo.
</div>
<div id="ref-Mitchell2024International" class="csl-entry">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, Xiang Fang, and Jian Kang. 2024. <span>“<span class="nocase">The International Soundscape Database: An integrated multimedia database of urban soundscape surveys – questionnaires with acoustical and contextual information</span>.”</span> Zenodo. <a href="https://doi.org/10.5281/zenodo.10672568">https://doi.org/10.5281/zenodo.10672568</a>.
</div>
<div id="ref-Mitchell2020Soundscape" class="csl-entry">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. 2020. <span>“<span class="nocase">The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information</span>.”</span> <em>Applied Sciences</em> 10 (7): 2397. <a href="https://doi.org/10.3390/app10072397">https://doi.org/10.3390/app10072397</a>.
</div>
<div id="ref-Ooi2022Probably" class="csl-entry">
Ooi, Kenneth, Karn N. Watcharasupat, Bhan Lam, Zhen-Ting Ong, and Woon-Seng Gan. 2022. <span>“Probably Pleasant? A Neural-Probabilistic Approach to Automatic Masker Selection for Urban Soundscape Augmentation.”</span> In <em><span>ICASSP</span> 2022 - 2022 <span>IEEE</span> International Conference on Acoustics, Speech and Signal Processing (<span>ICASSP</span>)</em>. <span>IEEE</span>. <a href="https://doi.org/10.1109/icassp43922.2022.9746897">https://doi.org/10.1109/icassp43922.2022.9746897</a>.
</div>
<div id="ref-Parmanen2007weighted" class="csl-entry">
Parmanen, Juhani. 2007. <span>“A-Weighted Sound Pressure Level as a Loudness/Annoyance Indicator for Environmental Sounds – Could It Be Improved?”</span> <em>Applied Acoustics</em> 68 (1): 58–70. <a href="https://doi.org/10.1016/j.apacoust.2006.02.004">https://doi.org/10.1016/j.apacoust.2006.02.004</a>.
</div>
<div id="ref-RCT2018R" class="csl-entry">
R Core Team. 2018. <em><span>R</span>: <span>A</span> <span>L</span>anguage and <span>E</span>nvironment for <span>S</span>tatistical <span>C</span>omputing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-Russell1980circumplex" class="csl-entry">
Russell, James A. 1980. <span>“A Circumplex Model of Affect.”</span> <em>Journal of Personality and Social Psychology</em> 39 (6): 1161. <a href="https://doi.org/10.1037/h0077714">https://doi.org/10.1037/h0077714</a>.
</div>
<div id="ref-SchulteFortkamp2023Soundscapes" class="csl-entry">
Schulte-Fortkamp, Brigitte, André Fiebig, Joseph A. Sisneros, Arthur N. Popper, and Richard R. Fay, eds. 2023. <em>Soundscapes: <span>H</span>umans and <span>T</span>heir <span>A</span>coustic <span>E</span>nvironment</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-031-22779-0">https://doi.org/10.1007/978-3-031-22779-0</a>.
</div>
<div id="ref-SchulteFortkamp2013Introduction" class="csl-entry">
Schulte-Fortkamp, Brigitte, and Jian Kang. 2013. <span>“<span class="nocase">Introduction to the special issue on soundscapes</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 134 (1): 765–66. <a href="https://doi.org/10.1121/1.4810760">https://doi.org/10.1121/1.4810760</a>.
</div>
<div id="ref-Xiang2023Soundscape" class="csl-entry">
Xiang, Yi, Qi Meng, Xueyong Zhang, Mengmeng Li, Da Yang, and Yue Wu. 2023. <span>“<span class="nocase">Soundscape diversity: Evaluation indices of the sound environment in urban green spaces–Effectiveness, role, and interpretation</span>.”</span> <em>Ecological Indicators</em> 154: 110725.
</div>
<div id="ref-Xu2023frequency" class="csl-entry">
Xu, Zhi-yong, Lei Chen, Bryan C. Pijanowski, and Zhao Zhao. 2023. <span>“A Frequency-Dependent Acoustic Diversity Index: A Revision to a Classic Acoustic Index for Soundscape Ecological Research.”</span> <em>Ecological Indicators</em> 155 (November): 110940. <a href="https://doi.org/10.1016/j.ecolind.2023.110940">https://doi.org/10.1016/j.ecolind.2023.110940</a>.
</div>
<div id="ref-Yang2022Effects" class="csl-entry">
Yang, Da, Xinhao Cao, and Qi Meng. 2022. <span>“Effects of a Human Sound-Based Index on the Soundscapes of Urban Open Spaces.”</span> <em>Science of The Total Environment</em> 802 (January): 149869. <a href="https://doi.org/10.1016/j.scitotenv.2021.149869">https://doi.org/10.1016/j.scitotenv.2021.149869</a>.
</div>
<div id="ref-Zwicker2007Psychoacoustics" class="csl-entry">
Zwicker, Eberhard, and Hugo Fastl. 2007. <em><span class="nocase">Psychoacoustics: facts and models</span></em>. Third ed. Berlin ; New York: Springer. <a href="https://doi.org/10.1007/978-3-540-68888-4">https://doi.org/10.1007/978-3-540-68888-4</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>It is important to note that the parameters which appear in the density expression (<img src="https://latex.codecogs.com/png.latex?%5Cxi,%20%5COmega,%20%5Calpha">) are what are called ‘direct parameters’ (DP). They directly parameterise an MSN density and are typically only estimated by fitting an MSN to a sample. The more familiar and interpretable components (mean, standard deviation, and skewness) are termed the centred parameters (CP). It is possible to move from one parameterization to another, however “while any choice of the DP components is admissible, the same is not true for CP”; i.e.&nbsp;we can always move DP <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> CP but not always CP <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> DP. In this context, it is most important for readers not to confuse the location parameter <img src="https://latex.codecogs.com/png.latex?%5Cxi"> with the sample mean <img src="https://latex.codecogs.com/png.latex?%5Cmu">. A more complete explanation of these parameterizations can be found in <span class="citation" data-cites="Azzalini2016How">Adelchi Azzalini (2016)</span>↩︎</p></li>
<li id="fn2"><p>Further technical details of the multi-objective optimisation procedure and the relevant code can be found in the Supplementary Material.↩︎</p></li>
<li id="fn3"><p>For instance, the SSID Protocol, which produced the data used in this paper, attempted to address this by considering its spatial bounds for what constitutes one location to be “an ‘environmental unit’ wherein the environmental factors are consistent and is typically perceived to constitute a single distinct area”, noting that “the exact dimensions and delineation of the environmental unit will vary depending on the characteristics of the space” <span class="citation" data-cites="Mitchell2020Soundscape">(Mitchell et al. 2020)</span>↩︎</p></li>
<li id="fn4"><p>See <a href="https://cordis.europa.eu/project/id/740696/factsheet" class="uri">https://cordis.europa.eu/project/id/740696/factsheet</a> (Last viewed 2024-05-28).↩︎</p></li>
<li id="fn5"><p>See <a href="https://doi.org/10.5281/zenodo.10672568" class="uri">https://doi.org/10.5281/zenodo.10672568</a>↩︎</p></li>
<li id="fn6"><p>See <a href="https://github.com/MitchellAcoustics/J2401_JASA_SSID-Single-Index" class="uri">https://github.com/MitchellAcoustics/J2401_JASA_SSID-Single-Index</a>↩︎</p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{mitchell2024,
  author = {Mitchell, Andrew and Aletta, Francesco and Oberman, Tin and
    Kang, Jian},
  title = {Soundscape {Perception} {Indices} {(SPI):} {Developing}
    Context-Dependent Single Value Scores of Multidimensional Soundscape
    Perceptual Quality},
  journal = {Journal of the Acoustical Society of America},
  date = {2024-10-28},
  url = {https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/},
  langid = {en},
  abstract = {The soundscape approach provides a basis for considering
    the holistic perception of sound environments, in context. While
    steady advancements have been made in methods for assessment and
    analysis, a gap exists for comparing soundscapes and quantifying
    improvements in the multi-dimensional perception of a soundscape. To
    this end, there is a need for the creation of single value indices
    to compare soundscape quality which incorporate context, aural
    diversity, and specific design goals for a given application. Just
    as a variety of decibel-based indices have been developed for
    various purposes (e.g. \$L\_\{Aeq\}\$, \$L\_\{Ceq\}\$,
    \$L\_\{90\}\$, \$L\_\{den\}\$, etc.), the soundscape approach
    requires the ability to create novel indices for different uses,
    which share a common language and understanding. We therefore
    propose a unified framework for creating bespoke and reference
    single index measures of soundscape perception, allowing for new
    metrics to be defined in the future. This framework is based on a
    four-step test-target paradigm wherein a desired soundscape
    perception is defined as a target distribution within the soundscape
    circumplex and the 2D Kolmogorov-Smirnov distance is used to test an
    assessed soundscape against this target. Applications and
    implications of this framework are discussed and a multi-objective
    optimisation method for empirically defining perception indices is
    proposed.}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-mitchell2024" class="csl-entry quarto-appendix-citeas">
Mitchell, Andrew, Francesco Aletta, Tin Oberman, and Jian Kang. 2024.
<span>“Soundscape Perception Indices (SPI): Developing Context-Dependent
Single Value Scores of Multidimensional Soundscape Perceptual Quality
.”</span> <em>Journal of the Acoustical Society of America</em>,
October. <a href="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/">https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/</a>.
</div></div></section></div> ]]></description>
  <category>journal-articles</category>
  <guid>https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/</guid>
  <pubDate>Mon, 28 Oct 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraints, and applications</title>
  <dc:creator>Andrew Mitchell</dc:creator>
  <dc:creator>Francesco Aletta</dc:creator>
  <dc:creator>Tin Oberman</dc:creator>
  <dc:creator>Mercede Erfanian</dc:creator>
  <dc:creator>Jian Kang</dc:creator>
  <link>https://drandrewmitchell.com/research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html</link>
  <description><![CDATA[ 





<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>As the future of urban sound research and practice moves toward a more holistic soundscape focus, the ability to affect change at large scales and in a wide range of projects will require that familiar engineering tools and approaches can be applied to soundscape design. When attempting to apply soundscape in practice in the built environment, it becomes apparent that a predictive model of the users’ perceptual response to the acoustic environment is necessary. Whether to determine the impact of a design change, or to integrate a large scale data at neighbourhood and city levels, a mathematical model of the interacting factors will form a vital component of the implementation of the soundscape approach.</p>
<p>Current methods of assessing soundscapes are generally limited to a post hoc assessment of the existing environment, where users of the space in question are surveyed regarding their experience of the acoustic environment <span class="citation" data-cites="Engel2018Review Zhang2018Effect Ba2019Effect">(Engel et al. 2018; Zhang et al. 2018; Ba and Kang 2019)</span>. While this approach has proved useful in identifying the impacts of an existing environment, designers require the ability to predict how a change or proposed design will impact the soundscape of the space, before its implementation. To this end, a model that is built on measurable or estimate-able quantities of the environment would represent a leap forward in the ability to design soundscapes and to assess their broad impacts on health and wellbeing.</p>
<p>We will begin by outlining the use cases of predictive soundscape models and how they are necessary for certain applications. From the desired use cases, we will then outline a framework within which practical predictive models can be developed.</p>
</section>
<section id="defining-what-a-predictive-soundscape-model-is" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="defining-what-a-predictive-soundscape-model-is"><span class="header-section-number">2</span> Defining what a predictive soundscape model is</h2>
<p><span class="citation" data-cites="Aletta2016Soundscape">Aletta, Kang, and Axelsson (2016)</span> provide a review of the soundscape descriptors and indicators commonly used in soundscape research and outlines an initial framework for developing predictive soundscape models. In their review, the authors identified eight potential soundscape descriptors, including perceived affective quality <span class="citation" data-cites="Axelsson2010principal">(Axelsson, Nilsson, and Berglund 2010)</span>, restorativeness <span class="citation" data-cites="Payne2013production">(Payne 2013)</span>, etc. Similarly, the authors identified a range of potential indicators used to characterise the acoustic environment, including environmental acoustics indicators such as <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, <img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D%20%E2%88%92%20L_%7BAeq%7D"> and psychoacoustic indicators such as Loudness (<img src="https://latex.codecogs.com/png.latex?N_5">) and Sharpness (S).</p>
<p>However, it is noted that several studies show that no single psychoacoustic indicator alone can explain the variation in soundscape responses (as expressed via the descriptors) (e.g. <span class="citation" data-cites="PerssonWaye2002Psycho">(Persson Waye and Öhrström 2002)</span>). The goal of statistical modelling, therefore is to create a more complex and complete representation of the relationship between soundscape indicators and descriptors, beyond what any single indicator could achieve.</p>
<p>Figure&nbsp;1 shows a conceptual view of this relationship. We start with <strong>soundscape indicators</strong>, which characterise the physical and contextual environment to which the listener is exposed. This can be broken down into <strong>sonic features</strong> (e.g.&nbsp;the acoustical features listed above) and <strong>characteristics of the space itself</strong> (e.g.&nbsp;the amount of visible sky, the intended use-case of the space, how crowded the space is, etc.). In order to translate from the physical inputs to an expressed description of the soundscape perception, we introduce the concept of a <strong>perceptual mapping</strong> <span class="citation" data-cites="Lionello2021new">(Lionello 2021)</span>. This mapping represents a simplified idea of how each individual’s brain processes the inputs from the soundscape which they experience, forms a perception, and finally expresses that perception through their description of the soundscape. For our purposes, this perceptual mapping is treated as essentially a black box mapping inputs to outputs. It can be conceived of as a network of weights in which certain characteristics of the sound may have different weights and directions depending on the context, through which all of the inputs are processed, resulting in the soundscape rating. Conceptually, this perceptual mapping – the pathways and weightings through which the inputs are processed before being expressed as a perceptual descriptor – is established prior to an individual’s exposure to the soundscape in question.</p>
<div id="fig-model" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2023-08-20_Internoise-framework/Overall_Model_Concept_Diagram_2022-04-28.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The conceptual model of soundscape perception, illustrating the perceptual mapping from physical inputs, through personal experience, to soundscape descriptors. The role of the statistical model is to attempt to approximate or reflect this perceptual mappint. Reproduced with permission from <span class="citation" data-cites="Mitchell2022Predictive">Mitchell (2022)</span>
</figcaption>
</figure>
</div>
<p>It should be made clear that this represents a very simplified view of how a soundscape perception is formed, however it provides a useful conceptual framework for the purposes of understanding and modelling how someone’s perception forms in response to their exposure to a space. One way to consider the function of a statistical model of soundscape perception is as replicating the perceptual mapping between soundscape indicators and descriptors <span class="citation" data-cites="Lionello2021new">(Lionello 2021)</span>. As a person experiences an urban space, they are exposed to an array of physical inputs, these are then processed by the listener through their own personal experience and mapped to their perception of that space. This perception is then expressed through their description of this experience of the soundscape. It is this mapping of physical inputs to perceptual description which the statistical model aims to reflect. The most successful model would then accurately replicate the general perceptual mapping across the population.</p>
</section>
<section id="applications-in-design-and-mapping" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="applications-in-design-and-mapping"><span class="header-section-number">3</span> Applications in design and mapping</h2>
<p>The soundscape approach faces several challenges in practical applications which are unaddressed by current assessment methods, but which may be solved through the development of a predictive modelling framework. The first of these challenges is predicting how a change in an existing sound environment will be reflected in the soundscape perception. While it is possible in this scenario to measure the existing soundscape perception via questionnaire surveys, if a change is then introduced to the acoustic environment, it is so far impossible to say what the resulting soundscape change would be. This question relates strongly to the idea of soundscape interventions; where a particular noise pollution challenge is addressed by introducing more pleasant sounds (e.g.&nbsp;a water feature), following the soundscape principle of treating sound as a resource <span class="citation" data-cites="Lavia2016Soundscape Moshona2022What">(Lavia et al. 2016; Moshona et al. 2022)</span>. Predicting how much a particular intervention would improve the soundscape (or, indeed whether it would improve at all) is not yet possible with the retrospective methods available.</p>
<p>Several studies have attempted to address this gap by developing machine learning or statistical models of soundscape perception which are focussed on prediction, rather than inference. An array of modelling techniques are used, with linear regression being the most common <span class="citation" data-cites="Lionello2020systematic">(Lionello, Aletta, and Kang 2020)</span>, and also including artificial neural networks (ANN) <span class="citation" data-cites="PuyanaRomero2016Modelling Yu2009Modeling">(Puyana Romero et al. 2016; Yu and Kang 2009)</span> and support vector regression (SVR) <span class="citation" data-cites="Fan2016Automatic Fan2017Emo Giannakopoulos2019Athens">(Fan, Thorogood, and Pasquier 2016, 2017; Giannakopoulos, Orfanidi, and Perantonis 2019)</span>. However, these studies have focussed primarily on using these models to investigate the constructs of soundscape perception, with few efforts to put the models themselves to use. <span class="citation" data-cites="Mitchell2021Investigating">Mitchell et al. (2021)</span> attempted to address this by both developing a predictive model and applying it to an applied scenario where traditional assessment methods were impractical. In a unique application, <span class="citation" data-cites="Ooi2022Probably">Ooi et al. (2022)</span> created a predictive model of soundscape pleasantness which fed an automated and reactive soundscape enhancement system <span class="citation" data-cites="Watcharasupat2022Autonomous">(Watcharasupat et al. 2022)</span>.</p>
<p>Retrospective methods also struggle to capture the dynamics of the soundscape in a space. Whether through the narrative interview method of ISO/TS 12913-2 <span class="citation" data-cites="ISO12913Part2">(ISO/TS 12913-2:2018 2018)</span>, through soundwalks, or through in situ questionnaires <span class="citation" data-cites="Mitchell2020Soundscape">(Mitchell et al. 2020)</span>, only the soundscape during the particular period which the researchers are actively investigating is captured. This makes it very difficult to determine diurnal, seasonal, or yearly patterns of the soundscape. These patterns may be driven by corresponding diurnal, seasonal, or yearly patterns in the acoustic or visual environment, or by variations in how people process and respond to the sound at different times of day/season/year. Currently the only way to investigate any of these patterns is through repeated surveys. Predictive modelling, on the other hand, could allow a trained soundscape model to be paired with longterm monitoring methods to track how a soundscape perception may change in response to changes in the acoustic environment.</p>
<p>Similarly, a move towards modelling methods based on objective and/or measurable factors would facilitate the application of mapping in soundscape. While noise maps have become common in urban noise research and legislation <span class="citation" data-cites="EEA2020Environmental Gasco2020Social">(EEA 2020; Gasco et al. 2020)</span>, they can be difficult to translate into a soundscape approach. The Environmental Noise Directive (END) <span class="citation" data-cites="EuropeanUnion2002Directive">(European Union 2002)</span>, first implemented in 2002, is the main EU instrument to identify noise pollution impacts and track urban noise levels across the EU. Its goals were to determine the population’s exposure to environmental noise, make information on environmental noise available to the public, and prevent and reduce environmental noise and its effects. In general, noise maps are based on modelled traffic flows, from which decibel levels are extrapolated and mapped, although interpolation and mobile measurement methods have also been recently developed <span class="citation" data-cites="Aumond2018Probabilistic">(see Aumond, Jacquesson, and Can 2018)</span>. Alternatively, they can be produced using longterm SLMs or sensor networks. While these methods have significant utility for tracking increases in urban noise levels and are important for determining the health and societal impacts of noise on a large scale, their restricted focus on noise levels alone limits their scope and reduces the potential for identifying more nuanced health and psychological effects of urban sound.</p>
<p>Several studies have attempted to bring soundscape to urban noise mapping. The most notable of these attempts <span class="citation" data-cites="Aumond2018Probabilistic Aletta2015Soundscape Hong2017Exploring Kang2018Impact">(Aumond, Jacquesson, and Can 2018; Aletta and Kang 2015; Hong and Jeon 2017; Kang and Aletta 2018)</span> bring new, more sophisticated methods for mapping urban sound (not just noise levels). For instance, all four present methods which map the relative level of various sound sources, producing maps of the spatial distribution of bird sounds, human voices, water sounds, etc. In <span class="citation" data-cites="Aletta2015Soundscape">Aletta and Kang (2015)</span> and <span class="citation" data-cites="Hong2017Exploring">Hong and Jeon (2017)</span> the mapping relied on soundscape surveys conducted in public spaces, then used interpolation methods and basic relationships to the measured noise levels to generate a map of the perceived soundscape over the entire study space. <span class="citation" data-cites="Kang2018model">Kang et al. (2018)</span>, after starting with survey responses, attempted to create a prediction methods which relied only on the audio recordings made in the space to create visual maps of the predicted soundscape perception (i.e.&nbsp;the perceptual attributes ’pleasant’, ’calm’, ’eventful’, ’annoying’, ’chaotic’, ’monotonous’). According to the authors, the prediction and mapping model would follow three steps: (1) sound sources recognition and profiling, (2) prediction of the soundscape’s perceptual attributes, and (3) implementation of soundscape maps. Unfortunately, from the paper, it appears that the prediction model results were not actually used for the mapping and, again, the survey responses from 21 respondents were interpolated to create the soundscape map. Their results indicated how a predictive model could have been slotted into a mapping use-case, but this was limited by (1) the relatively poor predictive performance for several of the attributes, (2) the inability to automatically recognise sound sources, and (3) a very limited dataset in terms of sample size and variety of locations.</p>
<p>While the connection is not made to perception, <span class="citation" data-cites="Aumond2018Probabilistic">Aumond, Jacquesson, and Can (2018)</span> focussed on creating sound maps which can reflect the pattern of sound source emergences over time within a city. By stochastically activating varying sound sources across their map, they could map the percentage of time when a sound source emerges from the overall complex sound environment. If a predictive soundscape model which incorporates sound source information can be developed, then the same procedure which led to their sound source emergence maps could also feed the soundscape model, resulting in a map of predicted perception over time.</p>
<p>Urban scale noise mapping and its implementation at the international level has been crucial in highlighting the health impacts of urban noise and in providing evidence for the negative cost of excess noise. Traffic flow models of noise, large community noise surveys, and policy requirements to track noise levels have all been necessary to reveal these impacts. By creating predictive soundscape models, combined with new tools and sensing capabilities from smart city efforts, we can bring soundscape into these same realms. Without this, these large-scale impact studies will be limited to valuing the negative cost of urban noise, missing the potential value of positive soundscapes. By bringing perception-based practice to the same scale and type of evidence, we can expand urban sound research to consider a holistic view of urban spaces and their impacts.</p>
<p>The broader use-case and need for such soundscape models and maps was recently highlighted by <span class="citation" data-cites="Jiang2022Ten">Jiang et al. (2022)</span>, which opens the discussion for how the value and impact of soundscapes should be measured and what tools are needed to enable the valuation of policy interventions for soundscapes. In response to Question 5, “What soundscape metrics and data will be needed?”, the authors make clear the necessity of predictive soundscape models: “Quantitative soundscape metrics that link subjective perceptions to objective acoustic and contextual factors will be needed, to enable monetisation while at the same time account for the perception-based nature of soundscape.” In addition, the authors make a strong case for the need for soundscape indices: “Despite the varied requirements for soundscape metrics and data between and even within valuation methods, a standardised metric or set of metrics, such as dB in noise valuation [. . . ] will allow comparison and integration of different studies and building compatible evidence bases.”</p>
</section>
<section id="the-predictive-soundscape-model-framework" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="the-predictive-soundscape-model-framework"><span class="header-section-number">4</span> The Predictive Soundscape Model Framework</h2>
<p>Several forms and iterations of predictive models have been developed <span class="citation" data-cites="Lionello2020systematic">(Lionello, Aletta, and Kang 2020)</span> and more recently they have been put to use in real-world use cases <span class="citation" data-cites="Mitchell2021Investigating Watcharasupat2022Autonomous">(Mitchell et al. 2021; Watcharasupat et al. 2022)</span>. To improve on these models and make them into a useful engineering tool, we should establish a framework of overarching goals for models to achieve and the resulting development constraints. In general, the goals we define are related to how we might wish for models to be used and deployed, while the constraints are practical limitations which may make the performance of a given model less than ideal, but are necessary to achieve the deployment goals.</p>
<section id="goals" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="goals"><span class="header-section-number">4.1</span> Goals</h3>
<p>Before defining what form a general practical predictive model should take, we first need to make clear what the goals of such a model are, as derived from the preceding discussion laying out why predictive models are needed in soundscape.</p>
<p><strong>Accuracy</strong> – First, that it to a reasonable extent is successful in predicting the collective perception <span class="citation" data-cites="Mitchell2022How">(see Mitchell, Aletta, and Kang 2022)</span> of a soundscape. It should succeed at both indicating the central tendency of the soundscape perception, but importantly it should also inform the likely spread of perception among the population. The outcome of the predictive model should not be focussed on predicting an individual assessment; the goal is not the predict the perception of any specific individual, but to reflect the public’s perception of a public space. In other words, ideally the model will result in an accurate distribution of soundscape perceptions for the target population.</p>
<p><strong>Automation</strong> – Second, that it can be implemented automatically. Once an initial setup is performed, such as identifying what location the measurements are conducted in, the model should be capable of moving from recorded information to predicted soundscape distribution without human intervention. We need soundscape assessments to be able to be performed instrumentally. This enables it to be applied to unmanned uses, such as smart city sensors and soundscape mapping. It is impractical to conduct soundscape surveys or soundwalks in every location we wish to map and certainly not when we wish to see how these locations change over longer periods of time. A predictive model should allow us to survey these soundscapes remotely in order to extend soundscape to city-scale assessments.</p>
<p><strong>Comparisons</strong> – Third, the model should enable us to test, score, and compare proposed interventions. In a design context, it is crucial that various strategies and interventions can be tested and that the influencing factors can be identified. The model should assist the user in highlighting what factor is limiting the success of a soundscape, spark ideas for how to address it, and allow these ideas to be tested. Several other useful features of predictive soundscape models arise out of these goals and will be discussed later, but these form the core goals of the framework.</p>
</section>
<section id="constraints" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="constraints"><span class="header-section-number">4.2</span> Constraints</h3>
<p>If we accept that predictive models are necessary to advance a more holistic approach to urban sound in smart cities, we must then define the constraints of such a model. The goal here is to define a framework for what is needed from a future model intended to be used in a smart city sensors, soundscape mapping, or urban design context.</p>
<p><strong>Inputs</strong> – The first constraint is that the model must be based on measurable factors. By this, we mean that the data which eventually feeds into the predictive model should be collected via sensor measurements of one sort or another; this could be acoustic sound level measurements or recordings, environmental measurements, video recordings, or GIS measurements, etc. What it certainly cannot include is perceptual data. This is strictly a practical constraint – for a predictive model designed to be used in practice, there is no justification to include other perceptual factors, such as perceived greenness, derived from surveys but not whichever factor you desire to predict. If the goal is to predict soundscape pleasantness and it is necessary to survey people about the visual pleasantness, why not just also survey them about the soundscape pleasantness directly? Certainly this mix of perceptual data is useful in research and can elucidate the relationship between the sonic and visual environments, but it is not useful in a practical predictive context. Any results which arise from research combining this sort of perceptual information must eventually be translated into a component which can itself be measured or modelled.</p>
<p><strong>Calculation</strong> – The second constraint is that any analysis of the measured data can be done automatically, without human intervention. If the eventual goal is to deploy the model on continuously-running, unmanned sensor nodes or to enable practical large-scale measurements, the predictive model should be capable of operating with minimal human input. This means, for instance that if the model includes information about the sound source, this identification of the source should be possible to do automatically (i.e.&nbsp;through environmental sound recognition).</p>
<p>A potential constraint for some applications is related to computation time. Since one proposed application of a predictive soundscape model is to embed the model on a WASN node, the model would then need to be able to run on relatively low-power hardware such as a Raspberry Pi with a reasonable latency. This would especially present an issue for those models which rely on the combination of several psychoacoustic features <span class="citation" data-cites="Mitchell2021Investigating Orga2021Multilevel">(such as Mitchell et al. 2021; Orga et al. 2021)</span>, since these features are computationally intensive to calculate and several of them may need to be computed for each time step of the model. Although this is a real practical concern that should be addressed in the future, for the sake of this initial definition of a general predictive model used across many applications, we have not considered this a strict constraint.</p>
<p><strong>Generalisability</strong> – The third constraint is for the model to be generalisable to new locations. Ideally, it will be generalisable to new and (to it) unfamiliar soundscape types, but the minimum requirement should be that it can be applied to new locations which are otherwise similar to those in the training data. This means that any factors which are used to characterise the context provided by the location should be distinguished from a simple label of the location and should instead be derived from measurements of the location. In practice this could be geographical or architectural characteristics of the space, a proposed use-case of the space, or consistent visual characteristics of the space such as the proportion of pavement to green elements. This is in contrast to the model created in <span class="citation" data-cites="Mitchell2021Investigating">Mitchell et al. (2021)</span> which was constrained to be used only on those locations included in the training data since it made use of a location label.</p>
<p>For this third point, some aspects of the first and second constraints can be relaxed. Since this would only need to be defined once for a location, definitions such as the use case of the space could be defined by the person using the model. What is necessary is that the model and its component location-context factors can be set up ahead of time by the user, then the recording-level effects are able to be calculated automatically. In a multi-level modelling (MLM) context (such as that used in <span class="citation" data-cites="Mitchell2021Investigating">(Mitchell et al. 2021)</span>, this essentially amounts to choosing the appropriate location-level coefficients ahead of time then automatically calculating the features which are fed into those coefficients (per constraint 1 &amp; 2).</p>
<p><strong>Robustness</strong> – Finally, the model should be robust to missing components. If the original or full construction of the model depends on demographic information of the population using the space, in cases where this information is not available, it should be possible to omit it and still obtain a reasonable result. Here we may define potential ‘must-have’ and ‘optional’ factors. Given the amount of variance explained by the various factors which have been considered in previous predictive models, in-depth acoustic information is a must-have, while demographic and personal factors are an optional factor where the trade-off of losing 3% of the explained variance in eventfulness <span class="citation" data-cites="Erfanian2021Psychological">(Erfanian et al. 2021)</span> is accepted as reasonable. Based on the results of <span class="citation" data-cites="Mitchell2021Investigating">Mitchell et al. (2021)</span>, it would appear that location-context is crucial for modelling the pleasantness, but not for modelling the eventfulness. In order to determine the must-have factors for characterising the location-context, more work will need to be done to determine the appropriate input factors and their relative importance.</p>
</section>
</section>
<section id="making-use-of-the-predictions-in-design" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="making-use-of-the-predictions-in-design"><span class="header-section-number">5</span> Making use of the predictions in design</h2>
<p>There are various potential methods for integrating the predictive soundscape approach into a design and intervention setting. Not all spaces can or should have the same soundscape and soundscapes should be treated as dynamic, not static; identifying and creating an appropriate soundscape for the particular use case of a space is crucial to guiding its design. Proper forwardlooking design of a soundscape would involve defining the desired collective perception in the space. In the probabilistic soundscape approach from <span class="citation" data-cites="Mitchell2022How">Mitchell, Aletta, and Kang (2022)</span>, this can be achieved by drawing the desired shape in the circumplex and testing interventions which will bring the existing soundscape closer to the desired perception. A soundscape may need to be perceived as vibrant during the day and calm for some portion of the evening, meaning the desired shape should primarily sit within the vibrant quadrant but have some overlap into calm. This also enables designers to recognise the limitations of their environment and acknowledge that it is not always possible to transform a highly chaotic soundscape into a calm one. In these cases, instead the focus should be placed on shifting the perception to some degree in a positive direction.</p>
<div id="fig-cain" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cain-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2023-08-20_Internoise-framework/CainCircumplexTarget.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cain-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Adapted from <span class="citation" data-cites="Cain2013development">Cain, Jennings, and Poxon (2013)</span>. Using the soundscape circumplex shape for target-setting for soundscape design. Reproduced with permission from <span class="citation" data-cites="Mitchell2022Predictive">Mitchell (2022)</span>.
</figcaption>
</figure>
</div>
<p>The most sophisticated method of setting design goals is therefore to identify the desired shape which represents the variety of desired outcomes, and focus on designs and interventions which are most successful in matching the predicted outcome with that goal. This strategy of defining the optimal soundscape as an area or a shape within the 2-dimensional circumplex was previously illustrated by <span class="citation" data-cites="Cain2013development">Cain, Jennings, and Poxon (2013)</span>. In Figure&nbsp;2, we have adapted Cain’s Figure 6 to show how the shape of a target soundscape can be set and the shape of the existing soundscape compared to it. The work of a designer is then trialling intervention options which move the design soundscape closer to the target soundscape.</p>
</section>
<section id="towards-soundscape-indices" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="towards-soundscape-indices"><span class="header-section-number">6</span> Towards Soundscape Indices</h2>
<p>Although the types of visualisations developed in <span class="citation" data-cites="Mitchell2022How">(Mitchell, Aletta, and Kang 2022)</span> and <span class="citation" data-cites="Cain2013development">(Cain, Jennings, and Poxon 2013)</span> are a powerful tool for viewing, analysing, and discussing the multi-dimensional aspects of soundscape perception, there are certainly cases where simpler metrics are needed to aid discussion and to set design goals. Within the practicalities of built environment projects, the consequences and successes of a design often need to be quantifiable within a single index. Whether to demonstrate performance indicators to a client or to set and meet consistent policy requirements, numerical ratings and/or rankings are necessary. This therefore necessitates the creation of consistent and validated indices which indicate the degree to which a proposal achieves a set design goal.</p>
<p>The challenge for creating a single number index lies in properly combining the two-plus dimensions of soundscape perception with the needs of a specific project into a single index. The obvious option would be to ignore the multi-dimensionality and only score soundscape designs on the basis of their pleasantness score (as done in <span class="citation" data-cites="Ooi2022Probably">(Ooi et al. 2022)</span>). However, this seems to ignore both the significant importance of the eventfulness dimension in shaping the character of a soundscape and the role of appropriateness in determining the ’optimal soundscape’ for a space. Ideally, a soundscape index (or set of soundscape indices) would succeed at capturing all these aspects into a single scoring metric.</p>
</section>
<section id="conclusion" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">7</span> Conclusion</h2>
<p>The existing methods for soundscape assessment and measurement, such as those given in the ISO 12913 series, have been focussed primarily on determining the status quo of an environment. That is, they are able to determine how the space is currently perceived, but offer little insight into hypothetical environments. As such, they are less relevant for design purposes, where a key goal is to determine how a space will be perceived, not just how an existing space is perceived. The methods for assessment outlined in <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span> and for analysis given in <span class="citation" data-cites="ISO12913Part3">ISO/TS 12913-3:2019 (2019)</span> are inherently limited to post hoc assessments of an existing space. Since they are focussed on surveying people on their experience of the environment, it stands that the space must already exist for people to be able to experience. Toward this, and following from the combination of perceptual and objective data collection encouraged in <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span>, the natural push from the design perspective is towards ’predictive modelling’.</p>
</section>
<section id="references" class="level2 unnumbered">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-Aletta2015Soundscape" class="csl-entry">
Aletta, Francesco, and Jian Kang. 2015. <span>“<span class="nocase">Soundscape approach integrating noise mapping techniques: a case study in Brighton, UK</span>.”</span> <em>Noise Mapping</em> 2 (1): 1–12. <a href="https://doi.org/10.1515/noise-2015-0001">https://doi.org/10.1515/noise-2015-0001</a>.
</div>
<div id="ref-Aletta2016Soundscape" class="csl-entry">
Aletta, Francesco, Jian Kang, and Östen Axelsson. 2016. <span>“<span class="nocase">Soundscape descriptors and a conceptual framework for developing predictive soundscape models</span>.”</span> <em>Landscape and Urban Planning</em> 149 (July): 65–74. <a href="https://doi.org/10.1016/j.landurbplan.2016.02.001">https://doi.org/10.1016/j.landurbplan.2016.02.001</a>.
</div>
<div id="ref-Aumond2018Probabilistic" class="csl-entry">
Aumond, Pierre, Léo Jacquesson, and Arnaud Can. 2018. <span>“Probabilistic Modeling Framework for Multisource Sound Mapping.”</span> <em>Applied Acoustics</em> 139 (October): 34–43. <a href="https://doi.org/10.1016/j.apacoust.2018.04.017">https://doi.org/10.1016/j.apacoust.2018.04.017</a>.
</div>
<div id="ref-Axelsson2010principal" class="csl-entry">
Axelsson, Östen, Mats E. Nilsson, and Birgitta Berglund. 2010. <span>“<span class="nocase">A principal components model of soundscape perception</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 128 (5): 2836–46. <a href="https://doi.org/10.1121/1.3493436">https://doi.org/10.1121/1.3493436</a>.
</div>
<div id="ref-Ba2019Effect" class="csl-entry">
Ba, Meihui, and Jian Kang. 2019. <span>“<span class="nocase">Effect of a fragrant tree on the perception of traffic noise</span>.”</span> <em>Building and Environment</em>. <a href="https://doi.org/10.1016/j.buildenv.2019.04.022">https://doi.org/10.1016/j.buildenv.2019.04.022</a>.
</div>
<div id="ref-Cain2013development" class="csl-entry">
Cain, Rebecca, Paul Jennings, and John Poxon. 2013. <span>“The Development and Application of the Emotional Dimensions of a Soundscape.”</span> <em>Applied Acoustics</em> 74 (2): 232–39. <a href="https://doi.org/10.1016/j.apacoust.2011.11.006">https://doi.org/10.1016/j.apacoust.2011.11.006</a>.
</div>
<div id="ref-EEA2020Environmental" class="csl-entry">
EEA. 2020. <span>“<span class="nocase">Environmental noise in <span>Europe</span>, 2020.</span>”</span> Publications Office of the European Union. <a href="https://doi.org/10.2800/686249">https://doi.org/10.2800/686249</a>.
</div>
<div id="ref-Engel2018Review" class="csl-entry">
Engel, Margret Sibylle, André Fiebig, Carmella Pfaffenbach, and Janina Fels. 2018. <span>“<span class="nocase">A <span>Review</span> of <span>Socio</span>-acoustic <span>Surveys</span> for <span>Soundscape</span> <span>Studies</span></span>.”</span> <em>Current Pollution Reports</em> 4 (3): 220–39. <a href="https://doi.org/10.1007/s40726-018-0094-8">https://doi.org/10.1007/s40726-018-0094-8</a>.
</div>
<div id="ref-Erfanian2021Psychological" class="csl-entry">
Erfanian, Mercede, Andrew Mitchell, Francesco Aletta, and Jian Kang. 2021. <span>“Psychological Well-Being and Demographic Factors Can Mediate Soundscape Pleasantness and Eventfulness: A Large Sample Study.”</span> <em>Journal of Environmental Psychology</em> 77 (October): 101660. <a href="https://doi.org/10.1016/j.jenvp.2021.101660">https://doi.org/10.1016/j.jenvp.2021.101660</a>.
</div>
<div id="ref-EuropeanUnion2002Directive" class="csl-entry">
European Union. 2002. <em><span class="nocase">Directive 2002/49/EC of the European Parliament and of the Council of 25 June 2002 relating to the assessment and management of environmental noise</span></em>.
</div>
<div id="ref-Fan2016Automatic" class="csl-entry">
Fan, Jianyu, Miles Thorogood, and Philippe Pasquier. 2016. <span>“<span>Automatic Soundscape Affect Recognition Using A Dimensional Approach</span>.”</span> <em>AES: Journal of the Audio Engineering Society</em> 64 (9): 646–53. <a href="https://doi.org/10.17743/jaes.2016.0044">https://doi.org/10.17743/jaes.2016.0044</a>.
</div>
<div id="ref-Fan2017Emo" class="csl-entry">
———. 2017. <span>“Emo-Soundscapes: A Dataset for Soundscape Emotion Recognition.”</span> In <em>2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)</em>, 196–201. <a href="https://doi.org/10.1109/ACII.2017.8273600">https://doi.org/10.1109/ACII.2017.8273600</a>.
</div>
<div id="ref-Gasco2020Social" class="csl-entry">
Gasco, Luis, Rossano Schifanella, Luca Maria Aiello, Daniele Quercia, Cesar Asensio, and Guillermo de Arcas. 2020. <span>“<span class="nocase">Social Media and Open Data to Quantify the Effects of Noise on Health</span>.”</span> <em>Frontiers in Sustainable Cities</em> 2 (September): 41. <a href="https://doi.org/10.3389/frsc.2020.00041">https://doi.org/10.3389/frsc.2020.00041</a>.
</div>
<div id="ref-Giannakopoulos2019Athens" class="csl-entry">
Giannakopoulos, Theodoros, Margarita Orfanidi, and Stavros Perantonis. 2019. <span>“<span class="nocase">Athens Urban Soundscape (ATHUS): A Dataset for Urban Soundscape Quality Recognition</span>.”</span> In <em>International Conference on Multimedia Modeling</em>, 11295:338–48. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-14442-9">https://doi.org/10.1007/978-3-319-14442-9</a>.
</div>
<div id="ref-Hong2017Exploring" class="csl-entry">
Hong, Joo Young, and Jin Yong Jeon. 2017. <span>“Exploring Spatial Relationships Among Soundscape Variables in Urban Areas: A Spatial Statistical Modelling Approach.”</span> <em>Landscape and Urban Planning</em> 157 (January): 352–64. <a href="https://doi.org/10.1016/j.landurbplan.2016.08.006">https://doi.org/10.1016/j.landurbplan.2016.08.006</a>.
</div>
<div id="ref-ISO12913Part2" class="csl-entry">
ISO/TS 12913-2:2018. 2018. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 2: <span>Data</span> Collection and Reporting Requirements.”</span>
</div>
<div id="ref-ISO12913Part3" class="csl-entry">
ISO/TS 12913-3:2019. 2019. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 3: <span>Data</span> Analysis.”</span>
</div>
<div id="ref-Jiang2022Ten" class="csl-entry">
Jiang, Like, Aibgail Bristow, Jian Kang, Francesco Aletta, Rhian Thomas, Hilary Notley, Adam Thomas, and John Nellthorp. 2022. <span>“Ten Questions Concerning Soundscape Valuation.”</span> <em>Building and Environments</em>, May, 109231. <a href="https://doi.org/10.1016/j.buildenv.2022.109231">https://doi.org/10.1016/j.buildenv.2022.109231</a>.
</div>
<div id="ref-Kang2018Impact" class="csl-entry">
Kang, Jian, and Francesco Aletta. 2018. <span>“<span class="nocase">The Impact and Outreach of Soundscape Research</span>.”</span> <em>Environments</em> 5 (5): 58. <a href="https://doi.org/10.3390/environments5050058">https://doi.org/10.3390/environments5050058</a>.
</div>
<div id="ref-Kang2018model" class="csl-entry">
Kang, Jian, Francesco Aletta, Efstathios Margaritis, and Ming Yang. 2018. <span>“A Model for Implementing Soundscape Maps in Smart Cities.”</span> <em>Noise Mapping</em> 5 (1): 46–59. <a href="https://doi.org/10.1515/noise-2018-0004">https://doi.org/10.1515/noise-2018-0004</a>.
</div>
<div id="ref-Lavia2016Soundscape" class="csl-entry">
Lavia, Lisa, Max Dixon, Harry J. Witchel, and Mike Goldsmith. 2016. <span>“Soundscape and the <span>B</span>uilt <span>E</span>nvironment.”</span> In, edited by Jian Kang and Brigitte Schulte-Fortkamp, 243–302. Boca Raton, FL: CRC Press.
</div>
<div id="ref-Lionello2021new" class="csl-entry">
Lionello, Matteo. 2021. <span>“A New Methodology for Modelling Urban Soundscapes: <span>A</span> Psychometric Revisitation of the Current Standard and a <span>Bayesian</span> Approach for Individual Response Prediction.”</span> Master’s thesis, Unpublished. <a href="https://doi.org/10.13140/RG.2.2.30107.80160">https://doi.org/10.13140/RG.2.2.30107.80160</a>.
</div>
<div id="ref-Lionello2020systematic" class="csl-entry">
Lionello, Matteo, Francesco Aletta, and Jian Kang. 2020. <span>“<span class="nocase">A systematic review of prediction models for the experience of urban soundscapes</span>.”</span> <em>Applied Acoustics</em> 170 (June). <a href="https://doi.org/10.1016/j.apacoust.2020.107479">https://doi.org/10.1016/j.apacoust.2020.107479</a>.
</div>
<div id="ref-Mitchell2022Predictive" class="csl-entry">
Mitchell, Andrew. 2022. <span>“Predictive <span>M</span>odelling of <span>C</span>omplex <span>U</span>rban <span>S</span>oundscapes: <span>E</span>nabling an Engineering Approach to Soundscape Design.”</span> PhD Thesis, University College London. <a href="https://doi.org/10.13140/RG.2.2.15590.50245">https://doi.org/10.13140/RG.2.2.15590.50245</a>.
</div>
<div id="ref-Mitchell2022How" class="csl-entry">
Mitchell, Andrew, Francesco Aletta, and Jian Kang. 2022. <span>“How to Analyse and Represent Quantitative Soundscape Data.”</span> <em>JASA Express Letters</em> 2 (3): 037201. <a href="https://doi.org/10.1121/10.0009794">https://doi.org/10.1121/10.0009794</a>.
</div>
<div id="ref-Mitchell2020Soundscape" class="csl-entry">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. 2020. <span>“<span class="nocase">The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information</span>.”</span> <em>Applied Sciences</em> 10 (7): 2397. <a href="https://doi.org/10.3390/app10072397">https://doi.org/10.3390/app10072397</a>.
</div>
<div id="ref-Mitchell2021Investigating" class="csl-entry">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Magdalena Kachlicka, Matteo Lionello, Mercede Erfanian, and Jian Kang. 2021. <span>“Investigating Urban Soundscapes of the <span>COVID</span>-19 Lockdown: <span>A</span> Predictive Soundscape Modeling Approach.”</span> <em>The Journal of the Acoustical Society of America</em> 150 (6): 4474–88. <a href="https://doi.org/10.1121/10.0008928">https://doi.org/10.1121/10.0008928</a>.
</div>
<div id="ref-Moshona2022What" class="csl-entry">
Moshona, Cleopatra Christina, Francesco Aletta, Helen Henze, Xiaochao Chen, Andrew Mitchell, Tin Oberman, Huan Tong, André Fiebig, Jian Kang, and Brigitte Schulte-Fortkamp. 2022. <span>“What Is a Soundscape Intervention? Exploring Definitions and Identifi-Cation Criteria and a Platform to Gather Real-World Examples.”</span> In <em>51st International Congress and Exposition on Noise Control Engineering (INTER-NOISE 2022)</em>. <a href="https://www.researchgate.net/profile/Francesco-Aletta/publication/362906252_What_is_a_soundscape_intervention_Exploring_definitions_and_identification_criteria_and_a_platform_to_gather_real-world_examples/links/630664e561e4553b95364712/What-is-a-soundscape-intervention-Exploring-definitions-and-identification-criteria-and-a-platform-to-gather-real-world-examples.pdf">https://www.researchgate.net/profile/Francesco-Aletta/publication/362906252_What_is_a_soundscape_intervention_Exploring_definitions_and_identification_criteria_and_a_platform_to_gather_real-world_examples/links/630664e561e4553b95364712/What-is-a-soundscape-intervention-Exploring-definitions-and-identification-criteria-and-a-platform-to-gather-real-world-examples.pdf</a>.
</div>
<div id="ref-Ooi2022Probably" class="csl-entry">
Ooi, Kenneth, Karn N. Watcharasupat, Bhan Lam, Zhen-Ting Ong, and Woon-Seng Gan. 2022. <span>“Probably Pleasant? A Neural-Probabilistic Approach to Automatic Masker Selection for Urban Soundscape Augmentation.”</span> In <em><span>ICASSP</span> 2022 - 2022 <span>IEEE</span> International Conference on Acoustics, Speech and Signal Processing (<span>ICASSP</span>)</em>. <span>IEEE</span>. <a href="https://doi.org/10.1109/icassp43922.2022.9746897">https://doi.org/10.1109/icassp43922.2022.9746897</a>.
</div>
<div id="ref-Orga2021Multilevel" class="csl-entry">
Orga, Ferran, Andrew Mitchell, Marc Freixes, Francesco Aletta, Rosa Ma Alsina-Pagès, and Maria Foraster. 2021. <span>“<span class="nocase">Multilevel Annoyance Modelling of Short Environmental Sound Recordings</span>.”</span> <em>Sustainability</em> 13 (11): 5779. <a href="https://doi.org/10.3390/su13115779">https://doi.org/10.3390/su13115779</a>.
</div>
<div id="ref-Payne2013production" class="csl-entry">
Payne, Sarah R. 2013. <span>“The Production of a <span>P</span>erceived <span>R</span>estorativeness <span>S</span>oundscape <span>S</span>cale.”</span> <em>Applied Acoustics</em> 74 (2): 255–63. <a href="https://doi.org/10.1016/j.apacoust.2011.11.005">https://doi.org/10.1016/j.apacoust.2011.11.005</a>.
</div>
<div id="ref-PerssonWaye2002Psycho" class="csl-entry">
Persson Waye, K., and E. Öhrström. 2002. <span>“<span>P</span>sycho-Acoustic Characters of Relevance for Annoyance of Wind Turbine Noise.”</span> <em>Journal of Sound and Vibration</em> 250 (1): 65–73. <a href="https://doi.org/10.1006/jsvi.2001.3905">https://doi.org/10.1006/jsvi.2001.3905</a>.
</div>
<div id="ref-PuyanaRomero2016Modelling" class="csl-entry">
Puyana Romero, Virginia, Luigi Maffei, Giovanni Brambilla, and Giuseppe Ciaburro. 2016. <span>“Modelling the Soundscape Quality of Urban Waterfronts by Artificial Neural Networks.”</span> <em>Applied Acoustics</em> 111 (October): 121–28. <a href="https://doi.org/10.1016/j.apacoust.2016.04.019">https://doi.org/10.1016/j.apacoust.2016.04.019</a>.
</div>
<div id="ref-Watcharasupat2022Autonomous" class="csl-entry">
Watcharasupat, Karn N., Kenneth Ooi, Bhan Lam, Trevor Wong, Zhen-Ting Ong, and Woon-Seng Gan. 2022. <span>“Autonomous in-Situ Soundscape Augmentation via Joint Selection of Masker and Gain.”</span> <em><span>IEEE</span> Signal Processing Letters</em> 29: 1749–53. <a href="https://doi.org/10.1109/lsp.2022.3194419">https://doi.org/10.1109/lsp.2022.3194419</a>.
</div>
<div id="ref-Yu2009Modeling" class="csl-entry">
Yu, Lei, and Jian Kang. 2009. <span>“Modeling Subjective Evaluation of Soundscape Quality in Urban Open Spaces: An Artificial Neural Network Approach.”</span> <em>The Journal of the Acoustical Society of America</em> 126 (3): 1163–74. <a href="https://doi.org/10.1121/1.3183377">https://doi.org/10.1121/1.3183377</a>.
</div>
<div id="ref-Zhang2018Effect" class="csl-entry">
Zhang, Xu, Meihui Ba, Jian Kang, and Qi Meng. 2018. <span>“<span class="nocase">Effect of soundscape dimensions on acoustic comfort in urban open public spaces</span>.”</span> <em>Applied Acoustics</em> 133 (April): 73–81. <a href="https://doi.org/10.1016/j.apacoust.2017.11.024">https://doi.org/10.1016/j.apacoust.2017.11.024</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@inproceedings{mitchell2023,
  author = {Mitchell, Andrew and Aletta, Francesco and Oberman, Tin and
    Erfanian, Mercede and Kang, Jian},
  title = {A Conceptual Framework for the Practical Use of Predictive
    Models and {Soundscape} {Indices:} {Goals,} Constraints, and
    Applications},
  booktitle = {INTER-NOISE 2023 Conference},
  date = {2023-08-20},
  url = {https://drandrewmitchell.com/research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html},
  langid = {en},
  abstract = {With the recent standardization of soundscape, there has
    been increased interest in bringing the soundscape approach into an
    engineering context. While traditional assessment methods, such as
    those given in the ISO 12913 series, provide information on the
    current status quo of an environment, they offer limited insight
    into hypothetical environments and are therefore less relevant for
    design purposes. This conference paper presents a conceptual
    framework for the practical use of predictive soundscape models and
    indices. The framework outlines the goals, constraints, and
    potential applications of these models and highlights the need for
    further research in this area to better understand the dynamics of
    soundscape perception and to put predictive models to practical use.
    Predictive soundscape models can be integrated with soundscape
    indices - such as those being developed by the Soundscape Indices
    (SSID) project - for assessment purposes, providing a comprehensive
    approach to evaluating and designing sound environments. The use of
    predictive models is necessary to address the challenges faced in
    practical applications of the soundscape approach and to fill the
    gap between traditional assessment methods and the design of sound
    environments.}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-mitchell2023" class="csl-entry quarto-appendix-citeas">
Mitchell, Andrew, Francesco Aletta, Tin Oberman, Mercede Erfanian, and
Jian Kang. 2023. <span>“A Conceptual Framework for the Practical Use of
Predictive Models and Soundscape Indices: Goals, Constraints, and
Applications .”</span> In <em>INTER-NOISE 2023 Conference</em>. <a href="https://drandrewmitchell.com/research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html">https://drandrewmitchell.com/research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html</a>.
</div></div></section></div> ]]></description>
  <category>conference-papers</category>
  <guid>https://drandrewmitchell.com/research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html</guid>
  <pubDate>Sun, 20 Aug 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How to analyse and represent quantitative soundscape data</title>
  <dc:creator>Andrew Mitchell</dc:creator>
  <dc:creator>Francesco Aletta</dc:creator>
  <dc:creator>Jian Kang</dc:creator>
  <link>https://drandrewmitchell.com/research/papers/2022-03-16_JASAEL-HowToAnalyseQuantitativeSoundscapeData/paper.html</link>
  <description><![CDATA[ 





<section id="sec-introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Methods for collecting data on how people experience acoustic environments have been at the forefront of the debate in soundscape studies for the past 20 years. While the soundscape research field as we understand it today dates back to the late 1960s with the pioneering work of authors like M. Southworth <span class="citation" data-cites="Southworth1969sonic">(Southworth 1969)</span>, R.M. Schafer <span class="citation" data-cites="SoundscapeOursonicSchafer">(Schafer 1977)</span>, and H. Westerkamp <span class="citation" data-cites="westerkamp2002linking">(Westerkamp 2002)</span>, the theme of data collection methods for soundscape assessment emerged more prominently only recently <span class="citation" data-cites="kang2016ten">(Kang et al. 2016)</span>. There is a general consensus in the research community that standardised tools to gather and report individual responses on the perception of urban acoustic environments are indeed desirable, to provide comparable datasets and soundscape characterisations across different locations, times, and samples of people, as well as allowing for replicability studies, and offering inputs for modelling algorithms in soundscape prediction and design tasks. These were among the main drivers for the establishment of a Working Group at the International Organization for Standardization (ISO) back in 2008, which was named “Perceptual assessment of soundscape quality” (ISO/TC 43/SC 1/WG 54) that has so far published three documents within the ISO 12913 series on soundscape. Part 1 (ISO 12913-1:2014) is a full standard and provides a general framework and definitions of soundscape concepts <span class="citation" data-cites="ISO12913_1">(ISO 2014)</span>, while Part 2 (ISO/TS 12913-2:2018) and Part 3 (ISO/TS 12913-3:2019) are technical specifications and offer guidance on how data should be collected and analysed, accordingly <span class="citation" data-cites="ISO12913_2 ISO12913_3">(ISO 2018, 2019)</span> (Part 4, on soundscape design interventions, is currently under development by the working group, also registered as a technical specifications document). Specifically, Part 3 presents the proposed methods for analysing and representing the data collected by the soundscape surveys. Since the development of these standards, the focus has shifted from understanding individual perception to characterising the collective perception of increasingly large groups.</p>
<p>In a recent editorial paper on Soundscape Assessment, Axelsson and colleagues observe that it is important to critically discuss current theories and models in soundscape studies and to examine their effectiveness, while also looking at how to integrate different methods and perspectives for the discipline to make further advancements <span class="citation" data-cites="Axelsson2019editorial">(Axelsson, Guastavino, and Payne 2019)</span>. This work was mainly aimed at addressing the issue of meaningful comparability and representation of soundscape assessments. Part 2 of the ISO 12913 standard itself does not provide ultimate answers: the technical specifications recommend multiple methods, as consensus around a single protocol could not be reached. This diversity of methodological approaches should be interpreted as a fact that soundscape theory is still under development and, for this reason, the standardisation work should probably take a step back and focus on developing a reference method for comparability among soundscape studies, rather than a single protocol for soundscape data collection. Some attempts have indeed already been made in literature for the different methods proposed in the ISO/TS 12913-2:2018 <span class="citation" data-cites="aletta2019exploring">Jo, Seo, and Jeon (2020)</span>. Neither the standard nor the general soundscape literature has settled on effective methods of analysing and representing the data that results from these protocols. Data visualisations are particularly important for understanding and communicating information as multifaceted as soundscape perception <span class="citation" data-cites="tufte2001visual">(Tufte 2001)</span>. Although it is unlikely that any single method will be sufficient, attempts should be made to both facilitate future advancements in this realm and to develop a first step approach that captures the inherent uncertainty in perception studies, since including uncertainty is considered one of the core principles of good data visualisation <span class="citation" data-cites="Midway2020Principles">(Midway 2020)</span>.</p>
<p>This study thus aims to review the consequences of these methods for larger datasets and provide concrete examples for how soundscapes should be represented. In particular, we aim to strengthen the practices for characterising the soundscape of a location, as a collective perception by the users of the location. We also demonstrate how the progress of these tools from their initial scope (measuring and discussing the individual perception of a soundwalk participant) have not kept up with recent advances and requirements for larger-scale soundscape datasets. We question whether there are some issues related to the data collection instruments and data analysis methods as recommended and examine the results of the model framework and mathematical transformations laid out in the ISO technical specifications to guide the interpretation of the soundscape circumplex.</p>
<p>To examine these tools and the questions raised, we apply them to an existing large scale, real-world dataset of soundscape assessments collected according to the ISO methods. Finally, we propose a more holistic and advanced method of representing soundscapes as a probabilistic distribution of perceptions within the circumplex and provide a toolbox for others to use.</p>
</section>
<section id="sec-current" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> The current ISO 12917 framework</h1>
<p>Although different methods are proposed for data collection in ISO12913 Part 2 <span class="citation" data-cites="ISO12913_2">(ISO 2018)</span>, in the context of this study we focus on the questionnaire-based soundscape assessment (Method A), because it is underpinned by a theoretical relationship among the items of the questionnaire that compose it. The core of this questionnaire is the 8 perceptual attributes (PA) originally derived in <span class="citation" data-cites="Axelsson2010Principal">Axelsson, Nilsson, and Berglund (2010)</span>: pleasant, vibrant (or exciting), eventful, chaotic, annoying, monotonous, uneventful, and calm. In the questionnaire procedure, these PAs are assessed independently of each other, however they are conceptually considered to form a two-dimensional circumplex with <em>{Pleasantness} and </em>Eventfulness* on the x- and y-axis, respectively, where all regions of the space are equally likely to accommodate a given soundscape assessment <span class="citation" data-cites="Aletta2016Soundscape">(Aletta, Kang, and Axelsson 2016)</span>. In <span class="citation" data-cites="Axelsson2010Principal">Axelsson, Nilsson, and Berglund (2010)</span>, a third primary dimension, <em>Familiarity</em> was also found, however this only accounted for 8% of the variance and is typically disregarded as part of the standard circumplex. As will be made clear throughout, the circumplex model has several aspects which make it useful for representing the soundscape perception of a space as a whole.</p>
<section id="coordinate-transformation-into-the-two-primary-dimensions" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="coordinate-transformation-into-the-two-primary-dimensions"><span class="header-section-number">2.1</span> Coordinate transformation into the two primary dimensions</h2>
<p>To facilitate the analysis of the PA responses, the Likert scale responses are coded from 1 (Strongly disagree) to 5 (Strongly agree) as ordinal variables. In order to reduce the 8 PA values into a pair of coordinates which can be plotted on the Pleasant-Eventful axes, Part 3 of ISO 12913 <span class="citation" data-cites="ISO12913_3">(ISO 2019)</span> provides a trigonometric transformation, based on the <img src="https://latex.codecogs.com/png.latex?45%5Ccirc">-relationship between the diagonal axes and the pleasant and eventful axes. This transformation projects the coded values from the individual PAs down onto the primary Pleasantness and Eventfulness dimensions then adds them together to form a single coordinate pair. In theory, this coordinate pair then encapsulates information from all 8 PA dimensions onto a more easily understandable and analysable two dimensions. The ISO coordinates are thus calculated by:</p>
<p><span id="eq-pleasant"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bsplit%7D%0A%20%20%20%20ISO%20Pleasant%20=%20%5B(pleasant%20-%20annoying)%20+%20%5Ccos%2045%5Ccirc%20*%20(calm%20-%20chaotic)%20%5C%5C%20+%20%5Ccos%2045%5Ccirc%20*%20(vibrant%20-%20monotonous)%5D%20*%201/(4+%5Csqrt%7B32)%7D%0A%5Cend%7Bsplit%7D%0A%5Ctag%7B1%7D"></span></p>
<p><span id="eq-eventful"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bsplit%7D%0A%20%20%20%20ISO%20Eventful%20=%20%5B(eventful%20-%20uneventful)%20+%20%5Ccos%2045%5Ccirc%20*%20(chaotic%20-%20calm)%20%5C%5C%20+%20%5Ccos%2045%5Ccirc%20*%20(vibrant%20-%20monotonous)%5D%20*%201/(4+%5Csqrt%7B32)%7D%0A%5Cend%7Bsplit%7D%0A%5Ctag%7B2%7D"></span></p>
<p>where the PAs are arranged around the circumplex as shown in Figure&nbsp;1. The <img src="https://latex.codecogs.com/png.latex?%5Ccos%2045%5Ccirc"> term operates to project the diagonal terms down onto the x and y axes, and the <img src="https://latex.codecogs.com/png.latex?1%20/%20(4%20+%20%5Csqrt%7B32%7D)"> scales the resulting coordinates to the range (-1, 1). The result of this transformation is demonstrated in Figure&nbsp;1. This treatment of the 8 PAs makes several assumptions and inferences about the relationships between the dimensions. As stated in the standard <span class="citation" data-cites="ISO12913_3">(ISO 2019, 5)</span>:</p>
<blockquote class="blockquote">
<p>According to the two-dimensional model, vibrant soundscapes are both pleasant and eventful, chaotic soundscapes are both eventful and unpleasant, monotonous soundscapes are both unpleasant and uneventful, and finally calm soundscapes are both uneventful and pleasant.</p>
</blockquote>
<div id="fig-radar" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-radar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2022-03-16_JASAEL-HowToAnalyseQuantitativeSoundscapeData/figures/Figure1.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-radar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Example of representations of two soundscape assessments. Left: Radar plot of two example perceptual attribute (PA) ratings on the Likert scales (1 to 5). Right: Scatter plot of the same assessments on the soundscape circumplex, transformed according to ISO 12913 Part 3.
</figcaption>
</figure>
</div>
</section>
<section id="summarising-the-soundscape-assessment-of-a-location" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="summarising-the-soundscape-assessment-of-a-location"><span class="header-section-number">2.2</span> Summarising the soundscape assessment of a location</h2>
<p>While the assessment methods available are able to record the soundscape perception of a single individual, and that person’s perception is valid for themselves, it is not appropriate to then state that it is representative of the collective perception of that soundscape. In order to characterise the soundscape of a particular space or time, perceptual responses from multiple people must be collected and subsequently summarised or aggregated to describe the general soundscape of the location. The ISO guidelines stipulate a minimum of 20 participants for a soundwalk, with these broken up into sessions of no more than 5 participants at a time. Part 3 then provides the recommended methods for analysing this data.</p>
<p>Annex A.2 of ISO 12913 Part 3 provides the statistical measures to be used on the raw PA responses. The recommended measure of central tendency is the median, while the recommended measure of dispersion is the range. These are chosen as the data is ordinal by nature, however as will be demonstrated later, they have significant limitations. Although it is unclear, the implied intention is then that the median value of each PA is fed into Equation&nbsp;1 and Equation&nbsp;2 presented above to calculate the ISOPleasant and ISOEventful values, which can then be plotted in a two-dimensional scatter plot. Thus the standard suggests that 1) the projection method equations are not applied to individual responses and 2) only the median assessment of a location should be plotted.</p>
</section>
<section id="limitations-of-the-iso" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="limitations-of-the-iso"><span class="header-section-number">2.3</span> Limitations of the ISO</h2>
<p>How these methods should be applied to represent the soundscape of a location has not been adequately discussed in previous literature, nor sufficiently in Part 3 of ISO 1293 itself. Indeed, in Section A.3, the technical specifications document state that <span class="citation" data-cites="ISO12913_3">(ISO 2019, 5)</span>:</p>
<blockquote class="blockquote">
<p>Results can be reported in a two-dimensional scatter plot with coordinates for the two dimensions ‘pleasantness’ and ‘eventfulness’. The coordinates for ‘pleasantness’ are plotted on the X-axis, and the coordinates for ‘eventfulness’ on the Y-axis. Every data point in the scatter plot represents one investigated site.</p>
</blockquote>
<p>However, it is not made clear whether this single point on the circumplex can be considered to be a realistic representation of the average perception of the acoustic environment. Effectively, there is no representation of dispersion in the soundscape assessment, nor a recommended use of the range that was calculated as part of the analysis recommend in Section A.2 of Part 3 of the ISO 12913. Absent a suggestion from the ISO 12913 for how the range should be used, we therefore apply this analysis to an existing real-world soundscape dataset to determine whether it provides a useful measure of dispersion. Here we use the data contained in the International Soundscape Database (ISD) <span class="citation" data-cites="Mitchell2021International">(Mitchell, Oberman, Aletta, Erfanian, et al. 2021)</span>, which includes 1,300+ individual responses collected across 13 locations in London and Venice, according to the SSID Protocol, which is based on the ISO methods explored in this paper <span class="citation" data-cites="Mitchell2020Protocol">(Mitchell et al. 2020)</span>.</p>
<p>For any large enough sample for a site, the range will always be from 1 to 5, the maximum and minimum available Likert-scale values. We would expect that collecting more data would result in more information or better precision, however the range will always increase as the sample size increases. As an example, within the ISD data, of the 8 PAs collected at 13 locations (for a total of 104 scales), 88% have a range from 1 to 5 and with larger sample sizes at each location, this percentage would only have increased. Using range to analyse the dispersion provides very limited information for comparing the soundscape assessments of different locations, or of a location under different conditions.</p>
<p>Although the range does not appear to be a useful measure of dispersion, the median does provide a useful measure and appropriately functions to describe the central tendency of the soundscape assessment of the sample. However, by stipulating that the median of each PA should be taken prior to applying the circumplex projection, the ISO procedure only allows for plotting a single scatter point in the circumplex for each location and does not allow for plotting individual responses on the circumplex. This limits the possibilities for visualising the general trends in individual perception across the soundscape. Finally, no example or recommendation for how the circumplex scatter plot should be presented is given in the standard.</p>
<p>The instruments described in the ISO 12913 Part 2 <span class="citation" data-cites="ISO12913_2">(ISO 2018)</span> were originally designed primarily for the context of individual or small group assessments. In these scenarios, the focus is on assessing the particular soundscape perception of the person in question. Recent advances in the soundscape approach since the development of the standards have shifted some focus from individual soundscapes to characterising the overall soundscape of public spaces <span class="citation" data-cites="Mitchell2020Protocol">(Mitchell et al. 2020)</span> and to making comparisons between different groups of people <span class="citation" data-cites="Jeon2018cross">(Jeon et al. 2018)</span>. In this context, a consideration of the natural variation in people’s perception and the variation over time of a soundscape must be a core feature of how the soundscape is discussed. Reducing a public space which may have between tens and tens of thousands of people moving through it in a single day down to the mean (or median, or any other single metric) soundscape assessment often dismisses the reality of the space. Likewise, this overall soundscape of a public space cannot be determined through a ten person soundwalk, as there is no guarantee that the sample of people engaged in the soundwalk is representative of the users of the space (in fact it is likely they would not be).</p>
</section>
</section>
<section id="the-way-forward-pleasant-eventful-coordinates-and-probabilistic-soundscape-representation" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> The Way Forward: Pleasant-Eventful Coordinates and Probabilistic Soundscape Representation</h1>
<p>Given the identified issues with the recommended methods for statistical analysis and their shortcomings in representing the variation in perception of the soundscape in a space, how then should we discuss or present the results of these soundscape assessments? Ideally, the method will: 1) take advantage of the circumplex coordinates and their ability to be displayed on a scatter plot and treated as continuous variables, 2) scale from a dataset of twenty responses to thousands of responses, 3) facilitate the comparison of the soundscapes of different locations, conditions, and groups, and 4) encapsulate the nuances and diversity of soundscape perception by representing the distribution of responses.</p>
<p>We therefore present a visualisation in Figure&nbsp;2 of the soundscape assessments of several urban spaces included in the ISD <span class="citation" data-cites="Mitchell2021International">(Mitchell, Oberman, Aletta, Erfanian, et al. 2021)</span> which reflects these goals. The specific locations selected from the ISD are chosen for demonstration only and these methods can be applied to any location. Rather than attempting to represent a single individual’s soundscape or of describing a location’s soundscape as a single average assessment (as in <span class="citation" data-cites="Mitchell2021Investigating">Mitchell, Oberman, Aletta, Kachlicka, et al. (2021)</span>), this representation shows the whole range of perception of the users of the space. First, rather than calculating the median response to each PA in the location, then calculating the circumplex coordinates, the coordinates for each individual response are calculated. This results in a vector of ISOPleasant, ISOEventful values which are continuous variables from -1 to +1 and can be analysed statistically by calculating summary statistics (mean, standard deviation, quantiles, etc.) and through the use of regression modelling, which can often be simpler and more familiar than the recommended methods of analysing ordinal data. This also enables each individual’s response to be placed within the pleasant-eventful space. All of the responses for a location can then be plotted, giving an overall scatter plot for a location, as demonstrated in Figure&nbsp;2 (a).</p>
<div class="cell" data-layout="[[47,-3,50],[50,-3,47]]" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> soundscapy</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-4"></span>
<span id="cb1-5">ssid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> soundscapy.isd.load_isd_dataset()</span>
<span id="cb1-6">ssid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ssid.isd.filter_lockdown()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fmt: skip</span></span>
<span id="cb1-7">ssid, excl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ssid.sspy.validate_dataset(allow_na<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fmt: skip</span></span>
<span id="cb1-8"></span>
<span id="cb1-9">ssid.isd.filter_location_ids([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PancrasLock"</span>]).sspy.jointplot(</span>
<span id="cb1-10">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(a) Example distribution of the soundscape perception of an urban park"</span>,</span>
<span id="cb1-11">    diagonal_lines<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb1-12">    hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>,</span>
<span id="cb1-13">    legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb1-14">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>,</span>
<span id="cb1-15">)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fmt: skip</span></span>
<span id="cb1-16">plt.show()</span>
<span id="cb1-17"></span>
<span id="cb1-18">location <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RegentsParkFields"</span></span>
<span id="cb1-19">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb1-20">ssid.isd.filter_location_ids([location]).sspy.density(</span>
<span id="cb1-21">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(b) Median perception contour and scatter plot of individual assessments</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb1-22">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb1-23">    hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>,</span>
<span id="cb1-24">    legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb1-25">    density_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>,</span>
<span id="cb1-26">    palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dark:gray"</span>,</span>
<span id="cb1-27">)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fmt: skip</span></span>
<span id="cb1-28">plt.show()</span>
<span id="cb1-29"></span>
<span id="cb1-30">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb1-31"></span>
<span id="cb1-32">ssid.isd.filter_location_ids([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CamdenTown"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RussellSq"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PancrasLock"</span>]).sspy.density(</span>
<span id="cb1-33">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(c) Comparison of the soundscapes of three urban spaces</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb1-34">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb1-35">    hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>,</span>
<span id="cb1-36">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb1-37">    palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"husl"</span>,</span>
<span id="cb1-38">    legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb1-39">    density_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>,</span>
<span id="cb1-40">)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fmt: skip</span></span>
<span id="cb1-41">plt.show()</span>
<span id="cb1-42"></span>
<span id="cb1-43">ssid[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dBLevel"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.cut(</span>
<span id="cb1-44">    ssid[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LAeq_L(A)(dB(SPL))"</span>],</span>
<span id="cb1-45">    bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">63</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>),</span>
<span id="cb1-46">    labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Under 63dB"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Over 63dB"</span>),</span>
<span id="cb1-47">    precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb1-48">)</span>
<span id="cb1-49"></span>
<span id="cb1-50">ssid.sspy.jointplot(</span>
<span id="cb1-51">    marginal_kind<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kde"</span>,</span>
<span id="cb1-52">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(d) Soundscape perception as a function of sound level"</span>,</span>
<span id="cb1-53">    diagonal_lines<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb1-54">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb1-55">    palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"colorblind"</span>,</span>
<span id="cb1-56">    hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dBLevel"</span>,</span>
<span id="cb1-57">    density_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>,</span>
<span id="cb1-58">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb1-59">    legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#</span></span>
<span id="cb1-60">    marginal_kws<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"common_norm"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>},</span>
<span id="cb1-61">)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fmt: skip</span></span>
<span id="cb1-62">plt.show()</span>
<span id="cb1-63"></span>
<span id="cb1-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.tight_layout()</span></span></code></pre></div>
</details>
<div id="fig-circ" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-circ-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-circ" style="flex-basis: 47.0%;justify-content: flex-start;">
<div id="fig-circ-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-circ-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2022-03-16_JASAEL-HowToAnalyseQuantitativeSoundscapeData/paper_files/figure-html/fig-circ-output-1.png" data-ref-parent="fig-circ" width="609" height="605" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-circ-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Example distribution of the soundscape perception of an urban park
</figcaption>
</figure>
</div>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 3.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-circ" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-circ-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-circ-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2022-03-16_JASAEL-HowToAnalyseQuantitativeSoundscapeData/paper_files/figure-html/fig-circ-output-2.png" data-ref-parent="fig-circ" width="636" height="628" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-circ-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Median perception contour and scatter plot of individual assessments
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-circ" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-circ-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-circ-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2022-03-16_JASAEL-HowToAnalyseQuantitativeSoundscapeData/paper_files/figure-html/fig-circ-output-3.png" data-ref-parent="fig-circ" width="619" height="628" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-circ-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Comparison of the soundscapes of three urban spaces
</figcaption>
</figure>
</div>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 3.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-circ" style="flex-basis: 47.0%;justify-content: flex-start;">
<div id="fig-circ-4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-circ-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2022-03-16_JASAEL-HowToAnalyseQuantitativeSoundscapeData/paper_files/figure-html/fig-circ-output-4.png" data-ref-parent="fig-circ" width="604" height="605" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-circ-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) Soundscape perception as a function of sound level
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-circ-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: A demonstration of some use cases of representing soundscape perception as probabilistic distributions. Data is drawn from the International Soundscape Database (ISD) and is used for demonstration only. (a) Demonstrates a high level of detail for presenting the bivariate distribution of soundscape perception in a park (Russell Square in London). (b) Simplified view of the distribution using the 50th percentile contour. The assessments impacted by a series of helicopter fly-overs are made obvious in the chaotic quadrant. (c) A comparison of three popular public spaces in London. Their overlapping regions can reveal when and how their soundscapes may be similar. (d) A comparison across the full ISD for soundscape perception at <img src="https://latex.codecogs.com/png.latex?%3C65%20dB%20L_%7BAeq%7D"> and <img src="https://latex.codecogs.com/png.latex?%3E%2065%20dBA">. The introduction of other acoustic, environmental, and contextual data can reveal new and complex relationships with the soundscape perception.
</figcaption>
</figure>
</div>
</div>
<p>Once these individual responses are plotted, we then overlay a heatmap of the bivariate distribution (with isodensity curves for each decile) and marginal distribution plots<sup>1</sup>. In this way, three primary characteristics of the soundscape perception can be seen:</p>
<ol type="1">
<li><p>The distribution across both pleasantness and eventfulness, including the central tendency, the dispersion, and any skewness in the response;</p></li>
<li><p>The general shape of the soundscape within the space - in this case, Russell Sq is almost entirely in the pleasant half but is split relatively evenly across the eventfulness space, meaning while it is perceived as generally pleasant, it is not strongly calm or vibrant;</p></li>
<li><p>The degree of agreement about the soundscape perception among the sample - there appears to be a relatively high agreement about the character of Russell Sq, as demonstrated by the compactness of the distribution, but this is not the case for every location.</p></li>
</ol>
<p>Figure&nbsp;2 (a) includes several in-depth visualisations of the distribution of soundscape assessments, however the detail included can make further analysis difficult. In particular, a decile heatmap is so visually busy that, in our experience, it is not possible to plot more than one soundscape distribution at a time without the figure becoming overly busy. It also can make it difficult to truly grasp point 2, the general shape of the soundscape. To facilitate this, the soundscape can be represented by its 50th percentile contour, as demonstrated in Figure&nbsp;2 (b) where the shaded portion contains 50% of the responses. This simplified view of the distribution presents several advantages, as is demonstrated in Figure&nbsp;2 (c) and Figure&nbsp;2 (d) and takes inspiration from the recommendation in the ISO standard to use the median as a summary statistic. In our testing, the 50th percentile contour has proved useful, clear, and compact, however this should not be taken as the definitive correct percentile cutoff. Further work will need to be done to validate the precise presentation.</p>
<p>When visualised this way, it is possible to identify outliers and responses which are the result of anomalous sound events. For instance if during a survey session at a calm park, a fleet of helicopters flies overhead, driving the participants to respond that the soundscape is highly chaotic, we would see a group of scatter points in the chaotic quadrant which appear obviously outside the general pattern of responses. Often, these responses would be entirely discarded as outliers or the surveys and soundwalks would be halted entirely – ignoring what is in fact a significant impact on that location, its soundscape, and how useful it may be for the community. Alternatively, they would be naively included within the statistical analysis, significantly impacting the central tendency and dispersion metrics (i.e.&nbsp;median and range) without consideration for the context. This is the situation shown in Figure&nbsp;2 (b) where it is obvious that there is strong agreement that Regents Park Fields is highly pleasant and calm, however we can see numerous responses which assessed it as highly chaotic. These responses were taken when a series of military helicopter flyovers drastically changed the sound environment of the space for several minutes.</p>
<p>Figure&nbsp;2 (c) demonstrates how this simplified 50th percentile contour representation makes it possible to compare the soundscape of several locations in a sophisticated way. The soundscape assessments of three urban spaces, Camden Town, Pancras Lock, and Russell Square, are shown overlaid with each other. We can see that Camden Town, a busy and crowded street corner with high levels of traffic noise and amplified music, is generally perceived as chaotic, but the median contour shape which characterises it also crosses over into the vibrant quadrant. We can also see that, for a part of the sample, Russell Square and Pancras Lock are both perceived as similarly pleasant, however some portion of the responses perceived Pancras Lock as being somewhat chaotic and annoying. This kind of visualisation can highlight these similarities between the soundscapes in the locations and identify how they differ. From here, further investigation could lead us to answer what factors led to those people perceiving the location as unpleasant, and what similarities the soundscape of Pancras Lock has with Russell Square that could perhaps be enhanced to increase the proportion of people perceiving it as more pleasant.</p>
<p>In addition to solely analysing the distributions of the perceptual responses themselves, this method can also be combined with other acoustic, environmental, and contextual data. The final example, in Figure&nbsp;2 (d) demonstrates how this method can better demonstrate the complex relationships between acoustic features of the sound environment and the soundscape perception. The data in the ISD includes ~30-s-long binaural audio recordings taken while each participant was responding to the soundscape survey, providing an indication of the exact sound environment they were exposed to. For Figure&nbsp;2 (d) the entire dataset of 1,338 responses at all 13 locations has been split according to the analysis of these recordings giving a set of less than 65 dB <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"> and a set of more than 65 dB. The bivariate distributions of these two conditions are then plotted.</p>
<p>By presenting soundscape perception as a bivariate distributional shape on the circumplex, practitioners are obligated to address two key aspects of perception that are too often ignored: the distribution of potential responses and the eventful dimension. The array of potential responses to an environment is a crucial factor in assessing the successful design of a space and represents the reality of perception. There is no single perceptual outcome of an environment; it will always include some randomness inherent in human perception and this should be reflected in how we present soundscape assessments. Similarly, the eventful dimension is crucial to understanding how an environment is perceived and can have important impacts on the health and well-being of the users. Recent evidence also suggests that there is a more direct relationship between acoustic characteristics and the perception of eventfulness, while pleasantness is more dependent on context <span class="citation" data-cites="Mitchell2021Investigating">(Mitchell, Oberman, Aletta, Kachlicka, et al. 2021)</span>. Studies that explore the correlations between acoustic features and annoyance (or pleasantness) without considering eventfulness are perhaps missing the most direct effect of the acoustic features.</p>
</section>
<section id="making-use-of-the-soundscape-circumplex" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Making Use of the Soundscape Circumplex</h1>
<p>There are various potential methods for integrating the probabilistic soundscape approach into a design and intervention setting. Representing the soundscape as a shape within the circumplex provides flexibility in setting design goals for a space. Not all spaces can or should have the same soundscape and soundscapes should be treated as dynamic, not static; identifying and creating an appropriate soundscape for the particular use case of a space is crucial to guiding its design. Proper forward-looking design of a soundscape would involve defining the desired shape and distribution of perceptions in the space. This can be achieved by drawing the desired shape in the circumplex and testing interventions which will bring the existing soundscape closer to the desired perception. A soundscape may need to be perceived as vibrant during the day and calm for some portion of the evening, meaning the desired shape should primarily sit within the vibrant quadrant but have some overlap into calm. This also enables designers to recognise the limitations of their environment and acknowledge that it is not always possible to transform a highly chaotic soundscape into a calm one. In these cases, instead the focus should be placed on shifting the distribution to some degree in a positive direction. The most sophisticated method of setting design goals is therefore to identify the desired shape which represents the variety of desired outcomes, and focus on designs and interventions which are most successful in matching the predicted outcome with that goal.</p>
<p>Although the visualisations shown in Figure&nbsp;2 are a powerful tool for viewing, analysing, and discussing the multi-dimensional aspects of soundscape perception, there are certainly cases where simpler metrics are needed to aid discussion and to set design goals. For this, the underlying process of calculating the ISOPleasant and ISOEventful coordinates for each individual response is still the first step in analysing the quantitative soundscape data. These sets of coordinates can then be analysed and summarised in various ways. One approach which takes inspiration from noise annoyance <span class="citation" data-cites="ISO15666">(ISO/TS 15666:2021 2021)</span>, is to discuss the “percent of people likely to perceive” a soundscape as pleasant, vibrant, etc. when it is necessary to use numerical descriptions. In this way, a numerical design goal could also be set as e.g.&nbsp;‘the soundscape should be likely to be perceived as pleasant by at least 75% of users’ or the result of an intervention presented as e.g.&nbsp;‘the likelihood of the soundscape being perceived as calm increased from 30% to 55%’. These numbers can be drawn from either actual surveys or from the results of predictive models.</p>
<p>Although acknowledging the distribution of responses is crucial, it is sometimes necessary to summarise locations down to a single point to compare many different locations and to easily investigate how the soundscape assessment has generally changed over time. For this purpose, the mean of the ISOPleasant and ISOEventful values across all respondents is calculated to result in a single coordinate point per location. This clearly mirrors the original intent of the coordinate transformation presented in the ISO, but by applying the transformation first to each individual assessment then calculating the mean value, it maintains a direct link to the distributions shown in Figure&nbsp;2. An example plot using the mean response of each location to compare many locations and to demonstrate change in soundscape perception can be found in Figure 5 of <span class="citation" data-cites="Mitchell2021Investigating">Mitchell, Oberman, Aletta, Kachlicka, et al. (2021)</span>. The key to all of these analysis methods, whether they be the distributional plots shown in Figure&nbsp;2, the numerical summaries, or the use of other standard statistical analyses is treating the soundscape of the space or group as a collective perception as expressed by a vector of individual circumplex coordinates.</p>
<p>Finally, the primary concern addressed by this method is the analysis of larger soundscape datasets, compared to what is suggested in the standard. This is necessary in order to statistically describe the groups or sub-groups being investigated, and is typically taken to need a minimum of ~30 responses per group (although the full dataset, made up of many groups and locations may have many more responses in total, as in the ISD) <span class="citation" data-cites="Hong2015Influence PuyanaRomero2016Modelling">(e.g. Hong and Jeon 2015; Puyana Romero et al. 2016)</span>. It is unlikely that the bivariate distributions plots shown are appropriate for small datasets. However, the process of calculating the ISO coordinates for each individual response and treating this as a set of continuous values to subject to other statistical analysis holds for all sample sizes. Pleasant-eventful scatterplots are still useful for comparing differences in individual responses and appropriate methods of summarising small sample data should be explored (such as the univariate scatterplots described in <span class="citation" data-cites="Weissgerber2015Bar">Weissgerber et al. (2015)</span>).</p>
<section id="limitations-of-the-circumplex-and-quantitative-analysis" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="limitations-of-the-circumplex-and-quantitative-analysis"><span class="header-section-number">4.1</span> Limitations of the circumplex and quantitative analysis</h2>
<p>The method presented here is a solution for representing the soundscape of a space, which requires considering the perception of many people, but it is important to note that this is only one (very important) goal of the soundscape approach. Psychological and sociological investigations of people’s relationship to their sound environment and the interactions between social contexts and individual perception are a crucial aspect of the field for which this approach would likely not be sufficient <span class="citation" data-cites="Bild2018Public">(Bild et al. 2018)</span>. Open-response questions, structured interviews, and mixed-methods studies can provide additional insight into how people experience their environment and should be considered alongside or preceding this focus on how a space is likely to be perceived on a larger scale.</p>
<p>These other approaches are not in opposition to the methods proposed here, but instead further expand our view. The circumplex is a limited view of soundscape perception (this is made obvious by the fact that it excludes the third component, <em>familiarity</em>, identified in <span class="citation" data-cites="Axelsson2010Principal">Axelsson, Nilsson, and Berglund (2010)</span>) but it is an exceptionally rich tool for dealing with the two primary aspects of soundscape perception which can readily expand the much more limited view provided by existing noise and annoyance assessment tools. Aspects of the psychological and sociological emphasis can also be integrated into a circumplex-focused approach, as demonstrated in <span class="citation" data-cites="Erfanian2021Psychological">Erfanian et al. (2021)</span>, where personal factors such as age, gender, and psychological well-being were analysed in terms of how they mediated the ISOPleasant and ISOEventful outcomes.</p>
<p>There has been some discussion regarding the interdependence of the PAs and the strict validity of the 90<img src="https://latex.codecogs.com/png.latex?%5Ccirc"> and 45<img src="https://latex.codecogs.com/png.latex?%5Ccirc"> relationships between the attributes <span class="citation" data-cites="Lionello2021Introducing">(Lionello et al. 2021)</span>. Further work has indicated that the scaling between the attributes may vary, but the underlying relationships hold. It is for this reason that we have taken the coordinate projection as the starting point of this critique. It should also be noted that the particular PA descriptors used in ISO 12913 are intended for outdoor environments and should not be directly applied to indoor spaces. However, a proposed set of descriptors for some indoor environments has been derived which further confirms the validity of the circumplex relationships <span class="citation" data-cites="Torresin2020Indoor">(Torresin et al. 2020)</span>. The methods proposed here should be directly applicable to indoor spaces by using the comfort/content descriptors as well as to any other translations of soundscape descriptors into other languages <span class="citation" data-cites="Aletta2020Soundscape">(Aletta et al. 2020)</span> as long as the dimensional relationships of the circumplex are maintained.</p>
</section>
</section>
<section id="conclusions" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conclusions</h1>
<p>Soundscape studies have been steadily growing as a research field over the past three decades. Their relevance for the planning and design of urban spaces is now generally acknowledged by both the academic and practitioners’ communities. Yet, for their contribution in shaping better environments to be meaningful, it is necessary to agree on common methodological approaches and techniques to analyse and present standardised soundscape data. Therefore, the general goal of this work is to consider some of the questions that may still have been left unanswered by the ISO 12913 series when it comes to optimal ways to analyse and represent soundscape data coming from the ISO standardised protocols. As a result, we propose a method for presenting the results of standardised assessments as a distribution of soundscape perception within the circumplex space. This method provides an opportunity to conduct a nuanced discussion of soundscape perception which considers the variety of individual responses. The tools for generating these circumplex visualisations are made openly available as well. This shift is part of a move towards a more holistic approach to urban noise and to integrating the soundscape approach into urban design and regulations.</p>
</section>


<section id="references" class="level1 unnumbered">




</section>


<div id="quarto-appendix" class="default"><section id="data-and-code-availability" class="level1 unnumbered appendix"><h2 class="anchored quarto-appendix-heading">Data and Code Availability</h2><div class="quarto-appendix-contents">

<p>The data used in this study are openly available as v0.2.3 of the International Soundscape Database (ISD) at <a href="https://zenodo.org/record/5578572">https://zenodo.org/record/5578572</a>. A library of python functions for producing the type of plots presented (using the seaborn plotting library <span class="citation" data-cites="Waskom2021">(Waskom 2021)</span>) and an interactive Jupyter notebook which provides a tutorial for using this code, working with the ISD data, and recreating the figures of this paper has been made available as part of the ISD.</p>
</div></section><section id="acknowledgements" class="level1 unnumbered appendix"><h2 class="anchored quarto-appendix-heading">Acknowledgements</h2><div class="quarto-appendix-contents">

<p>This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (grant agreement No.&nbsp;740696, project title: Soundscape Indices - SSID). We would like to acknowledge Matteo Lionello for the helpful discussions, and (in alphabetical order) Mercede Erfanian, Magdalena Kachlicka, and Tin Oberman for the helpful discussions and the data collection support.</p>
</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-aletta2019exploring" class="csl-entry">
Aletta, Francesco, Claudia Guattari, Luca Evangelisti, Francesco Asdrubali, Tin Oberman, and Jian Kang. 2019. <span>“Exploring the Compatibility of <span>‘Method a’</span> and <span>‘Method b’</span> Data Collection Protocols Reported in the ISO/TS 12913-2: 2018 for Urban Soundscape via a Soundwalk.”</span> <em>Applied Acoustics</em> 155: 190–203.
</div>
<div id="ref-Aletta2016Soundscape" class="csl-entry">
Aletta, Francesco, Jian Kang, and Östen Axelsson. 2016. <span>“<span class="nocase">Soundscape descriptors and a conceptual framework for developing predictive soundscape models</span>.”</span> <em>Landscape and Urban Planning</em> 149 (July): 65–74. <a href="https://doi.org/10.1016/j.landurbplan.2016.02.001">https://doi.org/10.1016/j.landurbplan.2016.02.001</a>.
</div>
<div id="ref-Aletta2020Soundscape" class="csl-entry">
Aletta, Francesco, Tin Oberman, Östen Axelsson, Hui Xie, Yuan Zhang, Siu-Kit Lau, Shiu-Keung Tang, et al. 2020. <span>“Soundscape Assessment: Towards a Validated Translation of Perceptual Attributes in Different Languages.”</span> In <em>INTER-NOISE and NOISE-CON Congress and Conference Proceedings</em>, 261:3137–46. 3. Institute of Noise Control Engineering.
</div>
<div id="ref-Axelsson2019editorial" class="csl-entry">
Axelsson, Östen, Catherine Guastavino, and Sarah R. Payne. 2019. <span>“Editorial: Soundscape Assessment.”</span> <em>Frontiers in Psychology</em> 10: 2514. <a href="https://doi.org/10.3389/fpsyg.2019.02514">https://doi.org/10.3389/fpsyg.2019.02514</a>.
</div>
<div id="ref-Axelsson2010Principal" class="csl-entry">
Axelsson, Östen, Mats E. Nilsson, and Birgitta Berglund. 2010. <span>“<span class="nocase">A principal components model of soundscape perception</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 128 (5): 2836–46. <a href="https://doi.org/10.1121/1.3493436">https://doi.org/10.1121/1.3493436</a>.
</div>
<div id="ref-Bild2018Public" class="csl-entry">
Bild, Edda, Karin Pfeffer, Matt Coler, Ori Rubin, and Luca Bertolini. 2018. <span>“<span class="nocase">Public Space Users’ Soundscape Evaluations in Relation to Their Activities. An Amsterdam-Based Study</span>.”</span> <em>Frontiers in Psychology</em> 9: 1593. <a href="https://doi.org/10.3389/fpsyg.2018.01593">https://doi.org/10.3389/fpsyg.2018.01593</a>.
</div>
<div id="ref-Erfanian2021Psychological" class="csl-entry">
Erfanian, Mercede, Andrew Mitchell, Francesco Aletta, and Jian Kang. 2021. <span>“Psychological Well-Being and Demographic Factors Can Mediate Soundscape Pleasantness and Eventfulness: A Large Sample Study.”</span> <em>Journal of Environmental Psychology</em> 77 (October): 101660. <a href="https://doi.org/10.1016/j.jenvp.2021.101660">https://doi.org/10.1016/j.jenvp.2021.101660</a>.
</div>
<div id="ref-Hong2015Influence" class="csl-entry">
Hong, Joo Young, and Jin Yong Jeon. 2015. <span>“Influence of Urban Contexts on Soundscape Perceptions: A Structural Equation Modeling Approach.”</span> <em>Landscape and Urban Planning</em> 141 (September): 78–87. <a href="https://doi.org/10.1016/j.landurbplan.2015.05.004">https://doi.org/10.1016/j.landurbplan.2015.05.004</a>.
</div>
<div id="ref-ISO12913_1" class="csl-entry">
ISO. 2014. <span>“<span class="nocase">ISO 12913-1:2014 Acoustics - Soundscape - Part 1: Definition and conceptual framework</span>.”</span> Geneva: <span>International Organisation for Standardisation</span>; ISO Geneva.
</div>
<div id="ref-ISO12913_2" class="csl-entry">
———. 2018. <span>“<span class="nocase">ISO/TS 12913-2:2018 Acoustics - Soundscape - Part 2: Data collection and reporting requirements</span>.”</span> Geneva: <span>International Organisation for Standardisation</span>; ISO Geneva.
</div>
<div id="ref-ISO12913_3" class="csl-entry">
———. 2019. <span>“<span class="nocase">ISO/TS 12913-3:2019 Acoustics - Soundscape - Part 3: Data analysis</span>.”</span> <span>International Organisation for Standardisation</span>. <a href="https://bsol.bsigroup.com/Bibliographic/BibliographicInfoData/000000000030386393">https://bsol.bsigroup.com/Bibliographic/BibliographicInfoData/000000000030386393</a>.
</div>
<div id="ref-ISO15666" class="csl-entry">
ISO/TS 15666:2021. 2021. <span>“<span>Acoustics</span> – Assessment of Noise Annoyance by Means of Social and Socio-Acoustic Surveys.”</span>
</div>
<div id="ref-Jeon2018cross" class="csl-entry">
Jeon, Jin Yong, Joo Young Hong, Catherine Lavandier, Jeanne Lafon, Östen Axelsson, and Malin Hurtig. 2018. <span>“<span class="nocase">A cross-national comparison in assessment of urban park soundscapes in France, Korea, and Sweden through laboratory experiments</span>.”</span> <em>Applied Acoustics</em>. <a href="https://doi.org/10.1016/j.apacoust.2017.12.016">https://doi.org/10.1016/j.apacoust.2017.12.016</a>.
</div>
<div id="ref-jo2020soundscape" class="csl-entry">
Jo, Hyun In, Rosa Seo, and Jin Yong Jeon. 2020. <span>“Soundscape Assessment Methods: Compatibility of Questionnaires and Narrative Interview Based on ISO 12913-2.”</span> In <em>INTER-NOISE and NOISE-CON Congress and Conference Proceedings</em>, 261:3509–18. 3. Institute of Noise Control Engineering.
</div>
<div id="ref-kang2016ten" class="csl-entry">
Kang, Jian, Francesco Aletta, Truls T Gjestland, Lex A Brown, Dick Botteldooren, Brigitte Schulte-Fortkamp, Peter Lercher, et al. 2016. <span>“Ten Questions on the Soundscapes of the Built Environment.”</span> <em>Building and Environment</em> 108: 284–94.
</div>
<div id="ref-Lionello2021Introducing" class="csl-entry">
Lionello, Matteo, Francesco Aletta, Andrew Mitchell, and Jian Kang. 2021. <span>“Introducing a Method for Intervals Correction on Multiple Likert Scales: A Case Study on an Urban Soundscape Data Collection Instrument.”</span> <em>Frontiers in Psychology</em> 11: 3943. <a href="https://doi.org/10.3389/fpsyg.2020.602831">https://doi.org/10.3389/fpsyg.2020.602831</a>.
</div>
<div id="ref-Midway2020Principles" class="csl-entry">
Midway, Stephen R. 2020. <span>“Principles of Effective Data Visualization.”</span> <em>Patterns</em> 1 (9): 100141. https://doi.org/<a href="https://doi.org/10.1016/j.patter.2020.100141">https://doi.org/10.1016/j.patter.2020.100141</a>.
</div>
<div id="ref-Mitchell2020Protocol" class="csl-entry">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. 2020. <span>“<span class="nocase">The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys—Questionnaires with Acoustical and Contextual Information</span>.”</span> <em>Applied Sciences</em> 10 (7): 2397. <a href="https://doi.org/10.3390/app10072397">https://doi.org/10.3390/app10072397</a>.
</div>
<div id="ref-Mitchell2021International" class="csl-entry">
———. 2021. <span>“<span class="nocase">The International Soundscape Database: An integrated multimedia database of urban soundscape surveys – questionnaires with acoustical and contextual information</span>.”</span> Zenodo. <a href="https://doi.org/10.5281/zenodo.5578572">https://doi.org/10.5281/zenodo.5578572</a>.
</div>
<div id="ref-Mitchell2021Investigating" class="csl-entry">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Magdalena Kachlicka, Matteo Lionello, Mercede Erfanian, and Jian Kang. 2021. <span>“Investigating Urban Soundscapes of the <span>COVID</span>-19 Lockdown: A Predictive Soundscape Modeling Approach.”</span> <em>The Journal of the Acoustical Society of America</em> 150 (6): 4474–88. <a href="https://doi.org/10.1121/10.0008928">https://doi.org/10.1121/10.0008928</a>.
</div>
<div id="ref-PuyanaRomero2016Modelling" class="csl-entry">
Puyana Romero, Virginia, Luigi Maffei, Giovanni Brambilla, and Giuseppe Ciaburro. 2016. <span>“Modelling the Soundscape Quality of Urban Waterfronts by Artificial Neural Networks.”</span> <em>Applied Acoustics</em> 111 (October): 121–28. <a href="https://doi.org/10.1016/j.apacoust.2016.04.019">https://doi.org/10.1016/j.apacoust.2016.04.019</a>.
</div>
<div id="ref-SoundscapeOursonicSchafer" class="csl-entry">
Schafer, R. Murray. 1977. <em><span class="nocase">The Soundscape: Our sonic environment and the tuning of the world</span></em>.
</div>
<div id="ref-silverman2018density" class="csl-entry">
Silverman, Bernard W. 2018. <em>Density Estimation for Statistics and Data Analysis</em>. Routledge.
</div>
<div id="ref-Southworth1969sonic" class="csl-entry">
Southworth, Michael. 1969. <span>“<span class="nocase">The sonic environment of cities</span>.”</span> <em>Environment and Behavior</em>. <a href="https://doi.org/10.1177/001391656900100104">https://doi.org/10.1177/001391656900100104</a>.
</div>
<div id="ref-Torresin2020Indoor" class="csl-entry">
Torresin, Simone, Rossano Albatici, Francesco Aletta, Francesco Babich, Tin Oberman, Stefano Siboni, and Jian Kang. 2020. <span>“<span class="nocase">Indoor soundscape assessment: A principal components model of acoustic perception in residential buildings</span>.”</span> <em>Building and Environment</em> 182 (September): 107152. <a href="https://doi.org/10.1016/j.buildenv.2020.107152">https://doi.org/10.1016/j.buildenv.2020.107152</a>.
</div>
<div id="ref-tufte2001visual" class="csl-entry">
Tufte, Edward. 2001. <span>“The Visual Display of Quantitative Information.”</span> Cheshire: Graphic Press.–2001.–213 p.
</div>
<div id="ref-Waskom2021" class="csl-entry">
Waskom, Michael L. 2021. <span>“Seaborn: Statistical Data Visualization.”</span> <em>Journal of Open Source Software</em> 6 (60): 3021. <a href="https://doi.org/10.21105/joss.03021">https://doi.org/10.21105/joss.03021</a>.
</div>
<div id="ref-Weissgerber2015Bar" class="csl-entry">
Weissgerber, Tracey L., Natasa M. Milic, Stacey J. Winham, and Vesna D. Garovic. 2015. <span>“Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm.”</span> <em>PLOS Biology</em> 13 (4): 1–10. <a href="https://doi.org/10.1371/journal.pbio.1002128">https://doi.org/10.1371/journal.pbio.1002128</a>.
</div>
<div id="ref-westerkamp2002linking" class="csl-entry">
Westerkamp, Hildegard. 2002. <span>“Linking Soundscape Composition and Acoustic Ecology.”</span> <em>Organised Sound</em> 7 (1): 51–56.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The specifics of the bivariate kernel density estimation <span class="citation" data-cites="silverman2018density">(Silverman 2018)</span> are beyond the scope of this discussion and the most appropriate hyperparameters (e.g.&nbsp;estimation methods, smoothing factors) for this visualisation may need to be further explored. These parameters will likely depend on the specific dataset used.↩︎</p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{mitchell2022,
  author = {Mitchell, Andrew and Aletta, Francesco and Kang, Jian},
  title = {How to Analyse and Represent Quantitative Soundscape Data},
  journal = {JASA Express Letters},
  volume = {2},
  number = {3},
  pages = {037201},
  date = {2022-03-16},
  url = {https://pubs.aip.org/asa/jel/article/2/3/037201/2845750},
  doi = {10.1121/10.0009794},
  langid = {en},
  abstract = {This study first examines the methods presented in ISO
    12913 for analysing and representing soundscape data by applying
    them to a large existing database of soundscape assessments. The key
    issue identified is the inability of the standard methods to
    summarise the soundscape of locations and groups. The presented
    solution inherently considers the variety of responses within a
    group and provides an open-source visualisation tool to facilitate a
    nuanced approach to soundscape assessment and design. Several
    demonstrations of the soundscape distribution of urban spaces are
    presented, along with proposals for how this approach can be used
    and developed.}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-mitchell2022" class="csl-entry quarto-appendix-citeas">
Mitchell, Andrew, Francesco Aletta, and Jian Kang. 2022. <span>“How to
Analyse and Represent Quantitative Soundscape Data.”</span> <em>JASA
Express Letters</em> 2 (March): 037201. <a href="https://doi.org/10.1121/10.0009794">https://doi.org/10.1121/10.0009794</a>.
</div></div></section></div> ]]></description>
  <category>journal-articles</category>
  <guid>https://drandrewmitchell.com/research/papers/2022-03-16_JASAEL-HowToAnalyseQuantitativeSoundscapeData/paper.html</guid>
  <pubDate>Wed, 16 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Investigating urban soundscapes of the COVID-19 lockdown: A predictive soundscape modeling approach</title>
  <dc:creator>Andrew Mitchell</dc:creator>
  <dc:creator>Tin Oberman</dc:creator>
  <dc:creator>Francesco Aletta</dc:creator>
  <dc:creator>Magdalena Kachlicka</dc:creator>
  <dc:creator>Matteo Lionello</dc:creator>
  <dc:creator>Mercede Erfanian</dc:creator>
  <dc:creator>Jian Kang</dc:creator>
  <link>https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/JASA-Lockdown.html</link>
  <description><![CDATA[ 





<section id="sec-intro" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-intro"><span class="header-section-number">1</span> Introduction</h2>
<p>The global emergency caused by the COVID-19 pandemic in early 2020 required national lockdown measures across the world, primarily targeting human activity. In the United Kingdom, construction and transport were allowed to continue, but a decrease in activity was observed <span class="citation" data-cites="Hadjidemetriou2020impact">(Hadjidemetriou et al. 2020)</span>. In other countries, such as Italy, the restrictions were more severe and even included limiting people’s movement to a certain radius from their place of residence <span class="citation" data-cites="Ren2020Pandemic">(Ren 2020)</span>. The explorations in environmental acoustics of lockdown conditions across the world have revealed various degrees of impact on the acoustic environment, with researchers reporting reductions in noise levels affecting the population at the scale of urban agglomerations such as Ruhr Area in Germany <span class="citation" data-cites="Hornberg2021Impact">(Hornberg et al. 2021)</span> and conurbations in the south of France <span class="citation" data-cites="Munoz2020Lockdown">(Munoz et al. 2020)</span>. Impacts have also been reported at a scale of a multimillion city such as Madrid <span class="citation" data-cites="Asensio2020Changes">(Asensio, Pavón, and Arcas 2020)</span> or Barcelona <span class="citation" data-cites="BonetSola2021Soundscape">(Bonet-Solà et al. 2021)</span> as well as at a more local, city-center or even public space-scale in cities such as Stockholm <span class="citation" data-cites="Rumpler2021Noise">(Rumpler, Venkataraman, and Göransson 2021)</span>, London <span class="citation" data-cites="Aletta2020Assessing">(Aletta et al. 2020)</span>, Girona <span class="citation" data-cites="AlsinaPages2021Changes">(Alsina-Pagès, Bergadà, and Martı́nez-Suquı́a 2021)</span>, or Granada <span class="citation" data-cites="VidaManzano2021sound">(Vida Manzano et al. 2021)</span>. In general, these studies have demonstrated a decrease in urban noise levels and indicated a difference in the amount the level decreased depending on the type of space investigated (e.g.&nbsp;parks, urban squares, etc.) and the type of human activity characteristic for the space, with higher reductions in places typically associated with human sounds and activities such as shopping and tourism.</p>
<p>Those studies were mostly focused around the <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, as well as a standardization approach to reporting subsequent changes in soundscape proposed by <span class="citation" data-cites="Asensio2020Taxonomy">Asensio et al. (2020)</span>. They were not able to reveal the perceptual impact of such conditions in public spaces also because of: 1) the lack of subjective data for the exact or comparable locations in previous years; and 2) the lack of participants present in public spaces during the lockdown, hence the inability to collect soundscape data in situ. <span class="citation" data-cites="Munoz2020Lockdown">Munoz et al. (2020)</span> combined noise measurements with an online questionnaire deployed to residents, some of which were residing in the areas covered by the noise monitoring network available. The participants were asked to recall how their lockdown area sounded before and during the first lockdown in 2020 and to describe the perceived change. They observed a consistent reduction in levels, followed by the perceived reduction of transport sounds (air and road) and an increase of natural sounds, while the resulting environment was described as pleasant, calm, and peaceful. By combining field recordings and focus groups, <span class="citation" data-cites="Sakagami2020How">Sakagami (2020)</span> and <span class="citation" data-cites="Lenzi2021Soundscape">Lenzi, Sádaba, and Lindborg (2021)</span> observed changes in the sound source composition and the affective quality of soundscape in a residential area in Kobe, Japan and a public space in Getxa, Spain, respectively, during the different stages of the lockdown period. Following the easing of lockdown measures, a decrease in animal and traffic sounds was observed in Kobe, while an increase in eventfulness, loudness, and presence of human sound sources, followed by a decrease in pleasantness, was shown in Getxa.</p>
<p><span class="citation" data-cites="Aletta2020Assessing">Aletta et al. (2020)</span> explored the impacts of the COVID-19 lockdowns on the acoustic environment in London in particular, through many short-term (30s) binaural recordings. This study revealed that average reductions in the various locations considered ranged from 10.7 dB (<img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">) to 1.2 dB, with an overall average reduction of 5.4 dB. This metric-reporting focused approach left the following research questions unanswered: how would people have perceived these spaces as a result of this change in acoustic environment (RQ1), and would these sound level reductions result in improvements to the soundscape of the spaces (RQ2)? The 1st research question (RQ1), addressing the perceptual effect of the change in urban soundscape induced by the lockdowns, can be further broken down into the following questions: how was the sound source composition influenced by the change; how would the affective response to the acoustic environment in lockdowns change; and could this demonstrate the effect of human activities on the perception of an acoustic environment in general?</p>
<p>These questions arise out of the soundscape approach, which is characterized by prioritizing the perceptual effect of an acoustic environment by taking into account the interaction of sound sources, context, and the person perceiving it <span class="citation" data-cites="ISO12913Part1 Truax1999Handbook">(ISO 12913-1:2014 2014; Truax 1999)</span>, bringing together objective and subjective factors. The soundscape approach to noise mitigation and management is being recognized as a response to arising environmental requirements on noise pollution and sustainability, such as the regulation of quiet areas in Europe <span class="citation" data-cites="EuropeanUnion2002Directive Kang2018Impact Radicchi2021Sound">(European Union 2002; Kang and Aletta 2018; Radicchi et al. 2021)</span>. This has been further formalized in <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span> via the adoption of the circumplex model of soundscape <span class="citation" data-cites="Axelsson2010principal">(Axelsson, Nilsson, and Berglund 2010)</span>, in which the perception of a soundscape can be described in terms of its pleasantness and eventfulness, as one of the standard methods of soundscape assessment.</p>
<p>Soundscape research is therefore traditionally rooted in environmental acoustics and environmental psychology, typically dealing with outdoor spaces <span class="citation" data-cites="Torresin2020Indoor">(Torresin et al. 2020)</span> and urban open spaces, where parks and squares are often used as case study sites <span class="citation" data-cites="Kang2006Urban">(Kang 2006)</span>. A soundscape assessment typically requires people to be surveyed but the presence of people at a location influences assessment <span class="citation" data-cites="Aletta2018Towards">(Aletta and Kang 2018)</span> and ‘quiet places’ usually require low numbers of users to remain quiet, which limits the possibility of an assessment. Even in a crowded public space, soundscape surveys are demanding as they require significant resources to carry out at scale, limiting their widespread application <span class="citation" data-cites="Mitchell2020Soundscape">(Mitchell et al. 2020)</span>. Therefore, a need for a predictive model arises to overcome this limitation and improve the implementation of the soundscape approach into everyday planning and management practices.</p>
<p>According to a recent review of predictive soundscape models from <span class="citation" data-cites="Lionello2020systematic">Lionello, Aletta, and Kang (2020)</span>, the degree of employing auditory and non-auditory factors in soundscape prediction varies with some studies relying on contextual, personal/demographic <span class="citation" data-cites="Erfanian2021Psychological Tarlao2020Investigating">(Erfanian et al. 2021; Tarlao, Steffens, and Guastavino 2020)</span> or social media <span class="citation" data-cites="Aiello2016Chatty">(Aiello et al. 2016)</span> data entirely to predict and generate soundscape features. Some methods also incorporate perceptually-derived features, such as subjective sound level and visual pleasantness as predictors <span class="citation" data-cites="Lionello2020systematic">(Lionello, Aletta, and Kang 2020)</span>. In general, these methods which incorporate perceptually-derived inputs achieve better accuracy rates than those which don’t, however this perception information must also be obtained from people via a survey and therefore are unsuitable for predictive modeling where surveys are not possible. For example, <span class="citation" data-cites="Ricciardi2015Sound">Ricciardi et al. (2015)</span> proposed two models based on data collected from a smartphone application to predict urban sound quality indicators based on linear regressions. The first model which incorporated perceptually-derived input features (visual quality and familiarity) achieved an <img src="https://latex.codecogs.com/png.latex?R%5E2"> of 0.72, while a second model without these features achieved an <img src="https://latex.codecogs.com/png.latex?R%5E2"> of 0.58. This indicates the necessity for considering and accounting for the influence which contextual factors in a space have on the relationship between the sound environment itself and the listener’s perception of it (i.e.&nbsp;the soundscape) while also highlighting the challenges associated with a predictive model which depends only on measurable features.</p>
<p>Therefore, a third research question arises: what are the key features needed for a soundscape prediction model based on comprehensive acoustic on-site measurements to be used for assessing locations with low social presence or in situations where conducting surveys is impractical (RQ3)?</p>
</section>
<section id="materials-and-methods" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="materials-and-methods"><span class="header-section-number">2</span> Materials and methods</h2>
<p>This study was conducted via initial onsite data collection campaigns in Central London and Venice in 2019 before the outbreak of COVID-19 as part of the Soundscape Indices (SSID) project <span class="citation" data-cites="Mitchell2020Soundscape">(Mitchell et al. 2020)</span> and in 2020 during the strictest part of the lockdowns <span class="citation" data-cites="Aletta2020Assessing">(Aletta et al. 2020)</span>, including objective acoustic data (2019 and 2020) and subjective responses (2019 only). The full in situ dataset, as described in this section, has been made publicly available as ‘The International Soundscape Database (V0.2.1)’ on Zenodo<sup>1</sup><span class="citation" data-cites="Mitchell2021International">(Mitchell et al. 2021)</span>.</p>
<p>Using both 2019 and 2020 binaural recordings, an online listening experiment was conducted to provide an understanding about the change in sound source composition. The 2019 onsite questionnaire data were used to define the dominant sound source at each location as a starting point for interpreting soundscape change. A predictive model was developed to reveal the change in the perceived pleasantness and eventfulness using objective acoustic data and location to predict subjective responses. Although the initial (2019) dataset contains additional locations (specifically, in Spain, the Netherlands, and China), due to the nature of this study as a reaction to the strict movement and activity restrictions, the sites which could be included in the lockdown (2020) measurement campaigns were limited to locations where staff and equipment had access and where recordings could be undertaken during the spring of 2020.</p>
<p>The sites were selected to provide a mixture of sizes and uses, varying in typology ranging from paved squares to small and large parks to waterside spaces across both cities. Throughout the text they are indexed via a LocationID based on the location’s name (e.g.&nbsp;CamdenTown, SanMarco), while a more in-depth overview of each is given in supplementary material<sup>2</sup>. London is taken as an example of a large, typically noisy city while the Venice sample provides a unique look at spaces with typically very high human activity levels and no road traffic activity. In particular, the 2019 Venice surveys were taken to coincide with the yearly Carnevale festival in order to capture its distinct soundscape.</p>
<p>The ISO/TS 12913 <span class="citation" data-cites="ISO12913Part2">(ISO/TS 12913-2:2018 2018)</span> series were consulted for reporting on soundscape data. A detailed description of the 2019 survey campaigns is featured throughout the paper and in the public database. This study was approved by departmental UCL IEDE Ethics Committee on 17th July 2018 for onsite data collection and on the 2nd of June 2020 for the on-line listening experiment and is conducted in adherence to the ethical requirements of the Declaration of Helsinki <span class="citation" data-cites="WMA2013World">(World Medical Association 2013)</span>.</p>
<section id="onsite-data-questionnaires-binaural-measurements-and-recordings" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="onsite-data-questionnaires-binaural-measurements-and-recordings"><span class="header-section-number">2.1</span> Onsite data: Questionnaires, binaural measurements, and recordings</h3>
<p>The initial onsite data collection featured both questionnaire data collected from the general public and acoustic measurements, conducted across thirteen urban locations (in London <img src="https://latex.codecogs.com/png.latex?N=11">, in Venice <img src="https://latex.codecogs.com/png.latex?N=2">) between the 28th of February and the 21st of June 2019, with additional sessions in July and October 2019. Although the total survey period in 2019 extended over several seasons, the surveys at any individual location did not extend over seasons with different occupancy patterns. A total of 1,318 questionnaire responses were collected from the general population across the measurement points during 1 – 3 hour-long campaigns in both cities in 2019, accompanied by 693 approximately 30-second long 24-bit 44.1 kHz binaural recordings. After data cleaning, each of the 13 locations was characterized by between 14 to 80 recordings and between 24 to 147 questionnaire responses. Mean age of the participants was 33.8, with a standard deviation of 14.57 (45% male, 53.8% female, 0.4% non-conforming, 0.9% prefer-not-to-say).</p>
<p>Although recent results from both <span class="citation" data-cites="Tarlao2020Investigating">Tarlao, Steffens, and Guastavino (2020)</span> and <span class="citation" data-cites="Erfanian2021Psychological">Erfanian et al. (2021)</span> indicate the important influence of personal and demographic factors – in particular age and gender – on soundscape perception, these factors were not included as potential features in the modeling process. Given the nature of this study as addressing a scenario when people could not be surveyed, no additional demographic information is available in the lockdown case to be fed into the model and is therefore not useful to include for the development and application of this specific predictive model. This information is reported throughout the study simply to provide further context to the data collection.</p>
<p>The subsequent measurement campaign in 2020 mimicked the binaural recording strategy applied in the initial campaign and was performed between the 6th and the 25th of April 2020 in both cities, this time excluding the questionnaire. An additional 571 binaural recordings were collected on-site in 2020.</p>
<section id="data-collection" class="level4" data-number="2.1.1">
<h4 data-number="2.1.1" class="anchored" data-anchor-id="data-collection"><span class="header-section-number">2.1.1</span> Data collection</h4>
<p>The 2019 data collection was performed across all the locations using the protocol based on the Method A of the <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span>, as described in <span class="citation" data-cites="Aletta2020Assessing">Aletta et al. (2020)</span> and <span class="citation" data-cites="Mitchell2020Soundscape">Mitchell et al. (2020)</span>, collected either via handheld tablets or paper copies of the questionnaire. The full questionnaire and data collection procedure are given in <span class="citation" data-cites="Mitchell2020Soundscape">Mitchell et al. (2020)</span>, however the key parts used for this study are those addressing sound source dominance and perceived affective quality (PAQ).</p>
<p>Participants are first asked to rate the perceived dominance of several sound sources, as assessed via a 5-point Likert scale, coded from 1 (Not at all) to 5 (Dominates completely). The sound sources are split into four categories: Traffic noise, Other noise, Human sounds, and Natural sounds and each is rated separately. Next are the 8 PAQs which make up the circumplex model of soundscape <span class="citation" data-cites="Axelsson2010principal">(Axelsson, Nilsson, and Berglund 2010)</span>: pleasant, chaotic, vibrant, uneventful, calm, annoying, eventful, and monotonous. These are assessed on a 5-point Likert scale from 1 (Strongly disagree) to 5 (Strongly agree). In order to simplify the results and allow for modeling the responses as continuous values, the 8 PAQs undergo a trigonometric projection to reduce them onto the two primary dimensions of pleasant and eventful, according to the procedure outlined in Part 3 of the ISO 12913 series <span class="citation" data-cites="ISO12913Part3">(ISO/TS 12913-3:2019 2019)</span>. In order to distinguish the projected values from the Likert-scale PAQ responses, the projected values will be referred to as ISOPleasant and ISOEventful and can be considered to form an x-y coordinate point (x = ISOPleasant, y = ISOEventful) as explained in detail in <span class="citation" data-cites="Lionello2021Introducing">Lionello et al. (2021)</span>.</p>
<p>The calibrated binaural device SQobold with BHS II by Head Acoustics was used in both campaigns at all the locations by various operators to capture acoustic data, as mentioned in the acknowledgments. Following the established onsite protocol <span class="citation" data-cites="Mitchell2020Soundscape">(Mitchell et al. 2020)</span>, when participants were stopped in a group and filled in their responses simultaneously, a single binaural recording was used to capture their experience as a group. The purpose behind this sampling strategy was to obtain data from the perspective of a typical user, corresponding to a range of individual experiences available within an urban open space. These recordings are indexed by a GroupID such that the recording for each group is matched up to each of the corresponding respondents and their individual survey responses.</p>
</section>
<section id="data-cleaning" class="level4" data-number="2.1.2">
<h4 data-number="2.1.2" class="anchored" data-anchor-id="data-cleaning"><span class="header-section-number">2.1.2</span> Data cleaning</h4>
<p>The cleaning of the samples was conducted using the ArtemiS SUITE 11. The researcher discarded or cropped whole recordings, or its parts affected by wind gusts or containing noises and speech generated by the recording operator by accident or for the purpose of explaining the questionnaire to a participant. This resulted in 1,258 binaural recordings then processed further, as described in Section&nbsp;2.1.3. Psychoacoustic analyses are shown in the publicly available database<sup>3</sup>.</p>
<p>In order to maintain data quality and exclude cases where respondents either clearly did not understand the PAQ adjectives or intentionally misrepresented their answers, surveys for which the same response was given for every PAQ (e.g.&nbsp;‘Strongly agree’ to all 8 attributes) were excluded prior to calculating the ISO projected values. This is justified as no reasonable respondent who understood the questions would answer that they ‘strongly agree’ that a soundscape is pleasant and annoying, calm and chaotic, etc. Cases where respondents answered ‘Neutral’ to all PAQs are not excluded in this way, as a neutral response to all attributes is not necessarily contradictory. In addition, surveys were discarded as incomplete if more than 50% of the PAQ and sound source questions were not completed.</p>
<p>The site characterization per <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span> is available in the supplementary material<sup>4</sup> and public database<sup>5</sup>, featuring the address, overall psychoacoustic characteristics of the location, typical use of each location, and pictures taken during the survey sessions.</p>
</section>
<section id="sec-psychoacousticAnalysis" class="level4" data-number="2.1.3">
<h4 data-number="2.1.3" class="anchored" data-anchor-id="sec-psychoacousticAnalysis"><span class="header-section-number">2.1.3</span> Psychoacoustic analyses</h4>
<p>The binaural recordings were analyzed in ArtemiS SUITE 11 to calculate the suite of 11 acoustic and psychoacoustic features given in Table&nbsp;1 to be used as initial predictors. The (psycho)acoustic predictors investigated were selected in order to describe many aspects of the recorded sound – in particular, the goal was to move beyond a focus on sound level, which currently dominates the existing literature on the acoustic effects of lockdowns noted in Section&nbsp;1. In all, they are expected to reflect the sound level (<img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">), perceived sound level (Loudness), spectral content (Sharpness, <img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D">, Tonality), temporal character or predictability (Impulsiveness, Fluctuation Strength, Relative Approach), and overall annoyance (Psychoacoustic Annoyance). These metrics have been proposed as indicators to predict perceptual constructs of the soundscape <span class="citation" data-cites="Aletta2016Soundscape Aletta2017Dimensions">(Aletta, Kang, and Axelsson 2016; Aletta, Axelsson, and Kang 2017)</span> and have shown promise when combined together to form a more comprehensive model applied to real-world sounds <span class="citation" data-cites="Orga2021Multilevel">(Orga et al. 2021)</span>. The maximum value from the left and right channels of the binaural recording are used, as suggested in <span class="citation" data-cites="ISO12913Part3">ISO/TS 12913-3:2019 (2019)</span>.</p>
<div id="tbl-psychoacoustics" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-psychoacoustics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Psychoacoustic features considered for inclusion in the predictive models. All metrics are calculated for the full length of the recording (<img src="https://latex.codecogs.com/png.latex?%5Csim30s">). As recommended by <span class="citation" data-cites="ISO2017Acoustics">ISO 532-1:2017 (2017)</span> and <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span>, the 5th percentile of Loudness is used rather than the average.
</figcaption>
<div aria-describedby="tbl-psychoacoustics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 22%">
<col style="width: 11%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Feature</strong></th>
<th style="text-align: center;"><strong>Symbol</strong></th>
<th style="text-align: center;"><strong>Unit</strong></th>
<th><strong>Calculation Method</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Loudness (5th percentile)</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?N_5"></td>
<td style="text-align: center;">sones</td>
<td><span class="citation" data-cites="ISO2017Acoustics">ISO 532-1:2017 (2017)</span></td>
</tr>
<tr class="even">
<td>Sharpness</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?S"></td>
<td style="text-align: center;">acum</td>
<td><span class="citation" data-cites="ISO2017Acoustics">ISO 532-1:2017 (2017)</span></td>
</tr>
<tr class="odd">
<td>Roughness</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?R"></td>
<td style="text-align: center;">asper</td>
<td><span class="citation" data-cites="Sottek2005Models">Sottek and Genuit (2005)</span></td>
</tr>
<tr class="even">
<td>Impulsiveness</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?I"></td>
<td style="text-align: center;">iu</td>
<td><span class="citation" data-cites="Sottek2005Models">Sottek and Genuit (2005)</span></td>
</tr>
<tr class="odd">
<td>Fluctuation Strength</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?FS"></td>
<td style="text-align: center;">vacil</td>
<td><span class="citation" data-cites="Sottek2005Models">Sottek and Genuit (2005)</span></td>
</tr>
<tr class="even">
<td>Tonality</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?T"></td>
<td style="text-align: center;">tuHMS</td>
<td><span class="citation" data-cites="Sottek2005Models">Sottek and Genuit (2005)</span></td>
</tr>
<tr class="odd">
<td>Psychoacoustic Annoyance</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?PA"></td>
<td style="text-align: center;">–</td>
<td><span class="citation" data-cites="Zwicker2007Psychoacoustics">Zwicker and Fastl (2007)</span></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"></td>
<td style="text-align: center;">dB</td>
<td><span class="citation" data-cites="IEC2013Electroacoustics">IEC 61672-1:2013 (2013)</span></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D"></td>
<td style="text-align: center;">dB</td>
<td><span class="citation" data-cites="ISO2016Acoustics">ISO 1996-1:2016 (2016)</span></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"></td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"></td>
<td style="text-align: center;">dB</td>
<td><span class="citation" data-cites="ISO2016Acoustics">ISO 1996-1:2016 (2016)</span></td>
</tr>
<tr class="odd">
<td>Relative Approach</td>
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?RA"></td>
<td style="text-align: center;">cPA</td>
<td><span class="citation" data-cites="Sottek2005Models">Sottek and Genuit (2005)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Table&nbsp;2 shows the Pearson correlation coefficient between each of the candidate acoustic features and the outcome pleasantness and eventfulness. As all variables considered are continuous, and the eventual model is linear, the Pearson coefficient is chosen as a measure of the strength of the linear relationship between two continuous variables. For ISOPleasant (<em>ISOPl</em>), we can perhaps see three tiers of correlations: the more highly correlated tier <img src="https://latex.codecogs.com/png.latex?(%7Cr%7C%20%3E%200.28)"> consists of Relative Approach (<img src="https://latex.codecogs.com/png.latex?RA">), <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, Roughness (<img src="https://latex.codecogs.com/png.latex?R">), Loudness (<img src="https://latex.codecogs.com/png.latex?N_5">), and Psychoacoustic Annoyance (<img src="https://latex.codecogs.com/png.latex?PA">); the low correlation tier consists of <img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D">, Tonality (<img src="https://latex.codecogs.com/png.latex?T">), and Fluctuation Strength (<img src="https://latex.codecogs.com/png.latex?FS">); while <img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D">, Impulsiveness (<img src="https://latex.codecogs.com/png.latex?I">), and Sharpness (<img src="https://latex.codecogs.com/png.latex?S">) show no correlation. For ISOEventful (<em>ISOEv</em>), these tiers are: <img src="https://latex.codecogs.com/png.latex?RA">, <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, <img src="https://latex.codecogs.com/png.latex?T">, <img src="https://latex.codecogs.com/png.latex?R">, and <img src="https://latex.codecogs.com/png.latex?N_5"> comprise the most correlated tier <img src="https://latex.codecogs.com/png.latex?(%7Cr%7C%20%3E%200.30)">; <img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D">, <img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D">, <img src="https://latex.codecogs.com/png.latex?FS">, and <img src="https://latex.codecogs.com/png.latex?PA"> show low correlations; <img src="https://latex.codecogs.com/png.latex?I"> and <img src="https://latex.codecogs.com/png.latex?S"> show no correlation.</p>
<div id="tbl-corr" class="striped hover quarto-float quarto-figure quarto-figure-center anchored" data-fontsize="10pt">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-corr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Pearson correlation coefficients between candidate acoustic features and ISOPleasant and ISOEventful across all 13 locations. Only statistically significant (<img src="https://latex.codecogs.com/png.latex?p%20%3C%200.01">) coefficients are shown.
</figcaption>
<div aria-describedby="tbl-corr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 5%">
<col style="width: 6%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 8%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong>Parameter</strong></th>
<th style="text-align: center;"><strong>ISOPl</strong></th>
<th style="text-align: center;"><strong>ISOEv</strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?PA"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?N_5"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?S"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?R"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?I"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?FS"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?T"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D"></strong></th>
<th style="text-align: center;"><strong><img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">ISOPleasant</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">ISOEventful</td>
<td style="text-align: center;">-0.24</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?PA"></td>
<td style="text-align: center;">-0.28</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?N_5"></td>
<td style="text-align: center;">-0.37</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?S"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?R"></td>
<td style="text-align: center;">-0.36</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?I"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.10</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.37</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?FS"></td>
<td style="text-align: center;">-0.11</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?T"></td>
<td style="text-align: center;">-0.21</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.16</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"></td>
<td style="text-align: center;">-0.34</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">-0.09</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D"></td>
<td style="text-align: center;">-0.18</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.21</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">-0.20</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.20</td>
<td style="text-align: center;">-0.49</td>
<td style="text-align: center;">-0.49</td>
<td style="text-align: center;">-0.54</td>
<td style="text-align: center;">-0.31</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-0.27</td>
<td style="text-align: center;">-0.28</td>
<td style="text-align: center;">-0.61</td>
<td style="text-align: center;">-0.22</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><img src="https://latex.codecogs.com/png.latex?RA"></td>
<td style="text-align: center;">-0.34</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.18</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">-0.14</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Among the inter-correlations for the psychoacoustic metrics considered for inclusion as input features, we can see several very highly correlated features (i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?%3E0.9">). As expected, <img src="https://latex.codecogs.com/png.latex?PA">, <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, and <img src="https://latex.codecogs.com/png.latex?N_5"> are highly correlated, meaning that careful consideration is paid to these features to ensure they do not contribute to multicollinearity in the final model.</p>
</section>
</section>
<section id="modelling" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="modelling"><span class="header-section-number">2.2</span> Modelling</h3>
<p>Two linear multi-level models (MLM) were computed to predict: 1) ISOPleasant, and 2) ISOEventful. These models are trained on the 2019 data only, then applied to the acoustic data collected during the 2020 lockdowns, the results of which are reported in Section&nbsp;3.2.3. The inherent grouped structure of the SSID database necessitates a modeling and analysis approach which considers the differing relationships between the objective acoustic features and the soundscape’s perceived affective quality ratings across the various locations and contexts. The individual-level of the models is made up of the acoustic features calculated from the binaural recordings made during each respondent’s survey period, while the group-level includes the categorical <code>LocationID</code> variable indicating the location in which the survey was taken, acting as a non-auditory contextual factor.</p>
<p>A separate backwards-step feature selection was performed for each of the outcome models in order to identify the minimal feature set to be used for predicting each outcome. In this feature selection process, an initial model containing all of the candidate features was fit. Each feature was then removed from the model one at a time, then the best-performing model is selected and the procedure continues step-wise until no improvement is seen by removing more features. This process is carried out first on the location-level features (including the potential to remove all features including LocationID, resulting in a ‘flat’ or standard multivariate linear regression model), then on the individual-level features. The performance criterion used for this process was the Akaike Information Criterion (AIC) <span class="citation" data-cites="Akaike1974new">(Akaike 1974)</span>. To check for multicollinearity among the selected features, the variance inflation factor (VIF) was calculated and a threshold of VIF &lt;5 was set. Any features which remained after the backwards stepwise selection and which exceeded this threshold were investigated and removed if they were highly collinear with the other features.</p>
<p>All of the input features are numeric values, in the units described above. Before conducting feature selection, the input features are z-scaled to enable proper comparison of their effect sizes. After the feature selection, the scaled coefficients are used in the text when reporting the final fitted models to facilitate discussion and comparison between the features. The unscaled model coefficients are reported in <strong>?@sec-appmod</strong> to enable the models to be applied to new data. In order to properly assess the predictive performance of the model, an 80/20 train-test split with a balanced shuffle across LocationIDs was used. The z-scaling and feature selection was performed on the training set only, in order to prevent data leakage. To score the performance of the model on the training and testing sets, we use the mean absolute error (MAE), which is in the scale of the response feature - for ISOPleasant this means our response can range from -1 to +1. However, since the end-goal of the model is to predict the soundscape assessment of the location as a whole, rather than the individual responses, we also assess the performance of the model in predicting the average response in each location. To do this, the mean response value for each location is calculated, and the <img src="https://latex.codecogs.com/png.latex?R%5E2"> accuracy across LocationIDs is reported for both the training and testing sets.</p>
<p>The model fitting and feature selection was performed using the <code>step</code> function from <code>lmerTest</code> (v3.1.3) <span class="citation" data-cites="Kuznetsova2017lmerTest">(Kuznetsova, Brockhoff, and Christensen 2017)</span> in R statistical software (v4.0.3) <span class="citation" data-cites="RCT2018R">(R Core Team 2018)</span>. The summaries and plots were created using the <code>sjPlot</code> package (v2.8.6) <span class="citation" data-cites="Luedecke2021sjPlot">(Lüdecke 2021)</span> and <code>seaborn</code> (v0.11.1) <span class="citation" data-cites="Waskom2021seaborn">(Waskom 2021)</span>.</p>
</section>
<section id="online-survey" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="online-survey"><span class="header-section-number">2.3</span> Online survey</h3>
<p>An online listening test was conducted using the Gorilla Experiment Builder<sup>6</sup> <span class="citation" data-cites="AnwylIrvine2019Gorilla">(Anwyl-Irvine et al. 2019)</span>. The participants were exposed to a random selection of 78 binaural recordings (39 from 2019 and 39 from 2020, 6 recordings per each location). Each participant had the option to evaluate either 1 or 2 sets of 6 recordings randomly assigned between 13 stimuli sets. Mp3 files, converted at 256 kBps were used due to the requirements of the Gorilla platform.</p>
<p>No visual stimuli were used in the experiment. The experiment consisted of: 1) an initial exercise to enhance chances of participants complying to the instructions and wearing headphones; 2) a training set using two randomly chosen binaural recordings (then not used in the main task) from the dataset; 3) a soundscape characterization questionnaire starting with an open-ended question about perceived sound sources and featuring the same questions as the one used in situ, looking into the perceived affective quality of the soundscape and the perceived sound source dominance of the following four types: traffic noise, other noise, human sounds and natural sounds; 4) a questionnaire on the basic demographic factors. The questionnaire used in the Part 3 of the online experiment is reported in Appendix A.</p>
<p>Having in mind the remote nature of the study and to ensure a minimum level of robustness for reliable sound source recognition, an initial exercise was performed consisting of a headphone screening test <span class="citation" data-cites="Woods2017Headphone">(Woods et al. 2017)</span> and a headphone reproduction level adjustment test <span class="citation" data-cites="Gontier2019Estimation">(Gontier et al. 2019)</span>. The level adjustment was performed using an eleven-second-long pink noise sample matched to the lowest and the highest <img src="https://latex.codecogs.com/png.latex?L_%7BA90%7D"> values from the experimental set. Participants were asked to adjust their listening level to clearly hear the quieter sample while keeping the level low enough, so they don’t find the louder sample disturbing. The headphones screening test followed, featuring a stereo signal of one-second-long 100 Hz sine tone, generated with Izotope RX 6 application, played at a 3 dB difference where one of the equally loud pairs had its phase inverted. A 100 Hz sine was used because the pilot tests revealed the 200 Hz sine tone proposed by <span class="citation" data-cites="Woods2017Headphone">Woods et al. (2017)</span> created a higher uncertainty varying across different laptop models and would likely contribute to the chances of a participant fooling the test. It was expected that participants using speakers would not be able to either hear the sine wave or would be fooled by the inverted phase effect and therefore not able to pass the trials, unless they were indeed using headphones. The participant needed to recognize the quietest of the 3 samples in a trial of 6 attempts. Only participants correctly answering 5 or more out of 6 trials were allowed to proceed with the experiment. Participants were asked not to change their audio output settings during the rest of the experiment. (This was introduced to ensure that a participant is using a headphones playback system which allows a listener to clearly recognize a 3 dB difference at 100 Hz as a proxy for sufficient audio quality playback.)</p>
<p>However, after the initial data collection, questions were raised as to how the playback loudness impacts ecological validity as it relates to the perceived affective quality of the soundscape. Given this concern, the PAQ responses from the online surveys were not included in further data analysis. Sound source identification is not considered to suffer the same validity concerns as this is not directly dependent on absolute playback level and requires only that the participant can clearly hear what is present. The purpose of the calibration procedure described above was to ensure the participant could clearly hear the softest samples used.</p>
<p>Online questionnaire data was collected between the 9th of June and the 9th of August 2020. Within the Gorilla Experiment Builder, a total of 250 attempts to complete the experiment were recorded, where 165 participants were excluded either on the basis of not passing the headphones screening (<img src="https://latex.codecogs.com/png.latex?N=79">) or for not completing the experiment, usually before engaging into the screening (<img src="https://latex.codecogs.com/png.latex?N=83">). Out of a total of 88 participants who completed the test, 2 participants were excluded as outliers as they provided uniform answers across all the questions and commented on not being able to properly hear the stimuli, despite their successful completion of the training tests. The participants of the online experiment were of mean age 32.42, 45.1% male, 54.9% female.</p>
<p>Figure&nbsp;1 illustrates and summarizes the framework and sections described above.</p>
<div id="fig-framework" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-framework-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure1.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-framework-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The study flowchart indicating the data collection, analysis, modeling, and discussion throughout the study. The subsections in the text to which each box refers are indicated in italics.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="results" class="level2 page-columns page-full" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="results"><span class="header-section-number">3</span> Results</h2>
<p>The results of the onsite surveys, online experiment, and the model development are reported here. They are reported following the structure of the ISO/TS 12913 series, revealing the perceived sound source dominance, key perceptual attributes (ISOPleasant and ISOEventful) and the lockdown-related changes.</p>
<section id="perceived-sound-source-dominance" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="perceived-sound-source-dominance"><span class="header-section-number">3.1</span> Perceived sound source dominance</h3>
<section id="sound-source-composition-per-location" class="level4" data-number="3.1.1">
<h4 data-number="3.1.1" class="anchored" data-anchor-id="sound-source-composition-per-location"><span class="header-section-number">3.1.1</span> 2019 sound source composition per location</h4>
<p>Questionnaire data was collected in English, Italian, and Spanish in both cities. The respective questionnaires can be found in the supplementary files and <span class="citation" data-cites="Mitchell2020Soundscape">Mitchell et al. (2020)</span>. Data presented here was aggregated per LocationID.</p>
<p>According to the highest scored mean value of the dominant sound source type, as shown in Figure&nbsp;2, the locations can be grouped into: natural sounds dominated (RegentsParkJapan, RegentsParkFields, RussellSq), human sounds dominated (SanMarco, TateModern, StPaulsRow, StPaulsCross, MonumentoGaribaldi), noise (traffic and other noise) sounds dominated (CamdenTown, EustonTap, TorringtonSq, PancrasLock). Traffic noise and Other noise have been combined here, and for the rest of the discussion, as these responses are highly correlated within this dataset and it is not helpful to consider them separately for this analysis. This follows the alternative sound source labels given in Figure C.3 of <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span> which combines Traffic and Other Noise. Finally, MarchmontGarden is unique in that all sound source types are assessed as being nearly equally present, with only 0.2 separating the least present (Other noise, 2.5) and the most present (Traffic noise, 2.7).</p>
<div id="fig-barchart" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-barchart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure2.jpg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-barchart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: (Color online) Mean response per Location ID for the perceived dominance of the sound source types, for the 2019 on-site campaign. The values represent the mean response of all participants in each location to the question “To what extent do you presently hear the following four types of sounds?”. Response values range from [1] Not at all to [5] Dominates completely.
</figcaption>
</figure>
</div>
</section>
<section id="overall-change-in-the-perceived-sound-source-dominance-during-lockdown" class="level4" data-number="3.1.2">
<h4 data-number="3.1.2" class="anchored" data-anchor-id="overall-change-in-the-perceived-sound-source-dominance-during-lockdown"><span class="header-section-number">3.1.2</span> Overall change in the perceived sound source dominance during lockdown</h4>
<p>1803 words describing the sound sources present in the 2019 recordings and 1395 words related to the 2020 recordings were input by participants in response to the open-ended question Q1 (see Appendix A). The frequency of occurrence, generated using the WordClouds web app, is shown in the Figure&nbsp;3, for the 2019 and the 2020 sets respectively. The most frequent words from both 2019 and 2020 groups are: noise, car/traffic, bird/birds, talk/voice and (foot)steps.</p>
<div id="fig-wordclo" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-wordclo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure3a.jpg" class="img-fluid figure-img"></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure3b.jpg" class="img-fluid figure-img"></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wordclo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: A graphic illustrating the frequency of occurrence of the sound sources reported by the participants of the online study across all locations, shown for recordings from the 2019 (above) and 2020 (below).
</figcaption>
</figure>
</div>
<p>The results from the listening tests deployed online were analyzed using the SPSS Statistics v. 25. Levene’s test for equality of variances resulted in highly statistically significant values for all 4 sound sources investigated (less than 0.001). Therefore, a Mann-Whitney U-test test was used as a non-parametric equivalent to the T-test to investigate the change in the perceived dominance of the four sound source types <span class="citation" data-cites="McKnight2010Mann">(McKnight and Najab 2010)</span>. The results for human sounds indicated that the perceived dominance was greater for the 2019 sample (M=3.82), than for the 2020 sample (M=2.62), U=41,656, p &lt; 0.001. The results for natural sounds indicated the perceived dominance increased from 2019 (M=2.00) to 2020 (M=2.54), U=63,797, p &lt; 0.001. However, the differences for the noise sources (traffic and other) were not statistically significant. The result of these changes is that while Human sounds were the clearly dominant source across the whole dataset in 2019, in 2020 the sound sources are, on average, much more evenly balanced. No single sound source category was identified as frequent across the 2020 dataset.</p>
<div id="tbl-source" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-source-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: Mean values and standard deviation for the perceived dominance of sound sources (rated from 1 - 5), assessed via an online survey.
</figcaption>
<div aria-describedby="tbl-source-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 12%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 24%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Sound source type</th>
<th style="text-align: center;">Campaign</th>
<th style="text-align: center;">N</th>
<th style="text-align: center;">Mean</th>
<th style="text-align: center;">Standard deviation</th>
<th style="text-align: center;">Standard error mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Traffic</td>
<td style="text-align: center;">2019</td>
<td style="text-align: center;">422</td>
<td style="text-align: center;">2.51</td>
<td style="text-align: center;">1.369</td>
<td style="text-align: center;">0.067</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: center;">2020</td>
<td style="text-align: center;">383</td>
<td style="text-align: center;">2.56</td>
<td style="text-align: center;">1.525</td>
<td style="text-align: center;">0.078</td>
</tr>
<tr class="odd">
<td>Other</td>
<td style="text-align: center;">2019</td>
<td style="text-align: center;">422</td>
<td style="text-align: center;">2.00</td>
<td style="text-align: center;">1.182</td>
<td style="text-align: center;">0.058</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: center;">2020</td>
<td style="text-align: center;">382</td>
<td style="text-align: center;">2.23</td>
<td style="text-align: center;">1.333</td>
<td style="text-align: center;">0.068</td>
</tr>
<tr class="odd">
<td>Human</td>
<td style="text-align: center;">2019</td>
<td style="text-align: center;">423</td>
<td style="text-align: center;">3.82</td>
<td style="text-align: center;">1.143</td>
<td style="text-align: center;">0.056</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: center;">2020</td>
<td style="text-align: center;">382</td>
<td style="text-align: center;">2.62</td>
<td style="text-align: center;">1.346</td>
<td style="text-align: center;">0.069</td>
</tr>
<tr class="odd">
<td>Natural</td>
<td style="text-align: center;">2019</td>
<td style="text-align: center;">424</td>
<td style="text-align: center;">2.00</td>
<td style="text-align: center;">1.307</td>
<td style="text-align: center;">0.063</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: center;">2020</td>
<td style="text-align: center;">380</td>
<td style="text-align: center;">2.54</td>
<td style="text-align: center;">1.441</td>
<td style="text-align: center;">0.074</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="model-selection-performance-and-application" class="level3 page-columns page-full" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="model-selection-performance-and-application"><span class="header-section-number">3.2</span> Model selection, performance, and application</h3>
<div id="tbl-model" class="striped hover column-page smaller quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: Scaled linear regression models of ISOPleasant and ISOEventful for 13 locations in London and Venice. ISOPleasant model structure: Random slope, random intercept multi-level model. ISOEventful model structure: Multi-variate linear regression.
</figcaption>
<div aria-describedby="tbl-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover smaller caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 28%">
<col style="width: 20%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 9%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>ISOPleasant</th>
<th></th>
<th></th>
<th>ISOEventful</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Predictors</td>
<td>Estimates</td>
<td>Confidence Interval (CI)</td>
<td>p</td>
<td>Estimates</td>
<td>CI</td>
<td>p</td>
</tr>
<tr class="even">
<td>(Intercept)</td>
<td>0.24</td>
<td>0.15–0.33</td>
<td>&lt;0.001</td>
<td>0.14</td>
<td>0.12–0.16</td>
<td>&lt;0.001</td>
</tr>
<tr class="odd">
<td>N5</td>
<td>−0.06</td>
<td>−0.10–0.02</td>
<td>&lt;0.001</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>S</td>
<td></td>
<td></td>
<td></td>
<td>−0.08</td>
<td>−0.11–0.06</td>
<td>&lt;0.001</td>
</tr>
<tr class="odd">
<td>FS</td>
<td></td>
<td></td>
<td></td>
<td>−0.02</td>
<td>−0.05–0.00</td>
<td>0.033</td>
</tr>
<tr class="even">
<td>T</td>
<td></td>
<td></td>
<td></td>
<td>0.04</td>
<td>0.01–0.07</td>
<td>0.002</td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"></td>
<td></td>
<td></td>
<td></td>
<td>0.14</td>
<td>0.11–0.17</td>
<td>&lt;0.001</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"></td>
<td></td>
<td></td>
<td></td>
<td>−0.03</td>
<td>−0.05–0.00</td>
<td>0.052</td>
</tr>
<tr class="odd">
<td><strong>Random effects</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"></td>
<td>0.11</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Ctau_%7B00%7D"></td>
<td><img src="https://latex.codecogs.com/png.latex?0.03_%7BLocationID%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Ctau_%7B11%7D"></td>
<td><img src="https://latex.codecogs.com/png.latex?0.02_%7BLocationID.L_%7BAeq%7D%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?0.00_%7BLocationID.L_%7BA10%7D-L_%7BA90%7D%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?0.00_%7BLocationID.L_%7BCeq%7D-L_%7BAeq%7D%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>ICC</td>
<td>0.90</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>N</td>
<td><img src="https://latex.codecogs.com/png.latex?13_%7BLocationID%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Observations</td>
<td>914</td>
<td></td>
<td></td>
<td>914</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>MAE train, test</td>
<td>0.258</td>
<td>0.259</td>
<td></td>
<td>0.233</td>
<td>0.231</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<section id="isopleasant-model-selected" class="level4" data-number="3.2.1">
<h4 data-number="3.2.1" class="anchored" data-anchor-id="isopleasant-model-selected"><span class="header-section-number">3.2.1</span> ISOPleasant model selected</h4>
<p>Following the feature selection, the ISOPleasant model (given in Table&nbsp;4) has <img src="https://latex.codecogs.com/png.latex?N_5"> as the fixed effect with a scaled coefficient of -0.06, and <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, <img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D">, and <img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"> as coefficients which vary depending on the LocationID. The training and testing MAE are very similar, indicating that the model is neither over- nor under-fitting to the training data (<img src="https://latex.codecogs.com/png.latex?MAE_%7Btrain%7D%20=%200.258">; <img src="https://latex.codecogs.com/png.latex?MAE_%7Btest%7D%20=%200.259">). The model performs very well at predicting the average soundscape assessment of the locations (<img src="https://latex.codecogs.com/png.latex?R%5E2_%7Btrain%7D%20=%200.998">; <img src="https://latex.codecogs.com/png.latex?R%5E2_%7Btest%7D%20=%200.85">).</p>
<p>The high intraclass correlation (<img src="https://latex.codecogs.com/png.latex?ICC%20=%200.90">) demonstrates that the location-level effects are highly important in predicting the pleasantness dimension. Within this random-intercept random-slope model structure, these effects include both the specific context of the location (i.e.&nbsp;the LocationID factor), but also the <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, <img src="https://latex.codecogs.com/png.latex?L_%7BA10%7D-L_%7BA90%7D">, and <img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"> features whose effects vary across locations. These slopes are given in Figure&nbsp;4. This point highlights the need to consider how the context of a location will influence the relationship between the acoustic features and the perceived pleasantness.</p>
<div id="fig-random" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-random-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure4.jpg" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-random-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: (Color online) Location-level scaled coefficients for the ISOPleasant model.
</figcaption>
</figure>
</div>
</section>
<section id="isoeventful-model-selected" class="level4" data-number="3.2.2">
<h4 data-number="3.2.2" class="anchored" data-anchor-id="isoeventful-model-selected"><span class="header-section-number">3.2.2</span> ISOEventful model selected</h4>
<p>Through the group-level feature selection, all of the group-level coefficients were removed, including the LocationID factor itself. Therefore the final ISOEventful model is a ‘flat’ multi-variate linear regression model, rather than a multi-level model. The ISOEventful model is a linear combination of S, FS, T, <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">, and <img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D">. The training and testing MAE are very similar, indicating that the model is not over-fit to the training data (<img src="https://latex.codecogs.com/png.latex?MAE_%7Btrain%7D%20=%200.233">; <img src="https://latex.codecogs.com/png.latex?MAE_%7Btest%7D%20=%200.231">). The model performs slightly worse than the ISOPleasant at predicting the mean location responses, but still performs well (<img src="https://latex.codecogs.com/png.latex?R%5E2_%7Btrain%7D%20=%200.873">; <img src="https://latex.codecogs.com/png.latex?R%5E2_%7Btest%7D%20=%200.715">).</p>
</section>
<section id="sec-application" class="level4" data-number="3.2.3">
<h4 data-number="3.2.3" class="anchored" data-anchor-id="sec-application"><span class="header-section-number">3.2.3</span> Application to lockdown data</h4>
<div id="fig-locations" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-locations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure5.jpg" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-locations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: (Color online) Soundscape circumplex coordinates for (a) the mean ISOPleasant and ISOEventful responses for each location; and (b) the mean predicted responses based on recordings made during the lockdown and the change in the location’s placement in the circumplex. In (b) the marker outline is shown for the 2019 location, red arrows indicate the change in the location’s coordinates.
</figcaption>
</figure>
</div>
<p>Once the two models were built and assessed, they were then applied to the lockdown recording data in order to predict the new soundscape ISO coordinates. Figure&nbsp;5 (a) shows the pre-lockdown ISO coordinates for each location and Figure&nbsp;5 (b) shows how the soundscapes are predicted to have been assessed during the lockdown period. As in the model assessment process, the predicted responses are calculated for each recording individually, then the mean for each location is calculated and plotted on the circumplex.</p>
<p>In 2019 the majority of locations in the dataset fall within the ‘vibrant’ quadrant of the circumplex, particularly those which are primarily dominated by human activity (e.g.&nbsp;San Marco, Tate Modern). Camden Town and Euston Tap, which are both in general visually and acoustically dominated by traffic, are the only two to be rated as ‘chaotic’, while no locations are overall considered to be ‘monotonous’. During the 2020 lockdown, there is general positive move along the ‘pleasant’ dimension and general negative move along the ‘eventful’ dimension, but several different patterns of movement can be noted. These are investigated further in the Discussion section below.</p>
</section>
</section>
</section>
<section id="discussion" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="discussion"><span class="header-section-number">4</span> Discussion</h2>
<section id="interpretation-of-the-results" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="interpretation-of-the-results"><span class="header-section-number">4.1</span> Interpretation of the results</h3>
<p>To interpret the results addressing the RQ1 and RQ2, it is necessary to separately look into the overall change in sound source composition, and the change in the affective quality of soundscapes per location.</p>
<section id="change-in-the-sound-source-composition" class="level4" data-number="4.1.1">
<h4 data-number="4.1.1" class="anchored" data-anchor-id="change-in-the-sound-source-composition"><span class="header-section-number">4.1.1</span> Change in the sound source composition</h4>
<p>The open-ended question about sound sources in the online survey did not reveal a change in sound source types but rather confirmed that all types were still present in both conditions. The sound source composition question taken from the Method A of the <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (2018)</span> revealed a statistically significant reduction in human sound sources and a significant increase in the perceived dominance of natural sound sources.</p>
<p>The most frequent sound sources detected from the open-ended question correspond to the main four sound source types investigated, which indicated that all types remained present in the lockdown condition (at all the locations). While traffic intensity might have gone down, where the results of the Mann-Whitney U-test were inconclusive, but supported by the psychoacoustic measurements <span class="citation" data-cites="Aletta2020Assessing">(Aletta et al. 2020)</span>, traffic-related sound sources were still clearly present.</p>
<p>The sound source composition of an outdoor acoustic environment is extremely complex. Removing one component, such as human sounds, has implications on the whole <span class="citation" data-cites="Gordo2021Rapid">(Gordo et al. 2021)</span>. Testing the effects of this in situ is not straightforward and interpreting this study in line with ‘what is the impact of human sounds’ must be taken within the broader context of the range of conditions which changed within the acoustic environment. However, looking at the overarching picture, the lockdown condition was a useful and unique case study to understand the impact which human activities – and the human sound source type in particular – can have on soundscape perception of urban open spaces.</p>
</section>
<section id="predicted-relative-changes-in-soundscapes-due-to-covid-19-restrictions" class="level4" data-number="4.1.2">
<h4 data-number="4.1.2" class="anchored" data-anchor-id="predicted-relative-changes-in-soundscapes-due-to-covid-19-restrictions"><span class="header-section-number">4.1.2</span> Predicted relative changes in soundscapes due to COVID-19 restrictions</h4>
<div id="fig-vectors" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vectors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure6.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vectors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: (Color online) The relative change in soundscape perception in the circumplex due to the COVID-19 lockdowns as predicted by the models, represented as vectors centered on the origin. <em>The lawn-works dominated session is shown separately as MonumentoGaribaldi</em> with a gray arrow to indicate that this is distinct from the effects of the lockdown changes.
</figcaption>
</figure>
</div>
<p>In order to interpret how the change of the acoustic environment at the locations examined would have been perceived, and to answer RQ2, relative change vectors within the circumplex space are shown in Figure . This clearly shows a few different patterns of soundscape change due to the effects of the 2020 lockdown. These can be further looked into depending on the magnitude and direction of change, shifts between quadrants shown in Figure&nbsp;5, and the sound source composition. The discussion below is organized according to groups of locations which show similar behaviors in the predicted magnitude and direction of change, or discusses a single location which is particularly notable.</p>
<section id="piazza-san-marco" class="level5" data-number="4.1.2.1">
<h5 data-number="4.1.2.1" class="anchored" data-anchor-id="piazza-san-marco"><span class="header-section-number">4.1.2.1</span> Piazza San Marco</h5>
<p>The largest change is seen in Piazza San Marco, with a predicted increase in pleasantness of 0.24 and a decrease in eventfulness of 0.44, enough to move the soundscape out of the ‘vibrant’ quadrant and into ‘calm’. This extreme change (relative to the rest of the locations) is exactly what would be expected given the unique context of the measurements taken in 2019 – the measurement campaign corresponded with Carnevale, a yearly festival which centers around the square. By contrast, due to the particularly strict measures imposed in Italy, during the lockdown measurement period, the square was almost entirely devoid of people. What is promising is that, without any of this contextual information about the presence or absence of people, our model is able to capture and reflect what may be considered a reasonable and expected direction and scale of change within the soundscape circumplex.</p>
</section>
<section id="locations-showing-an-increase-in-pleasantness" class="level5" data-number="4.1.2.2">
<h5 data-number="4.1.2.2" class="anchored" data-anchor-id="locations-showing-an-increase-in-pleasantness"><span class="header-section-number">4.1.2.2</span> Locations showing an increase in pleasantness</h5>
<p>The next locations of interest are those which, in the 2019 survey data, were rated as being dominated by traffic noise: Euston Tap, Camden Town, Torrington Square, and Pancras Lock. These are the only locations (besides San Marco) which show a predicted increase in pleasantness. Of these traffic-dominated spaces, the two which were most heavily dominated by traffic noise (Camden Town and Euston Tap) showed the most increase in pleasantness, with Torrington Square having slightly less of an increase. Pancras Lock, which was also rated as having high levels of both Human and Natural sounds shows only a modest improvement in pleasantness.</p>
</section>
<section id="locations-showing-a-decrease-in-pleasantness" class="level5" data-number="4.1.2.3">
<h5 data-number="4.1.2.3" class="anchored" data-anchor-id="locations-showing-a-decrease-in-pleasantness"><span class="header-section-number">4.1.2.3</span> Locations showing a decrease in pleasantness</h5>
<p>Among the locations which are predicted to experience a negative effect on pleasantness we see a mix of spaces which were assessed as being dominated by Human (St Pauls Cross and Tate Modern) and Natural (Regents Park Japan, Regents Park Fields, Russell Square) sounds before the lockdown. It is hard to discern a pattern of difference between these two groups, although it appears that the Human-dominated spaces saw a greater reduction in eventfulness, compared to the Natural-dominated spaces.</p>
<p>In general, we note that most of the spaces experience some degree of reduction in eventfulness. This pattern is particularly consistent with what would be expected from a reduction in human presence in these spaces <span class="citation" data-cites="Aletta2018Towards">(Aletta and Kang 2018)</span>, as reflected by the observation that, in general, those spaces which had the most human sounds prior to the lockdown showed the greatest reduction in eventfulness during the lockdown. In particular, Tate Modern, Camden Town, and Torrington Square show the greatest reduction in eventfulness. This appears to be due to these locations showing the greatest reduction in overall <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"> compared to other locations (8.1 dB, 5.2 dB, and 9.2 dB, respectively), with <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"> being the most influential feature in the eventfulness model, as shown in Table&nbsp;4. However, Russell Square also experienced a large decrease in <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"> on average (10.5 dB) but does not show the same reduction in eventfulness. This appears due to the correspondingly large decrease in <img src="https://latex.codecogs.com/png.latex?S"> (1.17 acum) which is not seen at the 3 previously mentioned locations. Russell Square normally features a medium-sized jet fountain which was turned off during the lockdowns in 2020 and therefore it experienced a drop in the overall sound level, but an increase in the proportion of low frequency noise to high frequency noise reflected by a decrease in sharpness which, within the eventfulness model, effectively cancels out the impact of the reduction in <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D">. While the overall sound level has an important impact, in order to determine the true impact a reduction in sound level may have, it must be taken in context with how the other aspects of the sound will also change.</p>
</section>
<section id="euston-tap" class="level5" data-number="4.1.2.4">
<h5 data-number="4.1.2.4" class="anchored" data-anchor-id="euston-tap"><span class="header-section-number">4.1.2.4</span> Euston Tap</h5>
<p>An unexpected result is that Euston Tap is predicted to experience an increase in eventfulness and it is unclear whether this accurately reflects the real experience people would have had in the space. Normally, Euston Tap is a mostly-outdoor drinking venue located at the entrance to London Euston Station and situated directly along a very busy central London road. During the 2020 survey, the researchers noted that the music and chatter of people from the pub was noticeably missing, but that the perceived reduction in road traffic was minimal. Based on the theory of vibrancy which would suggest it is driven by human presence and sounds <span class="citation" data-cites="Aletta2018Towards">(Aletta and Kang 2018)</span>, we would not therefore expect a shift in the vibrant direction as indicated here. This discrepancy may reveal a weakness in the context-independent ISOEventful model, or it may in fact be indicating that, at certain thresholds of traffic noise, a reduction in level – and therefore a reduction in energetic masking – will allow other aspects of the sound to influence the perception.</p>
</section>
<section id="monumento-garibaldi" class="level5" data-number="4.1.2.5">
<h5 data-number="4.1.2.5" class="anchored" data-anchor-id="monumento-garibaldi"><span class="header-section-number">4.1.2.5</span> Monumento Garibaldi</h5>
<p>Finally, special attention should be paid to the results shown for Monumento Garibaldi, which in 2019 was perceived as a pleasant and slightly calm green space featuring a gravel walkway. During the first measurement session during the lockdown in 2020, the researcher noted that the soundscape was dominated by landscaping works, in particular noise from strimmers (or weed whackers). In order to gain a sample which was more representative of the impact of the lockdowns, the researcher returned another day to repeat the measurements without interference from the works.</p>
<p>To examine the impact of these two scenarios separately, the prediction model was fitted to the data from the two sessions independently and the session which was impacted by the landscaping works is shown in Figure&nbsp;6 in gray and labeled MonumentoGaribaldi*, while the unaffected session is shown in red. In the latter case, the predicted change in soundscape as a result of the lockdown fits neatly into what would be expected and closely matches the predicted behavior of similar locations in London (i.e.&nbsp;Marchmont Garden and Russell Square). On the other hand, the session which was dominated by noise from the strimmers is predicted to have become much more chaotic, with a decrease in pleasantness of 0.16 and an increase in eventfulness of 0.27. This indicates that, although the model has no contextual information about the type of sound and in fact the training data never included sounds from similar equipment, just based on the psychoacoustic features of the sound it is able to reasonably predict the expected change in soundscape.</p>
</section>
<section id="general-notes" class="level5" data-number="4.1.2.6">
<h5 data-number="4.1.2.6" class="anchored" data-anchor-id="general-notes"><span class="header-section-number">4.1.2.6</span> General notes</h5>
<p>As a whole, the primary impact of the 2020 lockdowns on the soundscapes in London and Venice was an overall decrease in eventfulness. With the exception of Euston Tap, all of the sessions show some degree of reduction in eventfulness, reflecting the general decrease in sound levels and human sound sources across the locations. The impact of the lockdowns on pleasantness is more mixed and seems to be driven by the previous dominance of traffic noise in the space. However, it could also be noted that, while all locations experienced a reduction in sound level, those which are predicted to become more pleasant had an average <img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"> above 60 dB in 2019. By contrast, the locations which were predicted to experience a decrease in pleasantness generally had sound levels below 60 dBA in 2019. This may indicate that reductions in sound level can improve pleasantness when the sound level exceeds some threshold of around 60 - 65 dBA but are ineffective when sound levels are below this threshold. Similarly, <span class="citation" data-cites="Yang2005Acoustic">Yang and Kang (2005)</span> showed that, when the sound level is ‘lower than a certain value, say 70 dB’ there is no longer a significant improvement in the evaluation of acoustic comfort as the sound level reduces. It is unclear at this point where this threshold would lie for pleasantness/annoyance, how strict it may be, or how it is impacted by the sound source composition of the acoustic environment, therefore further research is needed in this area.</p>
</section>
</section>
<section id="model-selection-results" class="level4" data-number="4.1.3">
<h4 data-number="4.1.3" class="anchored" data-anchor-id="model-selection-results"><span class="header-section-number">4.1.3</span> Model selection results</h4>
<p>The most immediately interesting result of the model-building and feature selection process, answering to RQ3, is the apparent irrelevance of location context to the ISOEventful dimension. The multilevel model structure was chosen since the starting assumption was that soundscape perception is heavily influenced by contextual factors, such as expectations of the space and visual context <span class="citation" data-cites="Ricciardi2015Sound">(Ricciardi et al. 2015)</span>. For this modeling, these factors can be considered as location-level latent variables at least partially accounted for by the inclusion of the LocationID as the second-level factor. While this assumption certainly held true for ISOPleasant, our results indicate that these types of contextual factors are not significant for ISOEventful, and do not affect the relationship between the acoustic features of the sound and the perception.</p>
<p>In particular this result may herald a shift in modeling approach for soundscapes – where previous methods, in both the soundscape and noise paradigms, have mostly focused on deriving acoustic models of annoyance (in other words have focused on the ISOPleasant dimension) perhaps they should instead consider the acoustic models as primarily describing the eventfulness dimension when considered in situ. In addition this study takes the approach of modeling responses at an individual level in order to derive the soundscape assessment of the location. Rather than either attempting to represent the predicted response of an individual person – which is less useful in this sort of practical application – or to base the model on average metrics of the location, the goal is instead to characterize the location itself, through the aggregated predicted responses of individuals. The authors believe this modeling approach better addresses the practical goal of predictive soundscape modeling and reflects the structure of the data collection.</p>
</section>
</section>
<section id="limitations-of-the-study" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="limitations-of-the-study"><span class="header-section-number">4.2</span> Limitations of the study</h3>
<p>The onsite sampling method was initially not intended as the ultimate characterization of a location’s soundscape but rather as a tool for model development. Therefore, the change observed does not necessarily represent the ground truth about the site’s soundscape, if such a thing exists. Further, the online listening tests took a relatively small but random sample from the available database and did not include any contextual information. This proved to be sufficient for the purpose of detecting a change in sound source composition, however the relatively small sample of recordings included in the online study does limit how representative they are of the location’s sound environment as a whole. Similarly, the surveys and recordings taken represent only a snapshot of the soundscape or sound environment for a short period in time. This is a flaw in most soundscape sampling methods presented both in the literature and in ISO/TS 12913-2. To truly be said to characterize the soundscape of a space, long-term monitoring and survey methods will need to be developed in order to capture the changing environmental and contextual conditions in the space. Models of the sort presented here, which are based on measurable quantities, could prove to be useful in this sort of longterm monitoring as they could take continuous inputs from sensors and generate the likely soundscape assessment over time.</p>
<p>The audio-visual interaction forms a key component in people’s perception of urban spaces. This consideration has been a strength of soundscape research and has been incorporated via the use of in situ data collection. However, the visual aspect, and in particular how the visual environment changed as a result of the lockdown condition, was not considered in this study, reducing the comprehensiveness of the model. This was due primarily to data collection limitations imposed by the lockdown restrictions which made it impractical to replicate the <img src="https://latex.codecogs.com/png.latex?360%5E%7B%5Ccirc%7D"> videos made during the 2019 sessions. Future work on comprehensive predictive soundscape models should strive to make use of this visual aspect within their considered features.</p>
<p>The limitation of the sound source categorization adopted from the ISO standard is that it may not be clear to a respondent in which category they would place community sounds like church bells and music. This may be particularly relevant for comparing the lockdown condition, as in particular the ringing of bells for worship varied in different contexts throughout the pandemic. Whether bells ceased entirely or were increased not only would have an impact on the sound environment, but the purposeful action behind the decision to ring bells may have changed to public’s relationship to and perception of the sound itself <span class="citation" data-cites="Parker2020Anthropause">(Parker and Spennemann 2020)</span>. The open ended question on sound sources, however, revealed the presence of church bells in both years. Unfortunately, this is a limitation of the sound source categories given by the ISO standard on which this questionnaire was based. A sensible update based on the findings and experiences reported here would be to combine the Traffic and Other Noise categories as separating them does not appear to provide additional information, and to include a new category which would in some way encapsulate the types of community sounds for which there is currently not a clear category.</p>
<p>Further, the lockdown condition is likely to cause distortions of the circumplex soundscape perception model. Therefore, it is important to acknowledge that all the predictions were made for the people with no experience of the pandemic and its psychological effects. Conceptually, this model captured the perceptual mapping (i.e.&nbsp;the relationship between the acoustic indicator inputs and the soundscape descriptor outputs) of people in 2019, but this perceptual mapping is likely to have been affected by the psychological and contextual impacts of the lockdown itself, independent of its changes on the sound environment. Future research might look into potential perception changes in the post-pandemic world.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">5</span> Conclusion</h2>
<p>This study demonstrates an application of predictive modeling to the field of soundscape studies. The model building results reveal that, within this dataset, an approach based on psychoacoustics can achieve <img src="https://latex.codecogs.com/png.latex?R%5E2%20=%200.85"> for predicting the pleasantness of locations and <img src="https://latex.codecogs.com/png.latex?R%5E2%20=%200.715"> for predicting the eventfulness. A modeling–focused method of this sort is a key component to the potential scalability of the soundscape approach to applications such as smart city sensing, urban planning, and cost-effective, sustainable design. To demonstrate the usefulness and feasibility of such an approach, we apply our predictive model to a unique case study in which traditional soundscape survey methods were impossible.</p>
<p>By applying this predictive model to recordings collected during the 2020 lockdown, the change in perception of the urban soundscapes is revealed. In general, soundscapes became less eventful, and those locations which were previously dominated by traffic noise became more pleasant. By contrast, previously human- and natural-dominated locations are in fact predicted to become less pleasant despite the decrease in sound levels. While all sound source categories remained present in both years, overall, in 2020 a decrease in human sounds’ dominance was observed together with an increase in the perceived dominance of natural sounds. Although these results are limited in that they represent one snapshot of the soundscape of the spaces, the success of the model in responding to new and disturbing sound events demonstrates its potential usefulness in long-term monitoring of urban soundscapes.</p>
</section>



<section id="references" class="level2 unnumbered">




</section>


<div id="quarto-appendix" class="default"><section id="acknowledgements" class="level2 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">Acknowledgements</h2><div class="quarto-appendix-contents">

<p>This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (Grant Agreement No.&nbsp;740696, project title: Soundscape Indices – SSID). More information and related publications can be found at the CORDIS webpage of the project<sup>7</sup>.</p>
<p>The authors would like to thank Zhongzhe Li for conducting binaural recordings at Euston Square Gardens and Torrington Square in 2019. The authors would like to thank Meihui Ba, Nicolas Assiotis, Veronica Rugeles Allan, Yu Wang and Hua Su for their help in conducting on-site surveys during the spring and the autumn of 2019.</p>
<p>On-site study data were collected and managed using REDCap electronic data capture tools hosted at University College London (UCL).</p>
</div></section><section id="appendix-a-online-survey-questionnaire" class="level2 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">Appendix A: Online survey questionnaire</h2><div class="quarto-appendix-contents">

<div id="tbl-gorilla" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-gorilla-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5: Questionnaire deployed via the Gorilla Experiment Builder
</figcaption>
<div aria-describedby="tbl-gorilla-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 7%">
<col style="width: 92%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Q1</strong></td>
<td><strong>While listening, please note any sound sources you can identify in this sound environment</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Q2</strong></td>
<td><strong>To what extent have you heard the following four types of sounds?</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td><strong>Traffic noise (e.g., cars, buses, trains, airplanes)</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td>Not at all / A little / Moderately / A lot / Dominates completely</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td><strong>Other noise (e.g., sirens, construction, industry, loading of goods)</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td>Not at all / A little / Moderately / A lot / Dominates completely</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td><strong>Sounds from human beings (e.g., conversation, laughter, children at play, footsteps)</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td>Not at all / A little / Moderately / A lot / Dominates completely</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td><strong>Natural sounds (e.g., singing birds, flowing water, wind in vegetation)</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td>Not at all / A little / Moderately / A lot / Dominates completely</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div></section><section id="sec-appmod" class="level2 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">Appendix B: Model Results</h2><div class="quarto-appendix-contents">

<p>Table&nbsp;6 presents the unscaled coefficients for the ISOPleasant and ISOEventful predictive models. The scaled coefficients are presented in the body of the text to facilitate comparisons between the various factors. However, we feel it is important to present unscaled coefficients such that these models could be implemented and compared for future work.</p>
<div id="tbl-unscl" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-unscl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6: The unscaled linear regression models of ISOPleasant and ISOEventful for 13 locations in London and Venice. Statistically significant p-values are highlighted in bold.
</figcaption>
<div aria-describedby="tbl-unscl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 28%">
<col style="width: 20%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 9%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>ISOPleasant</th>
<th></th>
<th></th>
<th>ISOEventful</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Predictors</td>
<td>Estimates</td>
<td>Confidence Interval (CI)</td>
<td>p</td>
<td>Estimates</td>
<td>CI</td>
<td>p</td>
</tr>
<tr class="even">
<td>(Intercept)</td>
<td>0.38</td>
<td>0.28–0.50</td>
<td>&lt;0.001</td>
<td>-0.77</td>
<td>-1.05-0.48</td>
<td>&lt;0.001</td>
</tr>
<tr class="odd">
<td>N5</td>
<td>−0.01</td>
<td>−0.01–0.00</td>
<td>&lt;0.001</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>S</td>
<td></td>
<td></td>
<td></td>
<td>−0.17</td>
<td>−0.23–0.12</td>
<td>&lt;0.001</td>
</tr>
<tr class="odd">
<td>FS</td>
<td></td>
<td></td>
<td></td>
<td>−1.36</td>
<td>−2.61–0.11</td>
<td>0.033</td>
</tr>
<tr class="even">
<td>T</td>
<td></td>
<td></td>
<td></td>
<td>0.24</td>
<td>0.08–0.39</td>
<td>0.002</td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?L_%7BAeq%7D"></td>
<td></td>
<td></td>
<td></td>
<td>0.02</td>
<td>0.08–0.29</td>
<td>&lt;0.001</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?L_%7BCeq%7D-L_%7BAeq%7D"></td>
<td></td>
<td></td>
<td></td>
<td>−0.01</td>
<td>−0.02–0.00</td>
<td>0.052</td>
</tr>
<tr class="odd">
<td><strong>Random effects</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"></td>
<td>0.11</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Ctau_%7B00%7D"></td>
<td><img src="https://latex.codecogs.com/png.latex?1.01_%7BLocationID%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Ctau_%7B11%7D"></td>
<td><img src="https://latex.codecogs.com/png.latex?0.00_%7BLocationID.L_%7BAeq%7D%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?0.00_%7BLocationID.L_%7BA10%7D-L_%7BA90%7D%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?0.00_%7BLocationID.L_%7BCeq%7D-L_%7BAeq%7D%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>ICC</td>
<td>0.90</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>N</td>
<td><img src="https://latex.codecogs.com/png.latex?13_%7BLocationID%7D"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Observations</td>
<td>914</td>
<td></td>
<td></td>
<td>914</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="fig-unsclRandom" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-unsclRandom-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/Figure7.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-unsclRandom-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: (Color online) The unscaled location-level coefficients for the ISOPleasant model.
</figcaption>
</figure>
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-Aiello2016Chatty" class="csl-entry">
Aiello, Luca Maria, Rossano Schifanella, Daniele Quercia, and Francesco Aletta. 2016. <span>“Chatty Maps: Constructing Sound Maps of Urban Areas from Social Media Data.”</span> <em>Royal Society Open Science</em> 3 (3): 150690. <a href="https://doi.org/10.1098/rsos.150690">https://doi.org/10.1098/rsos.150690</a>.
</div>
<div id="ref-Akaike1974new" class="csl-entry">
Akaike, H. 1974. <span>“A New Look at the Statistical Model Identification.”</span> <em><span>IEEE</span> Transactions on Automatic Control</em> 19 (6): 716–23. <a href="https://doi.org/10.1109/tac.1974.1100705">https://doi.org/10.1109/tac.1974.1100705</a>.
</div>
<div id="ref-Aletta2017Dimensions" class="csl-entry">
Aletta, Francesco, Östen Axelsson, and Jian Kang. 2017. <span>“<span class="nocase">Dimensions underlying the perceived similarity of acoustic environments</span>.”</span> <em>Frontiers in Psychology</em> 8 (July): 1–11. <a href="https://doi.org/10.3389/fpsyg.2017.01162">https://doi.org/10.3389/fpsyg.2017.01162</a>.
</div>
<div id="ref-Aletta2018Towards" class="csl-entry">
Aletta, Francesco, and Jian Kang. 2018. <span>“<span class="nocase">Towards an urban vibrancy model: A soundscape approach</span>.”</span> <em>International Journal of Environmental Research and Public Health</em> 15 (8): 1712. <a href="https://doi.org/10.3390/ijerph15081712">https://doi.org/10.3390/ijerph15081712</a>.
</div>
<div id="ref-Aletta2016Soundscape" class="csl-entry">
Aletta, Francesco, Jian Kang, and Östen Axelsson. 2016. <span>“<span class="nocase">Soundscape descriptors and a conceptual framework for developing predictive soundscape models</span>.”</span> <em>Landscape and Urban Planning</em> 149 (July): 65–74. <a href="https://doi.org/10.1016/j.landurbplan.2016.02.001">https://doi.org/10.1016/j.landurbplan.2016.02.001</a>.
</div>
<div id="ref-Aletta2020Assessing" class="csl-entry">
Aletta, Francesco, Tin Oberman, Andrew Mitchell, Huan Tong, and Jian Kang. 2020. <span>“<span class="nocase">Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term acoustic measurements</span>.”</span> <em>Noise Mapping</em> 7 (1): 123–34. <a href="https://doi.org/10.1515/noise-2020-0011">https://doi.org/10.1515/noise-2020-0011</a>.
</div>
<div id="ref-AlsinaPages2021Changes" class="csl-entry">
Alsina-Pagès, Rosa Ma, Pau Bergadà, and Carme Martı́nez-Suquı́a. 2021. <span>“Changes in the Soundscape of <span>G</span>irona During the <span>COVID</span> Lockdown.”</span> <em>The Journal of the Acoustical Society of America</em> 149 (5): 3416–23. <a href="https://doi.org/10.1121/10.0004986">https://doi.org/10.1121/10.0004986</a>.
</div>
<div id="ref-AnwylIrvine2019Gorilla" class="csl-entry">
Anwyl-Irvine, Alexander L., Jessica Massonnié, Adam Flitton, Natasha Kirkham, and Jo K. Evershed. 2019. <span>“Gorilla in Our Midst: An Online Behavioral Experiment Builder.”</span> <em>Behavior Research Methods</em> 52 (1): 388–407. <a href="https://doi.org/10.3758/s13428-019-01237-x">https://doi.org/10.3758/s13428-019-01237-x</a>.
</div>
<div id="ref-Asensio2020Taxonomy" class="csl-entry">
Asensio, César, Pierre Aumond, Arnaud Can, Luis Gascó, Peter Lercher, Jean-Marc Wunderli, Catherine Lavandier, et al. 2020. <span>“A <span>Taxonomy</span> <span>Proposal</span> for the <span>Assessment</span> of the <span>Changes</span> in <span>Soundscape</span> <span>Resulting</span> from the <span>COVID</span>-19 <span>Lockdown</span>.”</span> <em>International Journal of Environmental Research and Public Health</em> 17 (12): 4205. <a href="https://doi.org/10.3390/ijerph17124205">https://doi.org/10.3390/ijerph17124205</a>.
</div>
<div id="ref-Asensio2020Changes" class="csl-entry">
Asensio, César, Ignacio Pavón, and Guillermo de Arcas. 2020. <span>“Changes in Noise Levels in the City of <span>Madrid</span> During <span>COVID</span>-19 Lockdown in 2020.”</span> <em>The Journal of the Acoustical Society of America</em> 148 (3): 1748–55. <a href="https://doi.org/10.1121/10.0002008">https://doi.org/10.1121/10.0002008</a>.
</div>
<div id="ref-Axelsson2010principal" class="csl-entry">
Axelsson, Östen, Mats E. Nilsson, and Birgitta Berglund. 2010. <span>“<span class="nocase">A principal components model of soundscape perception</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 128 (5): 2836–46. <a href="https://doi.org/10.1121/1.3493436">https://doi.org/10.1121/1.3493436</a>.
</div>
<div id="ref-BonetSola2021Soundscape" class="csl-entry">
Bonet-Solà, Daniel, Carme Martı́nez-Suquı́a, Rosa Ma Alsina-Pagès, and Pau Bergadà. 2021. <span>“The Soundscape of the <span>COVID</span>-19 Lockdown: <span>B</span>arcelona Noise Monitoring Network Case Study.”</span> <em>International Journal of Environmental Research and Public Health</em> 18 (11): 5799. <a href="https://doi.org/10.3390/ijerph18115799">https://doi.org/10.3390/ijerph18115799</a>.
</div>
<div id="ref-Erfanian2021Psychological" class="csl-entry">
Erfanian, Mercede, Andrew Mitchell, Francesco Aletta, and Jian Kang. 2021. <span>“Psychological Well-Being and Demographic Factors Can Mediate Soundscape Pleasantness and Eventfulness: A Large Sample Study.”</span> <em>Journal of Environmental Psychology</em> 77 (October): 101660. <a href="https://doi.org/10.1016/j.jenvp.2021.101660">https://doi.org/10.1016/j.jenvp.2021.101660</a>.
</div>
<div id="ref-EuropeanUnion2002Directive" class="csl-entry">
European Union. 2002. <em><span class="nocase">Directive 2002/49/EC of the European Parliament and of the Council of 25 June 2002 relating to the assessment and management of environmental noise</span></em>.
</div>
<div id="ref-Gontier2019Estimation" class="csl-entry">
Gontier, Félix, Catherine Lavandier, Pierre Aumond, Mathieu Lagrange, and Jean-François Petiot. 2019. <span>“Estimation of the Perceived Time of Presence of Sources in Urban Acoustic Environments Using Deep Learning Techniques.”</span> <em>Acta Acustica United with Acustica</em> 105 (6): 1053–66. <a href="https://doi.org/10.3813/aaa.919384">https://doi.org/10.3813/aaa.919384</a>.
</div>
<div id="ref-Gordo2021Rapid" class="csl-entry">
Gordo, Oscar, Lluı́s Brotons, Sergi Herrando, and Gabriel Gargallo. 2021. <span>“Rapid Behavioural Response of Urban Birds to <span>COVID</span>-19 Lockdown.”</span> <em>Proceedings of the Royal Society B: Biological Sciences</em> 288 (1946): 20202513. <a href="https://doi.org/10.1098/rspb.2020.2513">https://doi.org/10.1098/rspb.2020.2513</a>.
</div>
<div id="ref-Hadjidemetriou2020impact" class="csl-entry">
Hadjidemetriou, Georgios M., Manu Sasidharan, Georgia Kouyialis, and Ajith K. Parlikad. 2020. <span>“The Impact of Government Measures and Human Mobility Trend on <span>COVID</span>-19 Related Deaths in the <span>UK</span>.”</span> <em>Transportation Research Interdisciplinary Perspectives</em> 6 (July): 100167. <a href="https://doi.org/10.1016/j.trip.2020.100167">https://doi.org/10.1016/j.trip.2020.100167</a>.
</div>
<div id="ref-Hornberg2021Impact" class="csl-entry">
Hornberg, Jonas, Timo Haselhoff, Bryce T. Lawrence, Jonas L. Fischer, Salman Ahmed, Dietwald Gruehn, and Susanne Moebus. 2021. <span>“Impact of the <span>COVID</span>-19 Lockdown Measures on Noise Levels in Urban Areas<span></span>a Pre/During Comparison of Long-Term Sound Pressure Measurements in the <span>R</span>uhr <span>A</span>rea, <span>G</span>ermany.”</span> <em>International Journal of Environmental Research and Public Health</em> 18 (9): 4653. <a href="https://doi.org/10.3390/ijerph18094653">https://doi.org/10.3390/ijerph18094653</a>.
</div>
<div id="ref-IEC2013Electroacoustics" class="csl-entry">
IEC 61672-1:2013. 2013. <span>“<span class="nocase">Electroacoustics – Sound level mdeters – Part 1: Specifications</span>.”</span> <a href="https://webstore.iec.ch/publication/5708">https://webstore.iec.ch/publication/5708</a>.
</div>
<div id="ref-ISO12913Part1" class="csl-entry">
ISO 12913-1:2014. 2014. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 1: <span>Definition</span> and Conceptual Framework.”</span>
</div>
<div id="ref-ISO2016Acoustics" class="csl-entry">
ISO 1996-1:2016. 2016. <span>“<span class="nocase">Acoustics – Description, measurement and assessment of environmental noise – Part 1: Basic quantities and assessment procedures</span>.”</span> <a href="https://www.iso.org/standard/59765.html">https://www.iso.org/standard/59765.html</a>.
</div>
<div id="ref-ISO2017Acoustics" class="csl-entry">
ISO 532-1:2017. 2017. <span>“<span class="nocase">Acoustics – Methods for calculating loudness – Part 1: Zwicker method</span>.”</span> <a href="https://www.iso.org/standard/63077.html">https://www.iso.org/standard/63077.html</a>.
</div>
<div id="ref-ISO12913Part2" class="csl-entry">
ISO/TS 12913-2:2018. 2018. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 2: <span>Data</span> Collection and Reporting Requirements.”</span>
</div>
<div id="ref-ISO12913Part3" class="csl-entry">
ISO/TS 12913-3:2019. 2019. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 3: <span>Data</span> Analysis.”</span>
</div>
<div id="ref-Kang2006Urban" class="csl-entry">
Kang, Jian. 2006. <em>Urban <span>S</span>ound <span>E</span>nvironment</em>. <span>CRC</span> Press. <a href="https://doi.org/10.1201/9781482265613">https://doi.org/10.1201/9781482265613</a>.
</div>
<div id="ref-Kang2018Impact" class="csl-entry">
Kang, Jian, and Francesco Aletta. 2018. <span>“<span class="nocase">The Impact and Outreach of Soundscape Research</span>.”</span> <em>Environments</em> 5 (5): 58. <a href="https://doi.org/10.3390/environments5050058">https://doi.org/10.3390/environments5050058</a>.
</div>
<div id="ref-Kuznetsova2017lmerTest" class="csl-entry">
Kuznetsova, Alexandra, Per B. Brockhoff, and Rune H. B. Christensen. 2017. <span>“<span class="nocase">lmerTest</span> Package: Tests in Linear Mixed Effects Models.”</span> <em>Journal of Statistical Software</em> 82 (13). <a href="https://doi.org/10.18637/jss.v082.i13">https://doi.org/10.18637/jss.v082.i13</a>.
</div>
<div id="ref-Lenzi2021Soundscape" class="csl-entry">
Lenzi, Sara, Juan Sádaba, and PerMagnus Lindborg. 2021. <span>“Soundscape in Times of Change: <span>C</span>ase Study of a City Neighbourhood During the <span>COVID</span>-19 Lockdown.”</span> <em>Frontiers in Psychology</em> 12 (March). <a href="https://doi.org/10.3389/fpsyg.2021.570741">https://doi.org/10.3389/fpsyg.2021.570741</a>.
</div>
<div id="ref-Lionello2020systematic" class="csl-entry">
Lionello, Matteo, Francesco Aletta, and Jian Kang. 2020. <span>“<span class="nocase">A systematic review of prediction models for the experience of urban soundscapes</span>.”</span> <em>Applied Acoustics</em> 170 (June). <a href="https://doi.org/10.1016/j.apacoust.2020.107479">https://doi.org/10.1016/j.apacoust.2020.107479</a>.
</div>
<div id="ref-Lionello2021Introducing" class="csl-entry">
Lionello, Matteo, Francesco Aletta, Andrew Mitchell, and Jian Kang. 2021. <span>“<span class="nocase">Introducing a Method for Intervals Correction on Multiple Likert Scales: A Case Study on an Urban Soundscape Data Collection Instrument</span>.”</span> <em>Frontiers in Psychology</em> 11: 3943. <a href="https://doi.org/10.3389/fpsyg.2020.602831">https://doi.org/10.3389/fpsyg.2020.602831</a>.
</div>
<div id="ref-Luedecke2021sjPlot" class="csl-entry">
Lüdecke, Daniel. 2021. <em>sjPlot: Data Visualization for Statistics in Social Science</em>. <a href="https://CRAN.R-project.org/package=sjPlot">https://CRAN.R-project.org/package=sjPlot</a>.
</div>
<div id="ref-McKnight2010Mann" class="csl-entry">
McKnight, Patrick E., and Julius Najab. 2010. <span>“Mann-Whitney <span>U</span> Test.”</span> John Wiley <span>&amp;</span> Sons, Inc. <a href="https://doi.org/10.1002/9780470479216.corpsy0524">https://doi.org/10.1002/9780470479216.corpsy0524</a>.
</div>
<div id="ref-Mitchell2020Soundscape" class="csl-entry">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. 2020. <span>“<span class="nocase">The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information</span>.”</span> <em>Applied Sciences</em> 10 (7): 2397. <a href="https://doi.org/10.3390/app10072397">https://doi.org/10.3390/app10072397</a>.
</div>
<div id="ref-Mitchell2021International" class="csl-entry">
———. 2021. <span>“<span class="nocase">The International Soundscape Database: An integrated multimedia database of urban soundscape surveys – questionnaires with acoustical and contextual information</span>.”</span> Zenodo. <a href="https://doi.org/10.5281/zenodo.5578572">https://doi.org/10.5281/zenodo.5578572</a>.
</div>
<div id="ref-Munoz2020Lockdown" class="csl-entry">
Munoz, Patricio, Bruno Vincent, Céline Domergue, Vincent Gissinger, Sébastien Guillot, Yann Halbwachs, and Valérie Janillon. 2020. <span>“Lockdown During <span>COVID</span>-19 Pandemic: <span>I</span>mpact on Road Traffic Noise and on the Perception of Sound Environment in <span>F</span>rance.”</span> <em>Noise Mapping</em> 7 (1): 287–302. <a href="https://doi.org/10.1515/noise-2020-0024">https://doi.org/10.1515/noise-2020-0024</a>.
</div>
<div id="ref-Orga2021Multilevel" class="csl-entry">
Orga, Ferran, Andrew Mitchell, Marc Freixes, Francesco Aletta, Rosa Ma Alsina-Pagès, and Maria Foraster. 2021. <span>“<span class="nocase">Multilevel Annoyance Modelling of Short Environmental Sound Recordings</span>.”</span> <em>Sustainability</em> 13 (11): 5779. <a href="https://doi.org/10.3390/su13115779">https://doi.org/10.3390/su13115779</a>.
</div>
<div id="ref-Parker2020Anthropause" class="csl-entry">
Parker, Murray, and Dirk H. R. Spennemann. 2020. <span>“<span class="nocase">Anthropause on audio: The effects of the COVID-19 pandemic on church bell ringing and associated soundscapes in New South Wales (Australia)</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 148 (5): 3102–6. <a href="https://doi.org/10.1121/10.0002451">https://doi.org/10.1121/10.0002451</a>.
</div>
<div id="ref-RCT2018R" class="csl-entry">
R Core Team. 2018. <em><span>R</span>: <span>A</span> <span>L</span>anguage and <span>E</span>nvironment for <span>S</span>tatistical <span>C</span>omputing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-Radicchi2021Sound" class="csl-entry">
Radicchi, Antonella, Pınar Cevikayak Yelmi, Andy Chung, Pamela Jordan, Sharon Stewart, Aggelos Tsaligopoulos, Lindsay McCunn, and Marcus Grant. 2021. <span>“Sound and the Healthy City.”</span> <em>Cities <span>&amp;</span> Health</em> 5 (1-2): 1–13. <a href="https://doi.org/10.1080/23748834.2020.1821980">https://doi.org/10.1080/23748834.2020.1821980</a>.
</div>
<div id="ref-Ren2020Pandemic" class="csl-entry">
Ren, Xuefei. 2020. <span>“Pandemic and Lockdown: <span>A</span> Territorial Approach to <span>COVID</span>-19 in <span>C</span>hina, <span>I</span>taly and the <span>U</span>nited <span>S</span>tates.”</span> <em>Eurasian Geography and Economics</em> 61 (4-5): 423–34. <a href="https://doi.org/10.1080/15387216.2020.1762103">https://doi.org/10.1080/15387216.2020.1762103</a>.
</div>
<div id="ref-Ricciardi2015Sound" class="csl-entry">
Ricciardi, Paola, Pauline Delaitre, Catherine Lavandier, Francesca Torchia, and Pierre Aumond. 2015. <span>“<span class="nocase">Sound quality indicators for urban places in <span>Paris</span> cross-validated by <span>Milan</span> data</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 138: 2337–48. <a href="https://doi.org/10.1121/1.4929747">https://doi.org/10.1121/1.4929747</a>.
</div>
<div id="ref-Rumpler2021Noise" class="csl-entry">
Rumpler, Romain, Siddharth Venkataraman, and Peter Göransson. 2021. <span>“Noise Measurements as a Proxy to Evaluating the Response to Recommendations in Times of Crisis: <span>A</span>n Update Analysis of the Transition to the Second Wave of the <span>CoViD</span>-19 Pandemic in <span>C</span>entral <span>S</span>tockholm, <span>S</span>weden.”</span> <em>The Journal of the Acoustical Society of America</em> 149 (3): 1838–42. <a href="https://doi.org/10.1121/10.0003778">https://doi.org/10.1121/10.0003778</a>.
</div>
<div id="ref-Sakagami2020How" class="csl-entry">
Sakagami, Kimihiro. 2020. <span>“How Did the ’State of Emergency’ Declaration in <span>Japan</span> Due to the <span>COVID-19</span> Pandemic Affect the Acoustic Environment in a Rather Quiet Residential Area?”</span> <em>UCL Open Environment</em>, no. 1: 1–9. <a href="https://doi.org/10.14324/111.444/ucloe.000009">https://doi.org/10.14324/111.444/ucloe.000009</a>.
</div>
<div id="ref-Sottek2005Models" class="csl-entry">
Sottek, Roland, and Klaus Genuit. 2005. <span>“Models of Signal Processing in Human Hearing.”</span> <em><span>AEU</span> - International Journal of Electronics and Communications</em> 59 (3): 157–65. <a href="https://doi.org/10.1016/j.aeue.2005.03.016">https://doi.org/10.1016/j.aeue.2005.03.016</a>.
</div>
<div id="ref-Tarlao2020Investigating" class="csl-entry">
Tarlao, Cynthia, Jochen Steffens, and Catherine Guastavino. 2020. <span>“Investigating Contextual Influences on Urban Soundscape Evaluations with Structural Equation Modeling.”</span> <em>Building and Environment</em> 188 (November). <a href="https://doi.org/10.1016/j.buildenv.2020.107490">https://doi.org/10.1016/j.buildenv.2020.107490</a>.
</div>
<div id="ref-Torresin2020Indoor" class="csl-entry">
Torresin, Simone, Rossano Albatici, Francesco Aletta, Francesco Babich, Tin Oberman, Stefano Siboni, and Jian Kang. 2020. <span>“<span class="nocase">Indoor soundscape assessment: A principal components model of acoustic perception in residential buildings</span>.”</span> <em>Building and Environment</em> 182 (September): 107152. <a href="https://doi.org/10.1016/j.buildenv.2020.107152">https://doi.org/10.1016/j.buildenv.2020.107152</a>.
</div>
<div id="ref-Truax1999Handbook" class="csl-entry">
Truax, Barry. 1999. <em>Handbook for <span>A</span>coustic <span>E</span>cology</em>. Cambridge, MA: Cambridge Street Publishing.
</div>
<div id="ref-VidaManzano2021sound" class="csl-entry">
Vida Manzano, Jerónimo, José Antonio Almagro Pastor, Rafael Garcı́a Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. 2021. <span>“The "Sound of Silence" in <span>G</span>ranada During the <span>COVID-19</span> Lockdown.”</span> <em>Noise Mapping</em> 8 (1): 16–31. <a href="https://doi.org/10.1515/noise-2021-0002">https://doi.org/10.1515/noise-2021-0002</a>.
</div>
<div id="ref-Waskom2021seaborn" class="csl-entry">
Waskom, Michael L. 2021. <span>“Seaborn: Statistical Data Visualization.”</span> <em>Journal of Open Source Software</em> 6 (60): 3021. <a href="https://doi.org/10.21105/joss.03021">https://doi.org/10.21105/joss.03021</a>.
</div>
<div id="ref-Woods2017Headphone" class="csl-entry">
Woods, Kevin J. P., Max H. Siegel, James Traer, and Josh H. McDermott. 2017. <span>“Headphone Screening to Facilitate Web-Based Auditory Experiments.”</span> <em>Attention, Perception, <span>&amp;</span> Psychophysics</em> 79 (7): 2064–72. <a href="https://doi.org/10.3758/s13414-017-1361-2">https://doi.org/10.3758/s13414-017-1361-2</a>.
</div>
<div id="ref-WMA2013World" class="csl-entry">
World Medical Association. 2013. <span>“World <span>M</span>edical <span>A</span>ssociation <span>D</span>eclaration of <span>H</span>elsinki: <span>E</span>thical Principles for Medical Research Involvinghuman Subjects.”</span> <em><span>JAMA</span></em> 310 (20): 2191. <a href="https://doi.org/10.1001/jama.2013.281053">https://doi.org/10.1001/jama.2013.281053</a>.
</div>
<div id="ref-Yang2005Acoustic" class="csl-entry">
Yang, W., and J. Kang. 2005. <span>“Acoustic Comfort Evaluation in Urban Open Public Spaces.”</span> <em>Applied Acoustics</em> 66 (2): 211–29. <a href="https://doi.org/10.1016/j.apacoust.2004.07.011">https://doi.org/10.1016/j.apacoust.2004.07.011</a>.
</div>
<div id="ref-Zwicker2007Psychoacoustics" class="csl-entry">
Zwicker, Eberhard, and Hugo Fastl. 2007. <em><span class="nocase">Psychoacoustics: facts and models</span></em>. Third ed. Berlin ; New York: Springer. <a href="https://doi.org/10.1007/978-3-540-68888-4">https://doi.org/10.1007/978-3-540-68888-4</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See <a href="https://zenodo.org/record/5654747" class="uri">https://zenodo.org/record/5654747</a> for “The International Soundscape Database (V0.2.1)” (Last viewed 11/9/21)↩︎</p></li>
<li id="fn2"><p>See supplementary material at <a href="https://www.scitation.org/doi/suppl/10.1121/10.0008928" class="uri">https://www.scitation.org/doi/suppl/10.1121/10.0008928</a> for site descriptions per ISO/TS (2018) featuring the address, overall psychoacoustic characteristics of the location, typical use of each location, and pictures taken during the survey sessions.↩︎</p></li>
<li id="fn3"><p>See <a href="https://zenodo.org/record/5654747" class="uri">https://zenodo.org/record/5654747</a> for “The International Soundscape Database (V0.2.1)” (Last viewed 11/9/21)↩︎</p></li>
<li id="fn4"><p>See supplementary material at <a href="https://www.scitation.org/doi/suppl/10.1121/10.0008928" class="uri">https://www.scitation.org/doi/suppl/10.1121/10.0008928</a> for site descriptions per ISO/TS (2018) featuring the address, overall psychoacoustic characteristics of the location, typical use of each location, and pictures taken during the survey sessions.↩︎</p></li>
<li id="fn5"><p>See <a href="https://zenodo.org/record/5654747" class="uri">https://zenodo.org/record/5654747</a> for “The International Soundscape Database (V0.2.1)” (Last viewed 11/9/21)↩︎</p></li>
<li id="fn6"><p>See (&lt;www.gorilla.sc&gt;) (Last viewed 11/29/21)↩︎</p></li>
<li id="fn7"><p>See <a href="https://cordis.europa.eu/project/rcn/211802/factsheet/en" class="uri">https://cordis.europa.eu/project/rcn/211802/factsheet/en</a> (Last viewed 12/7/21)↩︎</p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{mitchell2021,
  author = {Mitchell, Andrew and Oberman, Tin and Aletta, Francesco and
    Kachlicka, Magdalena and Lionello, Matteo and Erfanian, Mercede and
    Kang, Jian},
  title = {Investigating Urban Soundscapes of the {COVID-19} Lockdown:
    {A} Predictive Soundscape Modeling Approach},
  journal = {J. Acoust. Soc. Am.},
  volume = {150},
  number = {6},
  pages = {4474-\/-4488},
  date = {2021-12-28},
  url = {https://pubs.aip.org/asa/jasa/article/150/6/4474/995506/Investigating-urban-soundscapes-of-the-COVID-19},
  doi = {10.1121/10.0009794},
  langid = {en},
  abstract = {The unprecedented lockdowns due to COVID-19 in spring 2020
    triggered changes in human activities in public spaces. A predictive
    modeling approach was developed to characterize the changes in the
    perception of the sound environment when people could not be
    surveyed. Building on a database of soundscape questionnaires
    (\$N=1,136\$) and binaural recordings (\$N=687\$) collected in 13
    locations across London and Venice during 2019, new recordings
    (\$N=571\$) were made in the same locations during the 2020
    lockdowns. Using these 30-second-long recordings, linear multi-level
    models were developed to predict soundscape pleasantness
    (\$R\^{}2=0.85\$) and eventfulness (\$R\^{}2=0.715\$) during the
    lockdown and compare changes for each location. Performance was
    above average for comparable models. An online listening study also
    investigated the change in sound sources within the spaces. Results
    indicate: 1) human sounds were less dominant and natural sounds more
    dominant across all locations; 2) contextual information is
    important for predicting pleasantness but not for eventfulness; 3)
    perception shifted towards less eventful soundscapes and to more
    pleasant soundscapes for previously traffic-dominated locations, but
    not for human- and natural-dominated locations. This study
    demonstrates the usefulness of predictive modeling and the
    importance of considering contextual information when discussing the
    impact of sound level reductions on the soundscape.}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-mitchell2021" class="csl-entry quarto-appendix-citeas">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Magdalena Kachlicka,
Matteo Lionello, Mercede Erfanian, and Jian Kang. 2021.
<span>“Investigating Urban Soundscapes of the COVID-19 Lockdown: A
Predictive Soundscape Modeling Approach .”</span> <em>J. Acoust. Soc.
Am.</em> 150 (December): 4474--4488. <a href="https://doi.org/10.1121/10.0009794">https://doi.org/10.1121/10.0009794</a>.
</div></div></section></div> ]]></description>
  <category>journal-articles</category>
  <guid>https://drandrewmitchell.com/research/papers/2021-12-28_JASA-Lockdown/JASA-Lockdown.html</guid>
  <pubDate>Tue, 28 Dec 2021 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Exploring defining single value indices - SPI</title>
  <dc:creator>Andrew Mitchell</dc:creator>
  <link>https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code.html</link>
  <description><![CDATA[ 





<p>This notebook contains several explorations and developments leading to the SPI framework.</p>
<section id="setup" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Setup</h1>
<section id="import-libraries" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="import-libraries"><span class="header-section-number">1.1</span> Import Libraries</h2>
<div id="cell-3" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:36:07.299759Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:36:05.487098Z&quot;}" data-execution_count="38">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> soundscapy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sspy</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scripts <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> msn_utils</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> scripts.rpyskewnorm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> snpy</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scripts.MultiSkewNorm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MultiSkewNorm</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb1-12"></span>
<span id="cb1-13">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span>)</span></code></pre></div>
</div>
</section>
<section id="load-data" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="load-data"><span class="header-section-number">1.2</span> Load Data</h2>
<p>In addition to loading the latest version of the ISD, we also exclude a few samples that were identified as survey outliers. Most notably, this includes the samples at RegentsParkFields which were impacted by helicopter flyovers.</p>
<div id="cell-5" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:36:21.651402Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:36:07.300648Z&quot;}" data-execution_count="39">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load latest ISD dataset</span></span>
<span id="cb2-2"></span>
<span id="cb2-3">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.isd.load()</span>
<span id="cb2-4">data, excl_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.isd.validate(data)</span>
<span id="cb2-5">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Language != 'cmn'"</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Exclude RegentsParkJapan outliers</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># excl_id = list(data.query("LocationID == 'RegentsParkJapan'").query("ISOEventful &gt; 0.72 | ISOEventful &lt; -0.5").index)</span></span>
<span id="cb2-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Excluded RegentsParkFields outliers</span></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># excl_id = excl_id + list(data.query("LocationID == 'RegentsParkFields' and ISOPleasant &lt; 0").index) # Helicopters</span></span>
<span id="cb2-11">excl_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">652</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">706</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">548</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">550</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">551</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">553</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">569</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">580</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">609</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">618</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">623</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">636</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">643</span>]</span>
<span id="cb2-12">data.drop(excl_id, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-13">data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">LocationID</th>
<th data-quarto-table-cell-role="th">SessionID</th>
<th data-quarto-table-cell-role="th">GroupID</th>
<th data-quarto-table-cell-role="th">RecordID</th>
<th data-quarto-table-cell-role="th">start_time</th>
<th data-quarto-table-cell-role="th">end_time</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">Language</th>
<th data-quarto-table-cell-role="th">Survey_Version</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">RA_cp90_Max</th>
<th data-quarto-table-cell-role="th">RA_cp95_Max</th>
<th data-quarto-table-cell-role="th">THD_THD_Max</th>
<th data-quarto-table-cell-role="th">THD_Min_Max</th>
<th data-quarto-table-cell-role="th">THD_Max_Max</th>
<th data-quarto-table-cell-role="th">THD_L5_Max</th>
<th data-quarto-table-cell-role="th">THD_L10_Max</th>
<th data-quarto-table-cell-role="th">THD_L50_Max</th>
<th data-quarto-table-cell-role="th">THD_L90_Max</th>
<th data-quarto-table-cell-role="th">THD_L95_Max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>CarloV</td>
<td>CarloV2</td>
<td>2CV12</td>
<td>1434</td>
<td>2019-05-16 18:46:00</td>
<td>2019-05-16 18:56:00</td>
<td>37.17685</td>
<td>-3.590392</td>
<td>eng</td>
<td>engISO2018</td>
<td>...</td>
<td>8.15</td>
<td>6.72</td>
<td>-0.09</td>
<td>-11.76</td>
<td>54.18</td>
<td>34.82</td>
<td>26.53</td>
<td>5.57</td>
<td>-9.00</td>
<td>-10.29</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>CarloV</td>
<td>CarloV2</td>
<td>2CV12</td>
<td>1435</td>
<td>2019-05-16 18:46:00</td>
<td>2019-05-16 18:56:00</td>
<td>37.17685</td>
<td>-3.590392</td>
<td>eng</td>
<td>engISO2018</td>
<td>...</td>
<td>8.15</td>
<td>6.72</td>
<td>-0.09</td>
<td>-11.76</td>
<td>54.18</td>
<td>34.82</td>
<td>26.53</td>
<td>5.57</td>
<td>-9.00</td>
<td>-10.29</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>CarloV</td>
<td>CarloV2</td>
<td>2CV13</td>
<td>1430</td>
<td>2019-05-16 19:02:00</td>
<td>2019-05-16 19:12:00</td>
<td>37.17685</td>
<td>-3.590392</td>
<td>eng</td>
<td>engISO2018</td>
<td>...</td>
<td>5.00</td>
<td>3.91</td>
<td>-2.10</td>
<td>-19.32</td>
<td>72.52</td>
<td>32.33</td>
<td>24.52</td>
<td>0.25</td>
<td>-16.30</td>
<td>-17.33</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>CarloV</td>
<td>CarloV2</td>
<td>2CV13</td>
<td>1431</td>
<td>2019-05-16 19:02:00</td>
<td>2019-05-16 19:12:00</td>
<td>37.17685</td>
<td>-3.590392</td>
<td>eng</td>
<td>engISO2018</td>
<td>...</td>
<td>5.00</td>
<td>3.91</td>
<td>-2.10</td>
<td>-19.32</td>
<td>72.52</td>
<td>32.33</td>
<td>24.52</td>
<td>0.25</td>
<td>-16.30</td>
<td>-17.33</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>CarloV</td>
<td>CarloV2</td>
<td>2CV13</td>
<td>1432</td>
<td>2019-05-16 19:02:00</td>
<td>2019-05-16 19:12:00</td>
<td>37.17685</td>
<td>-3.590392</td>
<td>eng</td>
<td>engISO2018</td>
<td>...</td>
<td>5.00</td>
<td>3.91</td>
<td>-2.10</td>
<td>-19.32</td>
<td>72.52</td>
<td>32.33</td>
<td>24.52</td>
<td>0.25</td>
<td>-16.30</td>
<td>-17.33</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1693</td>
<td>Noorderplantsoen</td>
<td>Noorderplantsoen1</td>
<td>NP161</td>
<td>61</td>
<td>2020-03-11 12:42:00</td>
<td>2020-03-11 12:55:00</td>
<td>NaN</td>
<td>NaN</td>
<td>nld</td>
<td>nldSSIDv1</td>
<td>...</td>
<td>2.54</td>
<td>2.00</td>
<td>-3.17</td>
<td>-11.97</td>
<td>59.64</td>
<td>37.87</td>
<td>26.54</td>
<td>6.33</td>
<td>-9.79</td>
<td>-10.34</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1694</td>
<td>Noorderplantsoen</td>
<td>Noorderplantsoen1</td>
<td>NP162</td>
<td>63</td>
<td>2020-03-11 12:39:00</td>
<td>2020-03-11 13:00:00</td>
<td>NaN</td>
<td>NaN</td>
<td>nld</td>
<td>nldSSIDv1</td>
<td>...</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1695</td>
<td>Noorderplantsoen</td>
<td>Noorderplantsoen1</td>
<td>NP162</td>
<td>62</td>
<td>2020-03-11 12:54:00</td>
<td>2020-03-11 12:58:00</td>
<td>NaN</td>
<td>NaN</td>
<td>nld</td>
<td>nldSSIDv1</td>
<td>...</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1696</td>
<td>Noorderplantsoen</td>
<td>Noorderplantsoen1</td>
<td>NP162</td>
<td>64</td>
<td>2020-03-11 12:56:00</td>
<td>2020-03-11 12:59:00</td>
<td>NaN</td>
<td>NaN</td>
<td>nld</td>
<td>nldSSIDv1</td>
<td>...</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1697</td>
<td>Noorderplantsoen</td>
<td>Noorderplantsoen1</td>
<td>NP163</td>
<td>70</td>
<td>2020-03-11 23:08:00</td>
<td>2020-03-11 23:18:00</td>
<td>NaN</td>
<td>NaN</td>
<td>nld</td>
<td>nldSSIDv1</td>
<td>...</td>
<td>2.58</td>
<td>1.99</td>
<td>-3.20</td>
<td>-9.67</td>
<td>57.99</td>
<td>35.54</td>
<td>29.32</td>
<td>8.86</td>
<td>-5.61</td>
<td>-6.71</td>
</tr>
</tbody>
</table>

<p>1648 rows × 142 columns</p>
</div>
</div>
</div>
<section id="isocoordinate-calculation-according-to-aletta-et.-al.-2024" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="isocoordinate-calculation-according-to-aletta-et.-al.-2024"><span class="header-section-number">1.2.1</span> ISOCoordinate calculation according to Aletta et. al.&nbsp;(2024)</h3>
<p>To move the 8-item PAQ responses into the 2-dimensional circumplex space, we use the projection method first presented in ISO 12913-3:2018. This projection method and its associated formulae were recently updated further in <span class="citation" data-cites="Aletta2024">(<strong>Aletta2024?</strong>)</span> to include a correction for the language in which the survey was conducted. The formulae are as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%25%20%5Cbegin%7Balign*%7D%0AP_%7BISO%7D%20=%20%5Cfrac%7B1%7D%7B%5Clambda_%7Bpl%7D%7D%20%5Csum_%7Bi=1%7D%5E%7B8%7D%20%5Ccos%20%5Ctheta_i%20%5Ccdot%20%5Csigma_i%20%5C%5C%0AE_%7BISO%7D%20=%20%5Cfrac%7B1%7D%7B%5Clambda_%7Bpl%7D%7D%20%5Csum_%7Bi=1%7D%5E%7B8%7D%20%5Csin%20%5Ctheta_i%20%5Ccdot%20%5Csigma_i%0A%25%20%5Cend%7Balign*%7D%0A"></p>
<p>where $_i$ is the response to the (i)th item of the PAQ. The resulting (x) and (y) values are then used to calculate the polar angle () and the radial distance (r) as follows:</p>
<div id="cell-8" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:36:21.661999Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:36:21.653412Z&quot;}" data-execution_count="40">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> soundscapy.surveys.survey_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LANGUAGE_ANGLES, PAQ_IDS</span>
<span id="cb3-2"></span>
<span id="cb3-3">LANGUAGE_ANGLES</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>{'eng': (0, 46, 94, 138, 177, 241, 275, 340),
 'arb': (0, 36, 45, 135, 167, 201, 242, 308),
 'cmn': (0, 18, 38, 154, 171, 196, 217, 318),
 'hrv': (0, 84, 93, 160, 173, 243, 273, 354),
 'nld': (0, 43, 111, 125, 174, 257, 307, 341),
 'deu': (0, 64, 97, 132, 182, 254, 282, 336),
 'ell': (0, 72, 86, 133, 161, 233, 267, 328),
 'ind': (0, 53, 104, 123, 139, 202, 284, 308),
 'ita': (0, 57, 104, 143, 170, 274, 285, 336),
 'spa': (0, 41, 103, 147, 174, 238, 279, 332),
 'swe': (0, 66, 87, 146, 175, 249, 275, 335),
 'tur': (0, 55, 97, 106, 157, 254, 289, 313)}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">tab <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame.from_dict(LANGUAGE_ANGLES, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>PAQ_IDS)</span>
<span id="cb5-2">tab</span></code></pre></div>
<div id="tbl-lang-angles" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="41">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-lang-angles-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Language-specific angles for projection into the ISO 12913-3:2018 circumplex space.
</figcaption>
<div aria-describedby="tbl-lang-angles-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="41">
<div>


<table class="dataframe do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">PAQ1</th>
<th data-quarto-table-cell-role="th">PAQ2</th>
<th data-quarto-table-cell-role="th">PAQ3</th>
<th data-quarto-table-cell-role="th">PAQ4</th>
<th data-quarto-table-cell-role="th">PAQ5</th>
<th data-quarto-table-cell-role="th">PAQ6</th>
<th data-quarto-table-cell-role="th">PAQ7</th>
<th data-quarto-table-cell-role="th">PAQ8</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">eng</td>
<td>0</td>
<td>46</td>
<td>94</td>
<td>138</td>
<td>177</td>
<td>241</td>
<td>275</td>
<td>340</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">arb</td>
<td>0</td>
<td>36</td>
<td>45</td>
<td>135</td>
<td>167</td>
<td>201</td>
<td>242</td>
<td>308</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">cmn</td>
<td>0</td>
<td>18</td>
<td>38</td>
<td>154</td>
<td>171</td>
<td>196</td>
<td>217</td>
<td>318</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">hrv</td>
<td>0</td>
<td>84</td>
<td>93</td>
<td>160</td>
<td>173</td>
<td>243</td>
<td>273</td>
<td>354</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">nld</td>
<td>0</td>
<td>43</td>
<td>111</td>
<td>125</td>
<td>174</td>
<td>257</td>
<td>307</td>
<td>341</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">deu</td>
<td>0</td>
<td>64</td>
<td>97</td>
<td>132</td>
<td>182</td>
<td>254</td>
<td>282</td>
<td>336</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ell</td>
<td>0</td>
<td>72</td>
<td>86</td>
<td>133</td>
<td>161</td>
<td>233</td>
<td>267</td>
<td>328</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ind</td>
<td>0</td>
<td>53</td>
<td>104</td>
<td>123</td>
<td>139</td>
<td>202</td>
<td>284</td>
<td>308</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ita</td>
<td>0</td>
<td>57</td>
<td>104</td>
<td>143</td>
<td>170</td>
<td>274</td>
<td>285</td>
<td>336</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">spa</td>
<td>0</td>
<td>41</td>
<td>103</td>
<td>147</td>
<td>174</td>
<td>238</td>
<td>279</td>
<td>332</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">swe</td>
<td>0</td>
<td>66</td>
<td>87</td>
<td>146</td>
<td>175</td>
<td>249</td>
<td>275</td>
<td>335</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">tur</td>
<td>0</td>
<td>55</td>
<td>97</td>
<td>106</td>
<td>157</td>
<td>254</td>
<td>289</td>
<td>313</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<div id="cell-10" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:36:22.886321Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:36:21.659548Z&quot;}" data-execution_count="42">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> soundscapy.surveys.survey_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PAQ_IDS</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data.iterrows():</span>
<span id="cb6-4">    lang <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Language"</span>]</span>
<span id="cb6-5">    angles <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LANGUAGE_ANGLES[lang]</span>
<span id="cb6-6">    iso_pl, iso_ev <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb6-7">        sspy.surveys.processing._adj_iso_pl(row[PAQ_IDS], angles, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>),</span>
<span id="cb6-8">        sspy.surveys.processing._adj_iso_ev(row[PAQ_IDS], angles, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>),</span>
<span id="cb6-9">    )</span>
<span id="cb6-10">    data.loc[i, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iso_pl</span>
<span id="cb6-11">    data.loc[i, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iso_ev</span>
<span id="cb6-12"></span>
<span id="cb6-13">data_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [sspy.isd.select_location_ids(data, loc) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> loc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>].unique()]</span>
<span id="cb6-14">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.plotting.create_circumplex_subplots(</span>
<span id="cb6-15">    data_list,</span>
<span id="cb6-16">    plot_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"density"</span>,</span>
<span id="cb6-17">    nrows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>,</span>
<span id="cb6-18">    ncols<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="cb6-19">    figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>),</span>
<span id="cb6-20">    legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-21">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-22">    subtitles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[loc <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> loc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>].unique()],</span>
<span id="cb6-23">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>,</span>
<span id="cb6-24">)</span>
<span id="cb6-25"></span>
<span id="cb6-26">fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-11" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting distribution density with empirical scatter</span></span>
<span id="cb7-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> empirical_msn_scatter(data, loc):</span>
<span id="cb7-3">    loc_msn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb7-4">    loc_msn.fit(</span>
<span id="cb7-5">        data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data.query(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"LocationID == '</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>loc<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'"</span>)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]]</span>
<span id="cb7-6">    )</span>
<span id="cb7-7">    loc_msn.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb7-8">    loc_Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(loc_msn.sample_data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span>
<span id="cb7-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> loc_Y</span>
<span id="cb7-10"></span>
<span id="cb7-11">data_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [empirical_msn_scatter(data, loc) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> loc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>].unique()]</span>
<span id="cb7-12"></span>
<span id="cb7-13">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.plotting.create_circumplex_subplots(</span>
<span id="cb7-14">    data_list,</span>
<span id="cb7-15">    plot_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"density"</span>,</span>
<span id="cb7-16">    nrows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>,</span>
<span id="cb7-17">    ncols<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="cb7-18">    figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>),</span>
<span id="cb7-19">    legend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb7-20">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb7-21">    subtitles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[loc <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> loc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID"</span>].unique()],</span>
<span id="cb7-22">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>,</span>
<span id="cb7-23">)</span>
<span id="cb7-24"></span>
<span id="cb7-25">fig.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="the-soundscape-perception-index-spi" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="the-soundscape-perception-index-spi"><span class="header-section-number">1.3</span> The Soundscape Perception Index (SPI)</h2>
<p>The SPI works by assessing the assessed (or calculated) distribution of soundscape responses against a target distribution. This target distribution represents the goal for the soundscape design. Since we consider a location’s soundscape perception to be the collective perception of its users, it is crucial that the target includes both the central tendency and the distribution.</p>
<section id="note-distributions-in-the-circumplex" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="note-distributions-in-the-circumplex"><span class="header-section-number">1.3.1</span> Note: Distributions in the circumplex</h3>
<p>We should begin by discussing how soundscape circumplex distributions are defined. The circumplex is defined by two axes: <img src="https://latex.codecogs.com/png.latex?P_%7BISO%7D"> and <img src="https://latex.codecogs.com/png.latex?E_%7BISO%7D"> which are limited to the range <img src="https://latex.codecogs.com/png.latex?%5B-1,1%5D">. Typically the distribution of collective perception of a soundscape is also not symmetrical, therefore making it a skewed distribution. A soundscape distribution is thus a two-dimensional truncated skew-normal distribution.</p>
<p>The skew-normal distribution is defined by three parameters: location, scale and shape. The location parameter defines the centre of the distribution, the scale parameter defines the spread of the distribution, and the shape parameter defines the skew of the distribution. The skew-normal distribution is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x;%20a,%20%5Comega,%20%5Calpha)%20=%20%5Cfrac%7B2%7D%7B%5Comega%7D%20%5Cphi%20%5Cleft(%20%5Cfrac%7Bx-a%7D%7B%5Comega%7D%20%5Cright)%20%5CPhi%20%5Cleft(%20%5Calpha%20%5Cfrac%7Bx-a%7D%7B%5Comega%7D%20%5Cright)%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cphi"> and <img src="https://latex.codecogs.com/png.latex?%5CPhi"> are the standard normal probability density function and cumulative distribution function respectively. The skew-normal distribution is thus a generalisation of the normal distribution, with the shape parameter <img src="https://latex.codecogs.com/png.latex?%5Calpha"> defining the skew. A positive shape parameter results in a right-skewed distribution, and a negative shape parameter results in a left-skewed distribution.</p>
<p>Truncated skew-normal distribution: https://www-tandfonline-com.libproxy.ucl.ac.uk/doi/epdf/10.1080/03610910902936109?needAccess=true</p>
<p>To generate the truncated skew-normal distribution, we use rejection sampling. This is a method of generating a distribution by sampling from a simpler distribution and rejecting samples that do not fit the target distribution. In this case, we sample from a skew-normal distribution (<code>scipy.stats.skewnorm</code>) and reject samples that are outside of the range <img src="https://latex.codecogs.com/png.latex?%5B-1,1%5D">.</p>
<section id="example---calculating-the-moments-of-locations-distribution-and-generating-the-equivalent-distribution-using-rejection-sampling" class="level4" data-number="1.3.1.1">
<h4 data-number="1.3.1.1" class="anchored" data-anchor-id="example---calculating-the-moments-of-locations-distribution-and-generating-the-equivalent-distribution-using-rejection-sampling"><span class="header-section-number">1.3.1.1</span> Example - Calculating the moments of location’s distribution and generating the equivalent distribution using rejection sampling</h4>
<div id="cell-13" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:36:23.057441Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:36:22.892591Z&quot;}" data-execution_count="44">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">test_loc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SanMarco"</span></span>
<span id="cb8-2">test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.isd.select_location_ids(data, test_loc)</span>
<span id="cb8-3"></span>
<span id="cb8-4">msn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb8-5">msn.fit(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test_data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]])</span>
<span id="cb8-6"></span>
<span id="cb8-7">msn.summary()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitted from data. n = 96
Direct Parameters:
xi:    [[0.06  0.597]]
omega: [[ 0.15  -0.058]
 [-0.058  0.093]]
alpha: [ 0.868 -0.561]


Centred Parameters:
mean:  [[0.281 0.447]]
sigma: [[ 0.101 -0.025]
 [-0.025  0.07 ]]
skew:  [ 0.145 -0.078]</code></pre>
</div>
</div>
<div id="cell-fig-dist-example" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:36:24.997380Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:36:22.947404Z&quot;}" data-execution_count="45">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> msn.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, return_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-2">Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(Y, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span>
<span id="cb10-3">D, p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> msn.ks2ds(test_data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]])</span>
<span id="cb10-4"></span>
<span id="cb10-5">color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sns.color_palette(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"colorblind"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb10-6"></span>
<span id="cb10-7">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb10-8">sspy.density_plot(</span>
<span id="cb10-9">    test_data,</span>
<span id="cb10-10">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb10-11">    density_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"full"</span>,</span>
<span id="cb10-12">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"a) Empirical data"</span>,</span>
<span id="cb10-13">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>color,</span>
<span id="cb10-14">)</span>
<span id="cb10-15">sspy.density_plot(</span>
<span id="cb10-16">    Y, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], density_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"full"</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"b) MSN sampled distribution</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> n sample = 1000"</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>color</span>
<span id="cb10-17">)</span>
<span id="cb10-18">plt.tight_layout()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-dist-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dist-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/fig-dist-example-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dist-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Example of fitting and sampling from a multivariate skew-normal distribution for data from the Piazza San Marco location.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-15" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hack using alpha dev version of soundscapy</span></span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> soundscapy.plotting.circumplex_plot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CircumplexPlot, Backend, CircumplexPlotParams</span>
<span id="cb11-3"></span>
<span id="cb11-4">Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> msn.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, return_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb11-5">Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(Y, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span>
<span id="cb11-6">D, p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> msn.ks2ds(test_data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]])</span>
<span id="cb11-7"></span>
<span id="cb11-8">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CircumplexPlotParams(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a) Sample data for Piazza San Marco"</span>)</span>
<span id="cb11-9">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CircumplexPlot(</span>
<span id="cb11-10">    test_data, params, backend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Backend.SEABORN</span>
<span id="cb11-11">)</span>
<span id="cb11-12">g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plot.jointplot()</span>
<span id="cb11-13">g.get_figure()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a) Sample data for Piazza San Marco"</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.02</span>)</span>
<span id="cb11-14">g.show()</span>
<span id="cb11-15"></span>
<span id="cb11-16">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CircumplexPlotParams(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"b) MSN sampled distribution</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> n sample = 1000"</span>)</span>
<span id="cb11-17">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CircumplexPlot(</span>
<span id="cb11-18">    Y, params, backend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Backend.SEABORN</span>
<span id="cb11-19">)</span>
<span id="cb11-20">g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plot.jointplot()</span>
<span id="cb11-21">g.get_figure()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"b) MSN sampled distribution</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> n sample = 1000"</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.05</span>)</span>
<span id="cb11-22">g.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-16" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Universal pleasant target</span></span>
<span id="cb12-2">target_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb12-3">target_1.define_dp(</span>
<span id="cb12-4">    xi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>]),</span>
<span id="cb12-5">    omega <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array(</span>
<span id="cb12-6">        [[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb12-7">         [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>]]),</span>
<span id="cb12-8">    alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb12-9">)</span>
<span id="cb12-10">target_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb12-11">target_2.define_dp(</span>
<span id="cb12-12">    xi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>]]),</span>
<span id="cb12-13">    omega <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.17</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.04</span>],</span>
<span id="cb12-14">              [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.04</span>,  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.09</span>]]),</span>
<span id="cb12-15">    alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb12-16">    )</span>
<span id="cb12-17"></span>
<span id="cb12-18">target_3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb12-19">target_3.define_dp(</span>
<span id="cb12-20">    xi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>]),</span>
<span id="cb12-21">    omega<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]),</span>
<span id="cb12-22">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]),</span>
<span id="cb12-23">)</span>
<span id="cb12-24"></span>
<span id="cb12-25">Y_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target_1.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, return_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb12-26">Y_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(Y_1, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span>
<span id="cb12-27">Y_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target_2.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, return_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb12-28">Y_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(Y_2, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span>
<span id="cb12-29">Y_3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target_3.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, return_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb12-30">Y_3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(Y_3, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span></code></pre></div>
</div>
<div id="cell-fig-targets" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb13-2">sspy.density_plot(</span>
<span id="cb13-3">    Y_1,</span>
<span id="cb13-4">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb13-5">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a) Target 1"</span>,</span>
<span id="cb13-6">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>,</span>
<span id="cb13-7">)</span>
<span id="cb13-8">sspy.density_plot(</span>
<span id="cb13-9">    Y_2, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"b) Target 2"</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span></span>
<span id="cb13-10">)</span>
<span id="cb13-11">sspy.density_plot(</span>
<span id="cb13-12">    Y_3, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c) Target 3"</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span></span>
<span id="cb13-13">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-targets" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/fig-targets-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Example of defining and sampling from three arbitrary bespoke targets.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-18" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">D_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> msn_utils.ks2d2s(</span>
<span id="cb14-2">    test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOPleasant'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOEventful'</span>]],</span>
<span id="cb14-3">    target_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_1,</span>
<span id="cb14-4">    extra<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb14-5">)</span>
<span id="cb14-6">D_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> msn_utils.ks2d2s(</span>
<span id="cb14-7">    test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOPleasant'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOEventful'</span>]],</span>
<span id="cb14-8">    target_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_2,</span>
<span id="cb14-9">    extra<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb14-10">)</span>
<span id="cb14-11">D_3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> msn_utils.ks2d2s(</span>
<span id="cb14-12">    test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOPleasant'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOEventful'</span>]],</span>
<span id="cb14-13">    target_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y_3,</span>
<span id="cb14-14">    extra<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb14-15">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Markdown</span>
<span id="cb15-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tabulate <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tabulate</span>
<span id="cb15-3"></span>
<span id="cb15-4">D_tbl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_1'</span>, D_1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), D_1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]],</span>
<span id="cb15-5">         [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_2'</span>, D_2[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), D_2[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]],</span>
<span id="cb15-6">         [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_3'</span>, D_3[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), D_2[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]]]</span>
<span id="cb15-7">Markdown(tabulate(</span>
<span id="cb15-8">    D_tbl,</span>
<span id="cb15-9">    headers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Target"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"D"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"p"</span>],</span>
<span id="cb15-10">    tablefmt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'grid'</span></span>
<span id="cb15-11">))</span></code></pre></div>
<div id="tbl-ks-test" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="50">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ks-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Kolmogorov-Smirnov test comparing the empirical test distribution (Piazza San Marco) against three soundscape target distributions.
</figcaption>
<div aria-describedby="tbl-ks-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="50">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 15%">
<col style="width: 9%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Target</th>
<th>D</th>
<th><pre><code>      p</code></pre></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>tgt_1</td>
<td>0.66</td>
<td>6.94745e-25</td>
</tr>
<tr class="even">
<td>tgt_2</td>
<td>0.83</td>
<td>8.96388e-39</td>
</tr>
<tr class="odd">
<td>tgt_3</td>
<td>0.28</td>
<td>8.96388e-39</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div id="cell-20" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb17-2"></span>
<span id="cb17-3">sspy.density_plot(</span>
<span id="cb17-4">    sspy.isd.select_location_ids(data, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SanMarco"</span>),</span>
<span id="cb17-5">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb17-6">    simple_density<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb17-7">    label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'test'</span>,</span>
<span id="cb17-8">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb17-9">    incl_outline<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb17-10">    color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sns.palettes.color_palette(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"colorblind"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb17-11">)</span>
<span id="cb17-12"></span>
<span id="cb17-13">sspy.density_plot(</span>
<span id="cb17-14">    pd.DataFrame({</span>
<span id="cb17-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>: target_3.sample_data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb17-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>: target_3.sample_data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb17-17">    }),</span>
<span id="cb17-18">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb17-19">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb17-20">    incl_outline<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb17-21">    simple_density<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb17-22">    label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>,</span>
<span id="cb17-23">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"San Marco compared against target</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">D=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>D_3[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, p=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>D_3[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb17-24">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span></span>
<span id="cb17-25">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">spis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb18-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> location <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data.LocationID.unique():</span>
<span id="cb18-3">    loc_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sspy.isd.select_location_ids(data, location)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOPleasant'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ISOEventful'</span>]]</span>
<span id="cb18-4">    spi_res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [msn_utils.spi(loc_data, target_data) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> target_data <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [Y_1, Y_2, Y_3]]</span>
<span id="cb18-5">    spis[location] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> spi_res</span>
<span id="cb18-6">spis_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(spis).T</span>
<span id="cb18-7">spis_df.columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_2'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_3'</span>]</span>
<span id="cb18-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># spis_df</span></span></code></pre></div>
</div>
<div id="cell-22" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> table_fill(spis_df, idx):</span>
<span id="cb19-2">    tgt_1_order <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> spis_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_1'</span>].sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb19-3">    tgt_2_order <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> spis_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_2'</span>].sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb19-4">    tgt_3_order <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> spis_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_3'</span>].sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb19-5"></span>
<span id="cb19-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tgt_str(tgt_order, idx):</span>
<span id="cb19-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tgt_order<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>values[idx]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">   </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tgt_order<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>index[idx]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb19-8"></span>
<span id="cb19-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> [<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, tgt_str(tgt_1_order, idx), tgt_str(tgt_2_order, idx), tgt_str(tgt_3_order, idx)]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">spis_tbl <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [table_fill(spis_df, idx) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(spis_df))]</span>
<span id="cb20-2">tabulate.PRESERVE_WHITESPACE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb20-3">Markdown(tabulate(</span>
<span id="cb20-4">    spis_tbl,</span>
<span id="cb20-5">    headers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Ranking"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"$SPI_1$ (pleasant)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"$SPI_2$ (calm)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"$SPI_3$ (vibrant)"</span>],</span>
<span id="cb20-6">    tablefmt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pipe'</span>,</span>
<span id="cb20-7">))</span></code></pre></div>
<div id="tbl-ex-spis" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="54">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ex-spis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: SPI scores and rankings for the soundscapes of locations included in the International Soundscape Database (ISD).
</figcaption>
<div aria-describedby="tbl-ex-spis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="54">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">Ranking</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?SPI_1"> (pleasant)</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?SPI_2"> (calm)</th>
<th style="text-align: left;"><img src="https://latex.codecogs.com/png.latex?SPI_3"> (vibrant)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">70 RegentsParkFields</td>
<td style="text-align: left;">61 CampoPrincipe</td>
<td style="text-align: left;">71 SanMarco</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: left;">69 CarloV</td>
<td style="text-align: left;">52 CarloV</td>
<td style="text-align: left;">62 TateModern</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: left;">65 RegentsParkJapan</td>
<td style="text-align: left;">50 PlazaBibRambla</td>
<td style="text-align: left;">60 StPaulsCross</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: left;">62 CampoPrincipe</td>
<td style="text-align: left;">49 RegentsParkFields</td>
<td style="text-align: left;">58 Noorderplantsoen</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: left;">61 PlazaBibRambla</td>
<td style="text-align: left;">45 MarchmontGarden</td>
<td style="text-align: left;">55 PancrasLock</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: left;">61 RussellSq</td>
<td style="text-align: left;">44 MonumentoGaribaldi</td>
<td style="text-align: left;">54 TorringtonSq</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: left;">61 MarchmontGarden</td>
<td style="text-align: left;">40 RussellSq</td>
<td style="text-align: left;">48 StPaulsRow</td>
</tr>
<tr class="even">
<td style="text-align: right;">8</td>
<td style="text-align: left;">61 MonumentoGaribaldi</td>
<td style="text-align: left;">38 RegentsParkJapan</td>
<td style="text-align: left;">48 RussellSq</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9</td>
<td style="text-align: left;">59 PancrasLock</td>
<td style="text-align: left;">38 PancrasLock</td>
<td style="text-align: left;">47 MiradorSanNicolas</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: left;">53 StPaulsCross</td>
<td style="text-align: left;">32 MiradorSanNicolas</td>
<td style="text-align: left;">43 CamdenTown</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11</td>
<td style="text-align: left;">49 TateModern</td>
<td style="text-align: left;">30 TateModern</td>
<td style="text-align: left;">40 CarloV</td>
</tr>
<tr class="even">
<td style="text-align: right;">12</td>
<td style="text-align: left;">48 StPaulsRow</td>
<td style="text-align: left;">30 StPaulsCross</td>
<td style="text-align: left;">36 MonumentoGaribaldi</td>
</tr>
<tr class="odd">
<td style="text-align: right;">13</td>
<td style="text-align: left;">43 MiradorSanNicolas</td>
<td style="text-align: left;">28 TorringtonSq</td>
<td style="text-align: left;">34 MarchmontGarden</td>
</tr>
<tr class="even">
<td style="text-align: right;">14</td>
<td style="text-align: left;">38 Noorderplantsoen</td>
<td style="text-align: left;">28 StPaulsRow</td>
<td style="text-align: left;">33 PlazaBibRambla</td>
</tr>
<tr class="odd">
<td style="text-align: right;">15</td>
<td style="text-align: left;">35 TorringtonSq</td>
<td style="text-align: left;">17 SanMarco</td>
<td style="text-align: left;">33 CampoPrincipe</td>
</tr>
<tr class="even">
<td style="text-align: right;">16</td>
<td style="text-align: left;">33 SanMarco</td>
<td style="text-align: left;">16 Noorderplantsoen</td>
<td style="text-align: left;">32 EustonTap</td>
</tr>
<tr class="odd">
<td style="text-align: right;">17</td>
<td style="text-align: left;">21 CamdenTown</td>
<td style="text-align: left;">15 CamdenTown</td>
<td style="text-align: left;">27 RegentsParkFields</td>
</tr>
<tr class="even">
<td style="text-align: right;">18</td>
<td style="text-align: left;">15 EustonTap</td>
<td style="text-align: left;">13 EustonTap</td>
<td style="text-align: left;">27 RegentsParkJapan</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div id="cell-24" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">spis_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tgt_1'</span>].sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>RegentsParkFields     70
CarloV                69
RegentsParkJapan      65
CampoPrincipe         62
PlazaBibRambla        61
RussellSq             61
MarchmontGarden       61
MonumentoGaribaldi    61
PancrasLock           59
StPaulsCross          53
TateModern            49
StPaulsRow            48
MiradorSanNicolas     43
Noorderplantsoen      38
TorringtonSq          35
SanMarco              33
CamdenTown            21
EustonTap             15
Name: tgt_1, dtype: int64</code></pre>
</div>
</div>
<div id="cell-25" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:54:15.403051Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:54:14.093650Z&quot;}" data-execution_count="56">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb23-2">target.define_dp(</span>
<span id="cb23-3">    xi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>]),</span>
<span id="cb23-4">    omega<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]),</span>
<span id="cb23-5">    alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]),</span>
<span id="cb23-6">)</span>
<span id="cb23-7">target.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb23-8">target.sspy_plot()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-26" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb24-2"></span>
<span id="cb24-3">sspy.density_plot(</span>
<span id="cb24-4">    test_data, incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"San Marco</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Empirical Density"</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span></span>
<span id="cb24-5">)</span>
<span id="cb24-6">sspy.density_plot(</span>
<span id="cb24-7">    pd.DataFrame(target.sample_data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]),</span>
<span id="cb24-8">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb24-9">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Target Density"</span>,</span>
<span id="cb24-10">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb24-11">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span></span>
<span id="cb24-12">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Once the target is defined, we will generate a set of points that represent the target distribution.</p>
<p>Now that our target has been defined, we can calculate the SPI for a given set of responses. We will use the responses from Piazza San Marco in Venice, Italy, as an example.</p>
<div id="cell-29" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:54:19.320850Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:54:19.295186Z&quot;}" data-execution_count="58">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">test_spi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.spi(data.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LocationID == 'SanMarco'"</span>)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]])</span>
<span id="cb25-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"San Marco SPI = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>test_spi<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>San Marco SPI = 71</code></pre>
</div>
</div>
<div id="cell-30" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:54:21.367966Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:54:20.381396Z&quot;}" data-execution_count="59">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb27-2"></span>
<span id="cb27-3">sspy.density_plot(</span>
<span id="cb27-4">    sspy.isd.select_location_ids(data, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SanMarco"</span>),</span>
<span id="cb27-5">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb27-6">    simple_density<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb27-7">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f""</span>,</span>
<span id="cb27-8">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"blue"</span></span>
<span id="cb27-9">)</span>
<span id="cb27-10">sspy.density_plot(</span>
<span id="cb27-11">    pd.DataFrame(target.sample_data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]),</span>
<span id="cb27-12">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb27-13">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb27-14">    simple_density<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb27-15">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Piazza San Marco</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">SPI = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>test_spi<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb27-16">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span></span>
<span id="cb27-17">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can compare this against another location, such as St Pancras Lock.</p>
<div id="cell-32" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:54:24.015026Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:54:22.957015Z&quot;}" data-execution_count="60">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">test_spi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.spi(</span>
<span id="cb28-2">    sspy.isd.select_location_ids(data, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PancrasLock"</span>)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]]</span>
<span id="cb28-3">)</span>
<span id="cb28-4">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb28-5"></span>
<span id="cb28-6">sspy.density_plot(</span>
<span id="cb28-7">    sspy.isd.select_location_ids(data, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RegentsParkFields"</span>),</span>
<span id="cb28-8">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb28-9">    simple_density<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb28-10">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f""</span>,</span>
<span id="cb28-11">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"blue"</span></span>
<span id="cb28-12">)</span>
<span id="cb28-13">sspy.density_plot(</span>
<span id="cb28-14">    pd.DataFrame(target.sample_data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]),</span>
<span id="cb28-15">    ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax,</span>
<span id="cb28-16">    incl_scatter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb28-17">    simple_density<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb28-18">    title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Pancras Lock</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">SPI = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>test_spi<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb28-19">    color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span></span>
<span id="cb28-20">)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>SPI scores assessed against a target should not inherently be considered a measure of the quality of the soundscape - instead it reflects the degree to which the soundscape matches the target. A high SPI score does not necessarily mean that the soundscape is of high quality, but rather that the soundscape is of high quality <em>according to the target</em>.</p>
<p>The <img src="https://latex.codecogs.com/png.latex?SPI_%7Bbespoke%7D"> thus provides a method for scoring and ranking the success of a soundscape design against the designer’s goals. Sticking with our defined target, we can assess all of the locations in the ISD and see which locations best match our target.</p>
<div id="cell-34" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:54:26.767584Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:54:26.096777Z&quot;}" data-execution_count="61">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">loc_bespoke <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb29-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> location <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data.LocationID.unique():</span>
<span id="cb29-3">    loc_bespoke[location] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.spi(</span>
<span id="cb29-4">        sspy.isd.select_location_ids(data, location)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]]</span>
<span id="cb29-5">    )</span>
<span id="cb29-6"></span>
<span id="cb29-7">loc_bespoke <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame.from_dict(loc_bespoke, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"index"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SPI"</span>])</span>
<span id="cb29-8">loc_bespoke.sort_values(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SPI"</span>, ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb29-9">loc_bespoke</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">SPI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">SanMarco</td>
<td>71</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TateModern</td>
<td>61</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Noorderplantsoen</td>
<td>61</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">StPaulsCross</td>
<td>59</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TorringtonSq</td>
<td>54</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">PancrasLock</td>
<td>53</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">StPaulsRow</td>
<td>47</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RussellSq</td>
<td>46</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MiradorSanNicolas</td>
<td>46</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CamdenTown</td>
<td>43</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CarloV</td>
<td>40</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MonumentoGaribaldi</td>
<td>36</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MarchmontGarden</td>
<td>35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">PlazaBibRambla</td>
<td>35</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CampoPrincipe</td>
<td>33</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">EustonTap</td>
<td>31</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">RegentsParkJapan</td>
<td>27</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RegentsParkFields</td>
<td>25</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Assessed against a different target would result in a different ranking:</p>
<div id="cell-36" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:37:50.073520Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:37:48.801134Z&quot;}" data-execution_count="62">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb30-2">target.define_dp(</span>
<span id="cb30-3">    np.array([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>]),</span>
<span id="cb30-4">    np.array([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>]]),</span>
<span id="cb30-5">    np.array([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>]),</span>
<span id="cb30-6">)</span>
<span id="cb30-7">target.summary()</span>
<span id="cb30-8"></span>
<span id="cb30-9">target.sample(n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb30-10">target.sspy_plot()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitted from direct parameters.
Direct Parameters:
xi:    [-0.5 -0.5]
omega: [[0.1 0. ]
 [0.  0.2]]
alpha: [-0.85  1.5 ]


None</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-26-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-37" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2024-02-02T22:37:53.923450Z&quot;,&quot;start_time&quot;:&quot;2024-02-02T22:37:53.178742Z&quot;}" data-execution_count="63">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">loc_bespoke_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb32-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> location <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> data.LocationID.unique():</span>
<span id="cb32-3">    loc_bespoke_2[location] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.spi(</span>
<span id="cb32-4">        sspy.isd.select_location_ids(data, location)[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>]]</span>
<span id="cb32-5">    )</span>
<span id="cb32-6"></span>
<span id="cb32-7">loc_bespoke_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame.from_dict(loc_bespoke_2, orient<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"index"</span>, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SPI"</span>])</span>
<span id="cb32-8">loc_bespoke_2.sort_values(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SPI"</span>, ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb32-9">loc_bespoke_2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">SPI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">EustonTap</td>
<td>30</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CamdenTown</td>
<td>22</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MarchmontGarden</td>
<td>19</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TorringtonSq</td>
<td>19</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">PancrasLock</td>
<td>17</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">PlazaBibRambla</td>
<td>15</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">StPaulsRow</td>
<td>15</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CampoPrincipe</td>
<td>11</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">StPaulsCross</td>
<td>11</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RegentsParkJapan</td>
<td>8</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">RussellSq</td>
<td>8</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CarloV</td>
<td>8</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">SanMarco</td>
<td>8</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">TateModern</td>
<td>8</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MiradorSanNicolas</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MonumentoGaribaldi</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Noorderplantsoen</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RegentsParkFields</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-38" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">target1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb33-2">target1.define_dp(</span>
<span id="cb33-3">    np.array([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>]), np.array([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]), np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb33-4">)</span>
<span id="cb33-5">target1.sample()</span>
<span id="cb33-6"></span>
<span id="cb33-7">target2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiSkewNorm()</span>
<span id="cb33-8">target2.define_dp(np.array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]), np.array([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>]]), np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]))</span>
<span id="cb33-9">target2.sample()</span>
<span id="cb33-10"></span>
<span id="cb33-11">target_mix_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target1.sample_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> target2.sample_data</span>
<span id="cb33-12"></span>
<span id="cb33-13">target_mix_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(target_mix_y, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOPleasant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ISOEventful"</span>])</span>
<span id="cb33-14"></span>
<span id="cb33-15">plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CircumplexPlot(</span>
<span id="cb33-16">    target_mix_y, backend<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Backend.SEABORN</span>
<span id="cb33-17">)</span>
<span id="cb33-18">g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plot.jointplot()</span>
<span id="cb33-19">g.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{mitchell,
  author = {Mitchell, Andrew},
  title = {Exploring Defining Single Value Indices - {SPI}},
  url = {https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code.html},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-mitchell" class="csl-entry quarto-appendix-citeas">
Mitchell, Andrew. n.d. <span>“Exploring Defining Single Value Indices -
SPI.”</span> <a href="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code.html">https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code.html</a>.
</div></div></section></div> ]]></description>
  <guid>https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/notebooks/SingleIndex-Code.html</guid>
  <pubDate>Thu, 07 Nov 2024 13:01:15 GMT</pubDate>
</item>
</channel>
</rss>
