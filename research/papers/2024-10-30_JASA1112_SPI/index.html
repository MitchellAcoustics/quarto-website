<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andrew Mitchell">
<meta name="author" content="Francesco Aletta">
<meta name="author" content="Tin Oberman">
<meta name="author" content="Jian Kang">
<meta name="dcterms.date" content="2024-10-28">
<meta name="keywords" content="Soundscape, Sound perception, index, urban design">
<meta name="description" content="Published in JASA in November, 2024. ">

<title>Soundscape Perception Indices (SPI): Developing context-dependent single value scores of multidimensional soundscape perceptual quality – Andrew Mitchell</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Soundscape Perception Indices (SPI): Developing context-dependent single value scores of multidimensional soundscape perceptual quality – Andrew Mitchell">
<meta property="og:description" content="Published in JASA in November, 2024. ">
<meta property="og:image" content="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta property="og:site_name" content="Andrew Mitchell">
<meta name="twitter:title" content="Soundscape Perception Indices (SPI): Developing context-dependent single value scores of multidimensional soundscape perceptual quality – Andrew Mitchell">
<meta name="twitter:description" content="Published in JASA in November, 2024. ">
<meta name="twitter:image" content="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta name="twitter:creator" content="@acousticsman">
<meta name="twitter:site" content="@acousticsman">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Andrew Mitchell</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-research" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Research</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-research">    
        <li>
    <a class="dropdown-item" href="../../../research/papers.html">
 <span class="dropdown-text">Open Source Papers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../research/presentations.html">
 <span class="dropdown-text">Talks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../research/list-of-pubs.html">
 <span class="dropdown-text">List of Publications</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../resources.html"> 
<span class="menu-text">Resources</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://github.com/MitchellAcoustics/quarto-website">
            Source Code
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://github.com/MitchellAcoustics/quarto-website/issues">
            Report a bug
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title"><p>Soundscape Perception Indices (SPI): Developing context-dependent single value scores of multidimensional soundscape perceptual quality</p></h1>
                  <div>
        <div class="description">
          Published in JASA in November, 2024. <span class="__dimensions_badge_embed__" data-doi="10.1121/10.0009794" data-hide-zero-citations="true" data-style="small_rectangle"></span>
          <script async="" src="https://badge.dimensions.ai/badge.js" charset="utf-8"></script>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">journal-articles</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-heading">Affiliations</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author">Andrew Mitchell <a href="mailto:a.j.mitchell@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0003-0978-5046" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University College London
            </p>
          <p class="affiliation">
              University College London
            </p>
        </div>
      <div class="quarto-title-meta-contents">
      <p class="author">Francesco Aletta <a href="mailto:f.aletta@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0003-0351-3189" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University College London
            </p>
        </div>
      <div class="quarto-title-meta-contents">
      <p class="author">Tin Oberman <a href="mailto:t.oberman@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University College London
            </p>
        </div>
      <div class="quarto-title-meta-contents">
      <p class="author">Jian Kang <a href="mailto:j.kang@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0001-8995-5636" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University College London
            </p>
        </div>
    </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 28, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">Abstract</div>
      <p>The soundscape approach provides a basis for considering the holistic perception of sound environments, in context. While steady advancements have been made in methods for assessment and analysis, a gap exists for comparing soundscapes and quantifying improvements in the multi-dimensional perception of a soundscape. To this end, there is a need for the creation of single value indices to compare soundscape quality which incorporate context, aural diversity, and specific design goals for a given application. Just as a variety of decibel-based indices have been developed for various purposes (e.g.&nbsp;<span class="math inline">L_{Aeq}</span>, <span class="math inline">L_{Ceq}</span>, <span class="math inline">L_{90}</span>, <span class="math inline">L_{den}</span>, etc.), the soundscape approach requires the ability to create novel indices for different uses, which share a common language and understanding. We therefore propose a unified framework for creating bespoke and reference single index measures of soundscape perception, allowing for new metrics to be defined in the future. This framework is based on a four-step test-target paradigm wherein a desired soundscape perception is defined as a target distribution within the soundscape circumplex and the 2D Kolmogorov-Smirnov distance is used to test an assessed soundscape against this target. Applications and implications of this framework are discussed and a multi-objective optimisation method for empirically defining perception indices is proposed.</p>
    </div>
  </div>

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>Soundscape, Sound perception, index, urban design</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-introduction" id="toc-sec-introduction" class="nav-link active" data-scroll-target="#sec-introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#sec-theoretical-background" id="toc-sec-theoretical-background" class="nav-link" data-scroll-target="#sec-theoretical-background"><span class="header-section-number">2</span> Theoretical Background</a>
  <ul>
  <li><a href="#sec-existing-soundscape-indices" id="toc-sec-existing-soundscape-indices" class="nav-link" data-scroll-target="#sec-existing-soundscape-indices"><span class="header-section-number">2.1</span> Existing ‘Soundscape Indices’</a>
  <ul class="collapse">
  <li><a href="#sec-soundscape-ecology-and-bioacoustics" id="toc-sec-soundscape-ecology-and-bioacoustics" class="nav-link" data-scroll-target="#sec-soundscape-ecology-and-bioacoustics"><span class="header-section-number">2.1.1</span> Soundscape Ecology and Bioacoustics</a></li>
  <li><a href="#sec-soundscape-perception" id="toc-sec-soundscape-perception" class="nav-link" data-scroll-target="#sec-soundscape-perception"><span class="header-section-number">2.1.2</span> Soundscape Perception</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-method" id="toc-sec-method" class="nav-link" data-scroll-target="#sec-method"><span class="header-section-number">3</span> Establishing the SPI Framework</a>
  <ul>
  <li><a href="#sec-core-method" id="toc-sec-core-method" class="nav-link" data-scroll-target="#sec-core-method"><span class="header-section-number">3.1</span> Core Method</a></li>
  <li><a href="#sec-circumplex-distribution" id="toc-sec-circumplex-distribution" class="nav-link" data-scroll-target="#sec-circumplex-distribution"><span class="header-section-number">3.2</span> Define and Parameterise a Soundscape Circumplex Distribution</a></li>
  <li><a href="#sec-sample-a-target-distribution" id="toc-sec-sample-a-target-distribution" class="nav-link" data-scroll-target="#sec-sample-a-target-distribution"><span class="header-section-number">3.3</span> Sample a Target Distribution</a></li>
  <li><a href="#compare-the-target-and-test-soundscape-assessment-distributions" id="toc-compare-the-target-and-test-soundscape-assessment-distributions" class="nav-link" data-scroll-target="#compare-the-target-and-test-soundscape-assessment-distributions"><span class="header-section-number">3.4</span> Compare the target and test soundscape assessment distributions</a></li>
  <li><a href="#calculate-the-spi-score" id="toc-calculate-the-spi-score" class="nav-link" data-scroll-target="#calculate-the-spi-score"><span class="header-section-number">3.5</span> Calculate the SPI score</a></li>
  </ul></li>
  <li><a href="#expanding-the-spi-framework" id="toc-expanding-the-spi-framework" class="nav-link" data-scroll-target="#expanding-the-spi-framework"><span class="header-section-number">4</span> Expanding the SPI framework</a>
  <ul>
  <li><a href="#bespoke-targets" id="toc-bespoke-targets" class="nav-link" data-scroll-target="#bespoke-targets"><span class="header-section-number">4.1</span> Bespoke Targets</a></li>
  <li><a href="#reference-targets" id="toc-reference-targets" class="nav-link" data-scroll-target="#reference-targets"><span class="header-section-number">4.2</span> Reference Targets</a>
  <ul class="collapse">
  <li><a href="#sec-targets" id="toc-sec-targets" class="nav-link" data-scroll-target="#sec-targets"><span class="header-section-number">4.2.1</span> Deriving a target based on a priori rankings</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-discussion" id="toc-sec-discussion" class="nav-link" data-scroll-target="#sec-discussion"><span class="header-section-number">5</span> Discussion</a>
  <ul>
  <li><a href="#applications-of-the-spi-framework" id="toc-applications-of-the-spi-framework" class="nav-link" data-scroll-target="#applications-of-the-spi-framework"><span class="header-section-number">5.1</span> Applications of the SPI framework</a></li>
  <li><a href="#connecting-with-soundscape-data" id="toc-connecting-with-soundscape-data" class="nav-link" data-scroll-target="#connecting-with-soundscape-data"><span class="header-section-number">5.2</span> Connecting with soundscape data</a></li>
  <li><a href="#comparison-with-existing-soundscape-indices" id="toc-comparison-with-existing-soundscape-indices" class="nav-link" data-scroll-target="#comparison-with-existing-soundscape-indices"><span class="header-section-number">5.3</span> Comparison with existing soundscape indices</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations"><span class="header-section-number">5.4</span> Considerations and future work</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">6</span> Conclusion</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements">Acknowledgements</a></li>
  <li><a href="#data-and-code-availability" id="toc-data-and-code-availability" class="nav-link" data-scroll-target="#data-and-code-availability">Data and Code Availability</a></li>
  <li><a href="#author-contributions" id="toc-author-contributions" class="nav-link" data-scroll-target="#author-contributions">Author contributions</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">7</span> References</a></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="notebooks/SingleIndex-Code-preview.html"><i class="bi bi-journal-code"></i>Exploring defining single value indices - SPI</a></li><li><a href="notebooks/TargetOptimization-preview.html"><i class="bi bi-journal-code"></i>Supplementary Material for: Soundscape Perception Indices (SPI) </a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="sec-introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>The EU Green Paper on Future Noise Policy indicates that 80 million EU citizens are suffering from potentially harmful environmental noise levels, according to the World Health Organization (WHO) recommendations <span class="citation" data-cites="Berglund1999Guidelines">(<a href="#ref-Berglund1999Guidelines" role="doc-biblioref">Berglund, Lindvall, and Schwela 1999</a>)</span>. The publication of the EU Directive Relating to the Assessment and Management of Environmental Noise (END) <span class="citation" data-cites="EuropeanUnion2002Directive">(<a href="#ref-EuropeanUnion2002Directive" role="doc-biblioref">European Union 2002</a>)</span> more than two decades ago has led to major actions across Europe, with reducing noise levels as their main focus, for which billions of Euros are being spent. However, it is widely recognised that solely reducing sound level in people’s living environments is not always feasible or cost-effective and, more importantly, with only 30% of environmental noise annoyance depending on physical aspects of the signal such as acoustic energy <span class="citation" data-cites="Guski1997Psychological">(<a href="#ref-Guski1997Psychological" role="doc-biblioref">Guski 1997</a>)</span>, sound level reduction will not necessarily lead to improved quality of life. For this reason, from a public health point of view, it is necessary to explore alternative management and design strategies for acoustic environments that rely on more positive soundscapes, rather than merely environments not affected by noise pollution <span class="citation" data-cites="Aletta2018Associations Kang2023Soundscape Kang2023Supportive">(<a href="#ref-Aletta2018Associations" role="doc-biblioref">Aletta, Oberman, and Kang 2018</a>; <a href="#ref-Kang2023Soundscape" role="doc-biblioref">Kang 2023</a>; <a href="#ref-Kang2023Supportive" role="doc-biblioref">Kang et al. 2023</a>)</span>.</p>
<p>Soundscape design, separate from (and complementary to) noise control engineering, is about the relationships between human physiology, perception, the sound environment, and its socio-cultural context <span class="citation" data-cites="Kang2006Urban">(<a href="#ref-Kang2006Urban" role="doc-biblioref">Kang 2006</a>)</span>. Soundscape research represents a paradigm shift in that it combines physical, social, and psychological approaches and considers environmental sounds as a ‘resource’ rather than ‘waste’ <span class="citation" data-cites="Kang2016Soundscape">(<a href="#ref-Kang2016Soundscape" role="doc-biblioref">Kang and Schulte-Fortkamp 2016</a>)</span> relating to perceptual constructs rather than just physical phenomena. However, the current research is still at the stage of describing and identifying the problems and tends to be fragmented and focussed on only special cases e.g.~subjective evaluations of soundscapes for residential areas <span class="citation" data-cites="SchulteFortkamp2013Introduction Chen2023Natural">(<a href="#ref-SchulteFortkamp2013Introduction" role="doc-biblioref">Schulte-Fortkamp and Kang 2013</a>; <a href="#ref-Chen2023Natural" role="doc-biblioref">Chen and Kang 2023</a>)</span>. In the movement from noise control to soundscape creation <span class="citation" data-cites="Aletta2015Soundscape">(<a href="#ref-Aletta2015Soundscape" role="doc-biblioref">Aletta and Kang 2015</a>)</span>, a vital step is the standardisation of methods to assess soundscape quality.</p>
<p>A common aim for implementing soundscape assessment in practice is to compare the quality of different soundscapes. Often (but not always) the goal is to identify a ‘good’ soundscape compared to a ‘bad’ soundscape. However, this presents several challenges:</p>
<ul>
<li>What makes a soundscape good or bad is highly contextual; that is, the same acoustic environment may result in different appreciations and perceptual outcomes, depending on where/when it is happening, and what groups of individuals are there to experience it.</li>
<li>On what metric should the quality rating be based? Previous attempts at defining objective metrics of “soundscape quality” assessment have fallen short of capturing the multidimensionality of people’s perception of surrounding acoustic environments.</li>
<li>How can we deal with different requirements and definitions of how a soundscape should be perceived? Soundscape constructs are normally seen as highly individualised, while designing the soundscapes of public spaces should look at accommodating the needs of a given community of a space as a whole.</li>
</ul>
<p>In many cases, the ultimate aim is to be able to rank soundscapes based on their quality. There is pressure from stakeholders and policymakers to move towards such simplified assessment protocols. However, any ranking metric should be flexible and be able to handle a variety of contexts and definitions of what a `good’ soundscape is for a given purpose. To address this, we will propose the Soundscape Perception Index (SPI) framework, a flexible method for defining single value indices of soundscape quality based on distributions within the Soundscape Circumplex Model (SCM) <span class="citation" data-cites="Axelsson2012Swedish Mitchell2022How Axelsson2010principal">(<a href="#ref-Axelsson2012Swedish" role="doc-biblioref">Östen Axelsson, Nilsson, and Berglund 2012</a>; <a href="#ref-Mitchell2022How" role="doc-biblioref">Mitchell, Aletta, and Kang 2022</a>; <a href="#ref-Axelsson2010principal" role="doc-biblioref">Ö. Axelsson, Nilsson, and Berglund 2010</a>)</span>. As previously suggested, the primary motivation behind the development of the Soundscape Perception Indices (SPI) framework stems from the need to address the existing gap in quantifying and comparing soundscape quality across diverse contexts and applications. By creating a unified framework for defining these indices, the aim is to is to empower stakeholders, decision-makers, and researchers with the ability to create tailored indices that align with their specific objectives and design goals, while simultaneously enabling cross-comparisons and benchmarking against empirically-defined reference soundscapes. This dual approach not only acknowledges the context-dependent nature of soundscape perception but also fosters a common language and understanding, facilitating knowledge sharing and collaborative efforts within the field. This paper will demonstrate the SPI framework and test whether it is capable of both scoring soundscape quality and generating consistent rankings of soundscapes across different contexts.</p>
</section>
<section id="sec-theoretical-background" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Theoretical Background</h1>
<p>In <span class="citation" data-cites="Aletta2016Soundscape">Aletta, Kang, and Axelsson (<a href="#ref-Aletta2016Soundscape" role="doc-biblioref">2016</a>)</span>, the authors defined a framework for categorising the components of a soundscape assessment. They define three aspects: soundscape descriptors, soundscape indicators, and soundscape indices. Soundscape descriptors are defined as ‘measures of how people perceive the acoustic environment’ and soundscape indicators as ‘measures used to predict the value of a soundscape descriptor’. The relationship between soundscape indicator(s) and a soundscape descriptor effectively defines what has been previously referred to as a “predictive soundscape model” <span class="citation" data-cites="Aletta2016Soundscape Mitchell2022Predictive">(<a href="#ref-Aletta2016Soundscape" role="doc-biblioref">Aletta, Kang, and Axelsson 2016</a>; <a href="#ref-Mitchell2022Predictive" role="doc-biblioref">Mitchell 2022</a>)</span>. There are primarily two rationales for modeling the relationship between the physical attributes and the perceived (i.e., soundscape) qualities of the acoustic environment. Firstly, a predictive model can forecast how individuals would perceive the acoustic environment, eliminating the need for labour-intensive surveys <span class="citation" data-cites="Mitchell2023conceptual">(<a href="#ref-Mitchell2023conceptual" role="doc-biblioref">Mitchell et al. 2023</a>)</span>. Secondly, a precise predictive model may unveil the root causes of these perceived qualities, thereby serving as a valuable tool for design. <span class="citation" data-cites="Lionello2020systematic">Lionello, Aletta, and Kang (<a href="#ref-Lionello2020systematic" role="doc-biblioref">2020</a>)</span> provided a review of such models and concluded contextual features play an important role in increasing the quality of the model. Indices on the other hand, the primary focus of this article, are single numerical values that combine multiple indicators or descriptors to provide a comprehensive representation of the overall soundscape perception and allow for comparison between soundscapes.</p>
<p>The earliest and most commonly used scientific index measuring sound level is the Decibel (dB). To represent the overall level of sound with a single value on one scale, as the Decibel index does, is often desirable. For this purpose, a number of different values representing sounds at various frequencies must be combined. Several frequency weighting networks have been developed since the 1930s, considering typical human responses to sound based on equal-loudness-level contours <span class="citation" data-cites="Fletcher1933Loudness">(<a href="#ref-Fletcher1933Loudness" role="doc-biblioref">Fletcher and Munson 1933</a>)</span> and, among them, the A-weighting network, with resultant decibel values called dBA, has been commonly used in almost all the national/international regulations <span class="citation" data-cites="Kryter1994Handbook">(<a href="#ref-Kryter1994Handbook" role="doc-biblioref">Kryter 1994</a>)</span>. However, there have been numerous criticisms on its effectiveness <span class="citation" data-cites="Parmanen2007weighted">(<a href="#ref-Parmanen2007weighted" role="doc-biblioref">Parmanen 2007</a>)</span> as the correlations between dBA and perceived sound quality (e.g.~noise annoyance) are often low <span class="citation" data-cites="Hellman1987Why">(<a href="#ref-Hellman1987Why" role="doc-biblioref">Hellman and Zwicker 1987</a>)</span>.</p>
<p>Another set of indices is psychoacoustic magnitudes, including loudness, fluctuation strength or roughness, sharpness, and pitch strength, developed through sound quality studies of industrial products since the 1980’s <span class="citation" data-cites="Zwicker2007Psychoacoustics">(<a href="#ref-Zwicker2007Psychoacoustics" role="doc-biblioref">Zwicker and Fastl 2007</a>)</span>. These emerged when it was conceived that acoustic emissions can be characterised beyond just sound level <span class="citation" data-cites="Blauert1997Sound">(<a href="#ref-Blauert1997Sound" role="doc-biblioref">Blauert and Jekosch 1997</a>)</span>. But while psychoacoustic magnitudes have proven to be successful for the assessment of product sound quality, in the field of environmental acoustics, their applicability has been limited <span class="citation" data-cites="Fastl2006Psychoacoustic">(<a href="#ref-Fastl2006Psychoacoustic" role="doc-biblioref">Fastl 2006</a>)</span>, since a significant feature of environmental acoustics is that there are multiple/dynamic sound sources. Additionally, while pyschoacoustic magnitudes incorporate perceptual aspects, both dB based and pyschoacoustic indicies are ultimately describing the acoustic signal and not the soundscape perception and may therefore be more accurately described as indicators rather than soundscape indices <span class="citation" data-cites="Mitchell2023conceptual">(<a href="#ref-Mitchell2023conceptual" role="doc-biblioref">Mitchell et al. 2023</a>)</span>.</p>
<p>When applied to urban sound and specifically to noise pollution, the soundscape approach introduces three key considerations beyond traditional noise control methods:</p>
<ol type="1">
<li>considering all aspects of the environment which may influence perception, not just the sound level and spectral content (e.g., visual setting, odour environment, spatial layout, etc.);</li>
<li>an increased and integrated consideration of the varying impacts which different sound sources and sonic characteristics have on perception; and</li>
<li>a consideration of both the positive and negative dimensions of soundscape perception.</li>
</ol>
<p>This approach can enable better outcomes by identifying positive soundscapes (in line with the END’s mandate to “preserve environmental noise quality where it is good” <span class="citation" data-cites="EuropeanUnion2002Directive">(<a href="#ref-EuropeanUnion2002Directive" role="doc-biblioref">European Union 2002</a>)</span>), better identifying specific sources of noise which impact soundscape quality and pinpointing the characteristics which may need to be decreased, and illuminating alternative methods which could be introduced to improve a soundscape where a reduction of noise is impractical <span class="citation" data-cites="Fiebig2018Does Kang2018Impact">(<a href="#ref-Fiebig2018Does" role="doc-biblioref">Fiebig 2018</a>; <a href="#ref-Kang2018Impact" role="doc-biblioref">Kang and Aletta 2018</a>)</span>. Factors such as the presence of natural or human-made sounds, their temporal patterns, and the overall contextual meaning ascribed to these sounds all contribute to the holistic perception of a soundscape.</p>
<section id="sec-existing-soundscape-indices" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-existing-soundscape-indices"><span class="header-section-number">2.1</span> Existing ‘Soundscape Indices’</h2>
<p>While the field of soundscape research has witnessed substantial progress, the development of standardized indices for evaluating and comparing soundscapes across diverse contexts has been relatively limited. Existing indices can be broadly seen as arising from two domains: soundscape ecology and soundscape perception.</p>
<section id="sec-soundscape-ecology-and-bioacoustics" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="sec-soundscape-ecology-and-bioacoustics"><span class="header-section-number">2.1.1</span> Soundscape Ecology and Bioacoustics</h3>
<p>Within the realm of soundscape ecology, indices such as the Acoustic Diversity Index (ADI) and Frequency-dependent Acoustic Diversity Index (FADI) <span class="citation" data-cites="Xu2023frequency">(<a href="#ref-Xu2023frequency" role="doc-biblioref">Xu et al. 2023</a>)</span> have been developed to quantify the diversity and complexity of acoustic signals within a given soundscape. Similar indices (e.g.&nbsp;ADI, NDSI, ACI) have also been developed to analyse the acoustic signal of complex acoustic environments and indicate the richness and diversity of biophonic (natural) and anthrophonic (human-made) sound sources. However, while these indices contribute valuable insights into the ecological aspects of soundscapes, they do not directly address the perceptual dimensions that are central to the soundscape approach <span class="citation" data-cites="SchulteFortkamp2023Soundscapes">(<a href="#ref-SchulteFortkamp2023Soundscapes" role="doc-biblioref">Schulte-Fortkamp et al. 2023</a>)</span>. The multi-dimensional nature of soundscape perception, encompassing factors such as pleasantness, eventfulness, and familiarity, necessitates a more comprehensive and context-sensitive approach.</p>
</section>
<section id="sec-soundscape-perception" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="sec-soundscape-perception"><span class="header-section-number">2.1.2</span> Soundscape Perception</h3>
<p>In the domain of soundscape perception, several indices have emerged as attempts to quantify the perceived quality of soundscapes, particularly in urban environments.</p>
<p>The Green Soundscape Index (GSI) <span class="citation" data-cites="Kogan2018Green">(<a href="#ref-Kogan2018Green" role="doc-biblioref">Kogan et al. 2018</a>)</span> incorporates factors such as the presence and levels of natural sounds and human-made sounds, and their respective contributions to the overall soundscape perception. The GSI is defined as the ratio of the perceived extent of natural sounds (PNS) to the perceived extent of traffic noise (PTN), ranging between 1/5 and 5. Subsequently, Cao and colleagues <span class="citation" data-cites="Cao2020Red Yang2022Effects">(<a href="#ref-Cao2020Red" role="doc-biblioref">Cao, Meng, and Kang 2020</a>; <a href="#ref-Yang2022Effects" role="doc-biblioref">Yang, Cao, and Meng 2022</a>)</span> proposed the Red Soundscape Index (<span class="math inline">RSI</span>), defined as the ratio of the perceived extent of human sounds to the perceived extent of either natural sounds (<span class="math inline">RSI_n</span>) or traffic sounds (<span class="math inline">RSI_t</span>), arguing that the GSI alone was not suitable for all urban soundscape design applications.</p>
<p>Building on ecological diversity concepts, <span class="citation" data-cites="Liu2014Effects">Liu et al. (<a href="#ref-Liu2014Effects" role="doc-biblioref">2014</a>)</span> introduced the Soundscape Diversity Index (SDI), which quantifies the probability of two randomly selected sounds in a soundscape belonging to different categories, providing a measure of soundscape complexity. Expanding on this approach, <span class="citation" data-cites="Xiang2023Soundscape">Xiang et al. (<a href="#ref-Xiang2023Soundscape" role="doc-biblioref">2023</a>)</span> defined an expanded set of soundscape diversity indices, including the SDI, the Soundscape Richness Index (SRI), the Soundscape Dominance Index (SDO), and the Soundscape Evenness Index (SEI). These indices, adapted from species diversity measures in ecology, offer a more nuanced approach to quantifying aspects of soundscape perception. <span class="citation" data-cites="Xiang2023Soundscape">Xiang et al. (<a href="#ref-Xiang2023Soundscape" role="doc-biblioref">2023</a>)</span> demonstrated that these indices could be partially explained by existing acoustic indicators and were more suitable for evaluating urban green spaces than traditional acoustic indices.</p>
<p><span class="citation" data-cites="Guo2023Harmonious">Guo et al. (<a href="#ref-Guo2023Harmonious" role="doc-biblioref">2023</a>)</span> proposed the Harmonious Degree of Sound Sources (SHD) index, which combines perceived loudness, occurrence, and preference for sound sources. The SHD assess how well the dominance of a sound aligns with visitors’ preferences, aiming to reflect the harmonious status of sounds in a soundscape.</p>
<p>In 2019, <span class="citation" data-cites="Kang2019Towards">Kang et al. (<a href="#ref-Kang2019Towards" role="doc-biblioref">2019</a>)</span> proposed the development of a set of soundscape indices (SSID) which might take the form <span class="math inline">SSID = f(\text{physical factors}) + f(\text{contextual factors}) + \ldots</span> where the functions and weights of each aspect influencing soundscape perception (i.e.&nbsp;physical/acoustic parameters, contextual and visual factors, personal factors, etc.) could be derived statistically from a large dataset of soundscape surveys. The work presented here represents a development of this thinking which has grown out of the SSID project, where the analysis and indexing of perception data and the connection between soundscape indicators and perception have been separated <span class="citation" data-cites="Mitchell2023conceptual">(<a href="#ref-Mitchell2023conceptual" role="doc-biblioref">Mitchell et al. 2023</a>)</span>. This modularization of perception prediction based on objective factors and soundscape index creation should enable more sophisticated and thoughtful index creation and more advanced and updateable prediction models.</p>
<p>While these indices offer valuable insights into specific aspects of soundscape perception, they are limited in their ability to capture the full multidimensionality of soundscape experienve across diverse contexts. The Soundscape Perception Index (SPI) framework presented in this paper builds upon these efforts by providing a flexible, context-sensitive approach to soundscape assessment. Unlike many previous indices, the SPI is not an analysis of an acoustic signal but rather is an index of perception based on soundscape descriptors. Furthermore, it does not represent a single target in a particular context, but is a generalisable, extensible, and adaptable framework for scoring soundscapes against any goal defined by the user.</p>
<p>The remainder of the paper will introduce and demonstrate this framework, providing a case study of defining an appropriate target.</p>
</section>
</section>
</section>
<section id="sec-method" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Establishing the SPI Framework</h1>
<p>The index framework, ‘Soundscape Perception Indices (SPI)’ introduced in this paper is defined here as the agreement between an observed or modelled soundscape perception distribution and a target soundscape perception distribution. Its goal is to determine whether a soundscape - whether it be a real-world location, a proposed design, or a hypothetical scenario - aligns with the desired (or reference) perception of that soundscape. This is achieved by first defining the target distribution, which could represent what is considered to be the ‘ideal’ soundscape perception for a given context or application. The test distribution is then compared to the target distribution using a distance metric, which quantifies the deviation between the two distributions. The resulting distance value serves as the basis for calculating the SPI, with smaller distances indicating a closer alignment between the perceived soundscape and the target soundscape perception.</p>
<p>We refer to this as an index framework rather than a single index, as the SPI can be tailored to specific contexts and applications by defining a range of target distributions. A single index is thus created for each target distribution. An SPI value therefore does not represent a ‘good’ or ‘bad’ soundscape, but rather a measure of how closely the perceived soundscape aligns with the desired target soundscape perception. This approach allows for the development of bespoke indices tailored to specific design goals and objectives, while also enabling cross-comparisons and benchmarking against empirically-defined reference soundscape targets.</p>
<section id="sec-core-method" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-core-method"><span class="header-section-number">3.1</span> Core Method</h2>
<p>SPI is grounded in the soundscape circumplex model (SCM) <span class="citation" data-cites="Axelsson2010principal Axelsson2012Swedish">(<a href="#ref-Axelsson2010principal" role="doc-biblioref">Ö. Axelsson, Nilsson, and Berglund 2010</a>; <a href="#ref-Axelsson2012Swedish" role="doc-biblioref">Östen Axelsson, Nilsson, and Berglund 2012</a>)</span>, a robust theoretical foundation for understanding and representing the multi-dimensional nature of soundscape perception. The reason for grounding the SPI in the soundscape circumplex is that we have observed this model to become the most prevalent assessment model in soundscape literature <span class="citation" data-cites="Aletta2023Adoption">(<a href="#ref-Aletta2023Adoption" role="doc-biblioref">Aletta and Torresin 2023</a>)</span>. The SCM is built on a series of descriptors referred to as the Perceived Affective Quality (PAQ), proposed by <span class="citation" data-cites="Axelsson2010principal">(<a href="#ref-Axelsson2010principal" role="doc-biblioref">Ö. Axelsson, Nilsson, and Berglund 2010</a>)</span>. These PAQs are based on the pleasantness-eventfulness paradigm adopted in research on emotions and environmental psychology (and its original version, conceptualized as valence-arousal paradigm), in particular Russell’s circumplex model of affect <span class="citation" data-cites="Russell1980circumplex">(<a href="#ref-Russell1980circumplex" role="doc-biblioref">Russell 1980</a>)</span>. As summarised by <span class="citation" data-cites="Axelsson2010principal">Ö. Axelsson, Nilsson, and Berglund (<a href="#ref-Axelsson2010principal" role="doc-biblioref">2010</a>)</span>: “Russell’s model identifies two dimensions related to the perceived pleasantness of environments and how activating or arousing the environment is.”</p>
<p>One benefit of the circumplex model is that, as a whole, it encapsulates several of the other proposed soundscape descriptors - in particular, annoyance, pleasantness, tranquillity, and possibly restorativeness <span class="citation" data-cites="Aletta2016Soundscape">(<a href="#ref-Aletta2016Soundscape" role="doc-biblioref">Aletta, Kang, and Axelsson 2016</a>)</span>. According to <span class="citation" data-cites="Axelsson2015How">Ö. Axelsson (<a href="#ref-Axelsson2015How" role="doc-biblioref">2015</a>)</span>, the two-dimensional circumplex model of perceived affective quality provides the most comprehensive information for soundscape assessment. It is also possible that the overall soundscape quality could itself be derived from the pleasant-eventful scores derived for a soundscape. The circumplex also lends itself well to questionnaire-based methods of data collection, as proposed in <span class="citation" data-cites="ISO12913Part2">ISO/TS 12913-2:2018 (<a href="#ref-ISO12913Part2" role="doc-biblioref">2018</a>)</span>. In contrast to methods such as soundwalks, interviews, and lab experiments, questionnaires are able to provide the quality and amount of data which is necessary for statistical modelling. Combined, these factors make the circumplex most appropriate for a single index as it provides a comprehensive summary of soundscape perception.</p>
<p>There are four steps involved in calculating the SPI, as shown in <a href="#fig-bespoke-spi" class="quarto-xref">Figure&nbsp;1</a>:</p>
<ol type="1">
<li>Define and parameterise the target circumplex distribution;</li>
<li>Sample the target distribution and prepare the test distribution;</li>
<li>Compare test and target distributions using the distance metric (two-dimensional Kolmogorov-Smirnov distance <span class="math inline">D_{BKS}</span>);</li>
<li>Calculate <span class="math inline">SPI = 100 * (1 - D_{BKS})</span>.</li>
</ol>
<div id="fig-bespoke-spi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bespoke-spi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/SPI-framework.drawio.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bespoke-spi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Steps for calculating the SPI.
</figcaption>
</figure>
</div>
<p>These steps and their required background are discussed in detail in the following sections. <a href="#sec-targets" class="quarto-xref">Section&nbsp;4.2.1</a> will then present strategies for defining targets and their applications. Throughout this paper, we use the data contained in the International Soundscape Database (ISD) <span class="citation" data-cites="Mitchell2024International">(<a href="#ref-Mitchell2024International" role="doc-biblioref">Mitchell et al. 2024</a>)</span>, which includes 1300+ individual responses on the PAQ scales collected across 13 locations in London and Venice, according to the SSID Protocol <span class="citation" data-cites="Mitchell2020Soundscape">(<a href="#ref-Mitchell2020Soundscape" role="doc-biblioref">Mitchell et al. 2020</a>)</span>.</p>
</section>
<section id="sec-circumplex-distribution" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-circumplex-distribution"><span class="header-section-number">3.2</span> Define and Parameterise a Soundscape Circumplex Distribution</h2>
<p>To move the eight-item PAQ responses into the two-dimensional circumplex space, we use the projection method first presented in ISO/TS 12913-3:2018 <span class="citation" data-cites="ISO12913Part3">(<a href="#ref-ISO12913Part3" role="doc-biblioref">ISO/TS 12913-3:2019 2019</a>)</span>. This projection method and its associated formulae were recently updated further in <span class="citation" data-cites="Aletta2024Soundscape">Aletta et al. (<a href="#ref-Aletta2024Soundscape" role="doc-biblioref">2024</a>)</span> to include a correction for the language in which the survey was conducted. <span class="citation" data-cites="Aletta2024Soundscape">Aletta et al. (<a href="#ref-Aletta2024Soundscape" role="doc-biblioref">2024</a>)</span> also provides adjusted angles for translations of the circumplex attributes to be used in calculating the <span class="math inline">P_{ISO}</span> and <span class="math inline">E_{ISO}</span> coordinates. Once the individual perceptual responses are projected into the circumplex space, the resulting data for each location is treated as a circumplex distribution. There are several advancements in considering circumplex distributions compared to the discussions originally given in <span class="citation" data-cites="Mitchell2022How">Mitchell, Aletta, and Kang (<a href="#ref-Mitchell2022How" role="doc-biblioref">2022</a>)</span> which are necessary for SPI. Before exploring the SPI method and target setting more specifically, we will first address these developments.</p>
<p>The circumplex is defined by two axes: <span class="math inline">P_{ISO}</span> and <span class="math inline">E_{ISO}</span>, which are limited to the range <span class="math inline">[-1, +1]</span>. Typically, data in the soundscape circumplex is treated as a combination of two independent normal distributions, one for each axis <span class="citation" data-cites="Mitchell2022How Ooi2022Probably">(<a href="#ref-Mitchell2022How" role="doc-biblioref">Mitchell, Aletta, and Kang 2022</a>; <a href="#ref-Ooi2022Probably" role="doc-biblioref">Ooi et al. 2022</a>)</span>. In some applications this approach is sufficient for capturing the distribution of soundscape perception, however defining a target distribution for SPI requires a more precise approach. The independent normal distribution approach relies on three key assumptions:</p>
<ol type="1">
<li>The two axes are normally distributed.</li>
<li>The two axes are symmetrically distributed.</li>
<li>The two axes are independent of each other.</li>
</ol>
<p>While the first assumption is generally valid, the second and third assumptions are not always met in practice. In particular, the distribution of soundscape perception responses in the circumplex is often characterised by a high degree of skewness, which can lead to inaccuracies in the calculation of the SPI. Soundscape circumplex distributions are most appropriately described as a bivariate skew-normal distribution <span class="citation" data-cites="Azzalini2005Skew">(<a href="#ref-Azzalini2005Skew" role="doc-biblioref">Adelchi Azzalini 2005</a>)</span> which accurately reflects the relationship between the two dimensions of the circumplex and the fact that real-world perceptual distributions have been consistently observed to not be strictly symmetric.</p>
<p>The skew-normal distribution is defined by three parameters: location (<span class="math inline">\mu</span>), scale (<span class="math inline">\sigma</span>), and shape (<span class="math inline">\alpha</span>). The location parameter defines the centre of the distribution, the scale parameter defines the spread of the distribution and the shape parameter defines the skew of the distribution. The one-dimensional skew-normal distribution is defined as <span class="citation" data-cites="Azzalini1996Multivariate">(<a href="#ref-Azzalini1996Multivariate" role="doc-biblioref">A. Azzalini and Valle 1996</a>)</span>:</p>
<p><span class="math display">
\phi(z; \alpha) = 2 \phi(z) \Phi(\alpha z) \quad \text{for} \quad z \in \mathbb{R}
</span></p>
<p>where <span class="math inline">\phi</span> and <span class="math inline">\Phi</span> are the standard normal probability density function and distribution function, respectively, and <span class="math inline">\alpha</span> is a shape variable which regulates the skewness. The distribution reduces to a standard normal density when <span class="math inline">\alpha = 0</span>. The bivariate skew-normal distribution extends this concept to two dimensions, allowing for the modelling of asymmetric and skewed distributions in a two-dimensional space such as the soundscape circumplex. The multivariate skew-normal (MSN) distribution including scale and location parameters is given by combining the normal density and distribution functions <span class="citation" data-cites="Azzalini1999Statistical">(<a href="#ref-Azzalini1999Statistical" role="doc-biblioref">A. Azzalini and Capitanio 1999</a>)</span>:</p>
<p><span class="math display">
Y = 2 \phi_k (y-\xi; \Omega) \Phi\{\alpha^T\omega^{-1}(y-\xi)\}
</span></p>
<p>where <span class="math inline">\phi_k</span> is the <em>k</em>-dimensional normal density with location <span class="math inline">\xi</span>, shape <span class="math inline">\alpha</span>, and covariance matrix <span class="math inline">\Omega</span>. <span class="math inline">\Phi \{ \dot \}</span> is the normal distribution function and <span class="math inline">\alpha</span> is a <em>k</em>-dimensional shape vector. When <span class="math inline">\alpha = 0</span>, <span class="math inline">Y</span> reduces to the standard multivariate normal <span class="math inline">N_k(\xi, \Omega)</span> density. A circumplex distribution can therefore be parameterised<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> with a 2x2 covariance matrix <span class="math inline">\Omega</span>, a 2x1 location vector <span class="math inline">\xi</span>, and a 2x1 shape vector <span class="math inline">\alpha</span>, written as:</p>
<p><span class="math display">
Y \sim MSN (\xi, \Omega, \alpha)
</span></p>
<p>By fitting an MSN distribution to empirical soundscape perception responses, it becomes possible to accurately capture the asymmetry and skewness of the distribution. A bivariate skew-normal distribution can be summarised as a set of these three parameters. Once parameterised, the distribution can then be sampled from to generate a synthetic distribution of soundscape perception responses.</p>
<p>Soundscape targets can thus be set by defining the desired MSN distribution. To demonstrate this, we will construct three arbitrary targets which will be used later to score three SPIs. The parameters chosen for the example targets are given in <a href="#tbl-target-params" class="quarto-xref">Table&nbsp;1</a>.</p>
<div id="tbl-target-params" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-target-params-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: The MSN direct parameterizations for three arbitrary example target distributions. <span class="math inline">\text{tgt}_1</span> is located in the pleasant half, with a wide variance, and a positive skew along the pleasantness axis. <span class="math inline">\text{tgt}_2</span> is located in the calm quadrant, with a typical variance, and a negative skew along the pleasantness axis and a positive skew along the eventful axis. <span class="math inline">\text{tgt}_3</span> is located in the vibrant quadrant, with a moderate variance, and a negative skew along the eventfulness axis.
</figcaption>
<div aria-describedby="tbl-target-params-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 56%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Target</th>
<th style="text-align: center;">Location <span class="math inline">\xi</span></th>
<th style="text-align: center;">Covariance Matrix <span class="math inline">\Omega</span></th>
<th style="text-align: center;">Shape <span class="math inline">\alpha</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\text{tgt}_1</span></td>
<td style="text-align: center;"><span class="math inline">[0.5, 0.0]</span></td>
<td style="text-align: center;"><span class="math inline">\begin{bmatrix} 0.2 &amp; 0.0 \\ 0.0 &amp; 0.2 \end{bmatrix}</span></td>
<td style="text-align: center;"><span class="math inline">[1, 0]</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\text{tgt}_2</span></td>
<td style="text-align: center;"><span class="math inline">[1.0, -0.4]</span></td>
<td style="text-align: center;"><span class="math inline">\begin{bmatrix} 0.18 &amp; -0.04 \\ -0.04 &amp; 0.09 \end{bmatrix}</span></td>
<td style="text-align: center;"><span class="math inline">[-8, 1]</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\text{tgt}_3</span></td>
<td style="text-align: center;"><span class="math inline">[0.5, 0.7]</span></td>
<td style="text-align: center;"><span class="math inline">\begin{bmatrix} 0.1 &amp; 0.05 \\ 0.05 &amp; 0.1 \end{bmatrix}</span></td>
<td style="text-align: center;"><span class="math inline">[0, -5]</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-sample-a-target-distribution" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="sec-sample-a-target-distribution"><span class="header-section-number">3.3</span> Sample a Target Distribution</h2>
<p>Once the parameters for an MSN are defined (i.e., the target), the MSN is then sampled using the <code>sn</code> package <span class="citation" data-cites="Azzalini2021R">(<a href="#ref-Azzalini2021R" role="doc-biblioref">A. Azzalini 2021</a>)</span> in <code>R</code> <span class="citation" data-cites="RCT2018R">(<a href="#ref-RCT2018R" role="doc-biblioref">R Core Team 2018</a>)</span>. This is to prepare the target distribution to be compared with the empirical test distribution. Several restrictions to the possible parameter values apply, most importantly the covariance matrix <span class="math inline">\Omega</span> must be a positive-definite matrix. In depth discussions of how these parameterizations should be defined and their restrictions can be found in <span class="citation" data-cites="Azzalini2016How">Adelchi Azzalini (<a href="#ref-Azzalini2016How" role="doc-biblioref">2016</a>)</span>. <a href="#fig-targets" class="quarto-xref">Figure&nbsp;2</a> shows the result of sampling (n=1000) the three example distributions given in <a href="#tbl-target-params" class="quarto-xref">Table&nbsp;1</a> and plotting them as soundscape distributions.</p>
<div class="quarto-embed-nb-cell">
<div id="cell-fig-targets" class="cell" data-execution_count="48">
<div class="cell-output cell-output-display">
<div id="fig-targets" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/notebooks-SingleIndex-Code-fig-targets-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Example of defining and sampling from three arbitrary bespoke targets.
</figcaption>
</figure>
</div>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-1" href="notebooks/SingleIndex-Code-preview.html#cell-fig-targets">Source: Exploring defining single value indices - SPI</a></div>
</section>
<section id="compare-the-target-and-test-soundscape-assessment-distributions" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="compare-the-target-and-test-soundscape-assessment-distributions"><span class="header-section-number">3.4</span> Compare the target and test soundscape assessment distributions</h2>
<p>Central to the SPI framework is the concept of a distance metric, which quantifies the deviation of a given soundscape from a desired target soundscape. This distance metric serves as the basis for calculating the SPI value, with smaller distances indicating a closer alignment between the perceived soundscape and the target soundscape perception. The distance between the test and target soundscape distributions is calculated using a two-dimensional Kolmogorov-Smirnov distance <span class="math inline">D_{BKS}</span>} <span class="citation" data-cites="Fasano1987multidimensional">(<a href="#ref-Fasano1987multidimensional" role="doc-biblioref">Fasano and Franceschini 1987</a>)</span>. The KS distance is a non-parametric metric of the equality of continuous distributions which is sensitive to both the location and shape of the distributions <span class="citation" data-cites="Chakravati1967Handbook">(<a href="#ref-Chakravati1967Handbook" role="doc-biblioref">Chakravati, Laha, and Roy 1967</a>)</span>.</p>
<p>Essentially, we approach this as a problem of (dis)similarity between soundscapes. The <span class="math inline">D_{BKS}</span> distance metric is then proposed to assess how similar any two given soundscapes distributions are within the circumplex. Taken to the extreme, two perfectly matching distributions in the soundscape circumplex would return a 100% SPI value, while two completely dissimilar distributions would return a 0% SPI value. In practical terms, for the former, this will never be achieved in real world scenarios; for the latter, it is also difficult to estimate how low the SPI value could actually go, and it should be considered that the distance may happen in different directions within the circumplex space. For instance, if a distribution for a vibrant soundscape was taken as a reference, a compared soundscape distribution may exhibit low SPI values for being located in the calm, OR monotonous, OR chaotic regions of the model.</p>
<p>Using the data from one location in the ISD (Piazza San Marco) as the test distribution, the <span class="math inline">D_{BKS}</span> statistic is calculated for each of the target distributions defined above, shown in <a href="#tbl-ks-test" class="quarto-xref">Table&nbsp;2</a> and <span class="citation" data-cites="fig">(<a href="#ref-fig" role="doc-biblioref"><strong>fig?</strong></a>)</span>–targets.</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-execution_count="50">
<div id="tbl-ks-test" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="50">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ks-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Kolmogorov-Smirnov test comparing the empirical test distribution (Piazza San Marco) against three soundscape target distributions.
</figcaption>
<div aria-describedby="tbl-ks-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="50">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 15%">
<col style="width: 9%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Target</th>
<th>D</th>
<th><pre><code>      p</code></pre></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>tgt_1</td>
<td>0.66</td>
<td>6.94745e-25</td>
</tr>
<tr class="even">
<td>tgt_2</td>
<td>0.83</td>
<td>8.96388e-39</td>
</tr>
<tr class="odd">
<td>tgt_3</td>
<td>0.28</td>
<td>8.96388e-39</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</div>
</section>
<section id="calculate-the-spi-score" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="calculate-the-spi-score"><span class="header-section-number">3.5</span> Calculate the SPI score</h2>
<p>The final step is to convert <span class="math inline">D_{BKS}</span> into a more interpretable form to use as a comparison across soundscapes. Since the KS distance is a measure of dissimilarity, we first subtract it from one to give a measure of similarity between the test distribution and the target distribution. This is then scaled to produce a score which ranges from 0 to 100, giving the final SPI formula:</p>
<p><span class="math display">
\text{SPI} = 100 * (1 - D_{BKS}\{\text{MSN}_{test}, \text{MSN}_{tgt}\})
</span></p>
<p>To show the usefulness of the test-target paradigm, we calculated the SPIs for each of the three target distributions for all the locations included in the ISD, as shown in <a href="#tbl-ex-spis" class="quarto-xref">Table&nbsp;3</a>. Since each location is now assigned an SPI, this makes it possible to effectively produce three separate rankings of soundscape quality for these locations, depending on which target is considered the goal.</p>
<div class="quarto-embed-nb-cell">
<div class="cell" data-execution_count="54">
<div id="tbl-ex-spis" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="54">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ex-spis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: SPI scores and rankings for the soundscapes of locations included in the International Soundscape Database (ISD).
</figcaption>
<div aria-describedby="tbl-ex-spis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="54">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">Ranking</th>
<th style="text-align: left;"><span class="math inline">SPI_1</span> (pleasant)</th>
<th style="text-align: left;"><span class="math inline">SPI_2</span> (calm)</th>
<th style="text-align: left;"><span class="math inline">SPI_3</span> (vibrant)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: left;">70 RegentsParkFields</td>
<td style="text-align: left;">61 CampoPrincipe</td>
<td style="text-align: left;">71 SanMarco</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: left;">69 CarloV</td>
<td style="text-align: left;">52 CarloV</td>
<td style="text-align: left;">62 TateModern</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: left;">65 RegentsParkJapan</td>
<td style="text-align: left;">50 PlazaBibRambla</td>
<td style="text-align: left;">60 StPaulsCross</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: left;">62 CampoPrincipe</td>
<td style="text-align: left;">49 RegentsParkFields</td>
<td style="text-align: left;">58 Noorderplantsoen</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: left;">61 PlazaBibRambla</td>
<td style="text-align: left;">45 MarchmontGarden</td>
<td style="text-align: left;">55 PancrasLock</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: left;">61 RussellSq</td>
<td style="text-align: left;">44 MonumentoGaribaldi</td>
<td style="text-align: left;">54 TorringtonSq</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: left;">61 MarchmontGarden</td>
<td style="text-align: left;">40 RussellSq</td>
<td style="text-align: left;">48 StPaulsRow</td>
</tr>
<tr class="even">
<td style="text-align: right;">8</td>
<td style="text-align: left;">61 MonumentoGaribaldi</td>
<td style="text-align: left;">38 RegentsParkJapan</td>
<td style="text-align: left;">48 RussellSq</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9</td>
<td style="text-align: left;">59 PancrasLock</td>
<td style="text-align: left;">38 PancrasLock</td>
<td style="text-align: left;">47 MiradorSanNicolas</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: left;">53 StPaulsCross</td>
<td style="text-align: left;">32 MiradorSanNicolas</td>
<td style="text-align: left;">43 CamdenTown</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11</td>
<td style="text-align: left;">49 TateModern</td>
<td style="text-align: left;">30 TateModern</td>
<td style="text-align: left;">40 CarloV</td>
</tr>
<tr class="even">
<td style="text-align: right;">12</td>
<td style="text-align: left;">48 StPaulsRow</td>
<td style="text-align: left;">30 StPaulsCross</td>
<td style="text-align: left;">36 MonumentoGaribaldi</td>
</tr>
<tr class="odd">
<td style="text-align: right;">13</td>
<td style="text-align: left;">43 MiradorSanNicolas</td>
<td style="text-align: left;">28 TorringtonSq</td>
<td style="text-align: left;">34 MarchmontGarden</td>
</tr>
<tr class="even">
<td style="text-align: right;">14</td>
<td style="text-align: left;">38 Noorderplantsoen</td>
<td style="text-align: left;">28 StPaulsRow</td>
<td style="text-align: left;">33 PlazaBibRambla</td>
</tr>
<tr class="odd">
<td style="text-align: right;">15</td>
<td style="text-align: left;">35 TorringtonSq</td>
<td style="text-align: left;">17 SanMarco</td>
<td style="text-align: left;">33 CampoPrincipe</td>
</tr>
<tr class="even">
<td style="text-align: right;">16</td>
<td style="text-align: left;">33 SanMarco</td>
<td style="text-align: left;">16 Noorderplantsoen</td>
<td style="text-align: left;">32 EustonTap</td>
</tr>
<tr class="odd">
<td style="text-align: right;">17</td>
<td style="text-align: left;">21 CamdenTown</td>
<td style="text-align: left;">15 CamdenTown</td>
<td style="text-align: left;">27 RegentsParkFields</td>
</tr>
<tr class="even">
<td style="text-align: right;">18</td>
<td style="text-align: left;">15 EustonTap</td>
<td style="text-align: left;">13 EustonTap</td>
<td style="text-align: left;">27 RegentsParkJapan</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="expanding-the-spi-framework" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Expanding the SPI framework</h1>
<p><a href="#sec-method" class="quarto-xref">Section&nbsp;3</a> has defined and demonstrated the foundational methodology for calculating an SPI score. This included how to: define and sample a target distribution; prepare the test and target distributions for comparison using the KS distance metric; and convert this into an SPI score. To expand this methodology into an applicable framework, we define two distinct types of targets: bespoke targets and reference targets, each serving a unique purpose in the index development process.</p>
<section id="bespoke-targets" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="bespoke-targets"><span class="header-section-number">4.1</span> Bespoke Targets</h2>
<p>Bespoke targets are essentially a direct application of the foundational method described above. Bespoke targets are tailor-made for specific projects, reflecting the desired soundscape perception for a particular application. These targets can be defined by stakeholders, designers, policymakers, or decision-makers based on their unique requirements, objectives, and constraints. This flexibility allows the SPI for a specific project to be tailored to the desire of the stakeholders for how that specific soundscape should function. It can also provide a consistent and quantifiable baseline for scenarios like a soundscape design contest wherein a target is specified and provided to all participants in the contest and the winning proposal is the design with the highest SPI score when assessed against that target. Stakeholders could use various methods to decide on a target, subject to the requirements of their project or use case. For example, it could be co-created with other stakeholders or space users, based on trying to match the soundscape of a previous project, or entirely arbitrary.</p>
</section>
<section id="reference-targets" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="reference-targets"><span class="header-section-number">4.2</span> Reference Targets</h2>
<p>In contrast to bespoke targets, reference targets represent generalized, widely recognized soundscape archetypes which transcend specific applications or projects. These archetypes serve as reference points and enable comparisons across different domains and use cases. Essentially a reference target is a target that has been <em>empirically defined</em> to encapsulate the ideal of a particular type of soundscape (e.g.&nbsp;for a park, for an urban square, for a particular group of users, etc.).</p>
<section id="sec-targets" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-targets"><span class="header-section-number">4.2.1</span> Deriving a target based on a priori rankings</h3>
<p>Absent from the above methodology has been an exploration of how to actually arrive at a target based on empirical evidence; i.e., not a target specified <em>ad hoc</em>, but rather an “absolute” target, based on type of space, use case, or similar. While arbitrary targets make the SPI framework incredibly flexible, able to score against an effectively infinite set of design goals, often targets should have some sort of systematic foundation, especially when defining a Reference Target. To enable this approach, we therefore present one method of systematically deriving a target distribution based on a given ranking of soundscape quality. Just as one primary goal of the SPI framework is to enable soundscape rankings to be produced from SPI scores, this method allows for rankings which were arrived at separately to produce an optimised SPI target.</p>
<p>The core challenge in developing a reference SPI target is determining what constitutes an “ideal” soundscape perception distribution for a given context. While we can directly specify MSN parameters to create bespoke targets based on theoretical expectations or design goals, developing empirically-grounded reference targets requires a more systematic approach.</p>
<p>To enable this approach, we therefore present one method of systematically deriving a target distribution based on a given ranking of soundscape quality. The <em>a priori</em> ranking serves as a bridge between existing knowledge about soundscape quality and the mathematical framework of the SPI. By starting with a ranking of soundscapes whose relative quality has been assessed through some external measure, we can use optimization techniques to derive MSN parameters that:</p>
<ol type="1">
<li>When used as an SPI target, produce scores that result in the same ranking order</li>
<li>Generate high SPI scores for the highly-ranked soundscapes</li>
<li>Define a distribution in the circumplex space that captures the perceptual characteristics common to high-quality soundscapes in this context.</li>
</ol>
<p>This approach allows us to work backwards from known good (and poor) examples to define what the target distribution should look like. For instance, if we know that location A has a better soundscape than location B for our purposes, the optimal target distribution should result in location A receiving a higher SPI score than location B.</p>
<p>In this case study, we will examine a possible ranking from the ISD park locations produced by the authors (shown in <a href="#tbl-isd-ranking" class="quarto-xref">Table&nbsp;4</a>).</p>
<div id="tbl-isd-ranking" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-isd-ranking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: A pre-defined ranking of soundscape quality of the park locations included in the International Soundscape Database (ISD). An SPI target will be derived which aims to reproduce this same ranking when applied to circumplex data from these locations.
</figcaption>
<div aria-describedby="tbl-isd-ranking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Rank</th>
<th style="text-align: center;">Location</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">RegentsParkJapan</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">RegentsParkFields</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">CampoPrincipe</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">MonumentoGaribaldi</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">RussellSq</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">MiradorSanNicolas</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">StPaulsCross</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">Noorderplantsoen</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Effectively, this is an optimisation task to determine the MSN parameters which best achieve the above goals. Parameter optimisation refers to the process of adjusting the parameters of a system, model, or algorithm to achieve the best possible performance according to one or more objectives. To set up the optimisation task, we first need to express the parameter space and any constraints. Since our goal is to identify an optimised soundscape target distribution, the parameters we will search over are:</p>
<ul>
<li><span class="math inline">\xi = (\xi_x, \xi_y)</span>, <span class="math inline">-1 \leq \xi \leq 1</span></li>
<li><span class="math inline">\Omega = \begin{pmatrix} var(x) &amp; cov(x, y) \\ cov(y, x) &amp; var(y) \end{pmatrix}</span>
<ul>
<li><span class="math inline">0 \leq var() \leq 1</span></li>
<li><span class="math inline">-1 \leq cov() \leq 1</span></li>
<li><span class="math inline">\Omega</span> must be symmetric and positive definite</li>
</ul></li>
<li><span class="math inline">\alpha = (\alpha_x, \alpha_y)</span>, <span class="math inline">-5 \leq \alpha \leq 5</span></li>
</ul>
<p>We then define the objective functions based on the two goals given above. For each step in the algorithm with a given trial set of parameters, a target distribution will be produced, the SPI for each test location assessed according to the protocol described in <a href="#sec-method" class="quarto-xref">Section&nbsp;3</a>, and the resulting set of SPI scores and ranking will be scored using the objective functions. Goal (1) is assessed by calculating the Spearman rank correlation between the <em>a priori</em> ranking and the SPI ranking:</p>
<p><span class="math display">
f_1 = r_{s}(R(\text{prior}), R(\text{target}))
</span></p>
<p>Goal (2) is scored by calculating a weighted sum of the produced SPIs. To prioritise a target which provides high SPI scores for highly ranked soundscapes, we weight according to the ranking position:</p>
<p><span class="math display">
f_2 = \sum_{i=1}^m \frac{1}{\text{rank}_i} \cdot SPI_i
</span></p>
<p>where <span class="math inline">m</span> is the number of included locations, <span class="math inline">SPI_i</span> is the calculated SPI score for the <span class="math inline">i</span>-th location assessed against a trial target, and <span class="math inline">\text{rank}_i</span> is the calculated rank value of the <span class="math inline">i</span>-th location.</p>
<p>Through our testing, optimising only on the rank correlation regularly produced targets which, while they did result in the desired ranking, were in no way representative of the soundscapes in question. We therefore aim to optimise for both a consistent soundscape ranking and for a high SPI score for the top-ranked soundscapes. Optimising these parameters with respect to multiple objectives ensures a more holistic approach to system improvement, acknowledging the trade-offs and interactions between different goals.</p>
<p>We apply the nondominated sorting genetic algorithm (NSGA-II) <span class="citation" data-cites="Deb2002fast">(<a href="#ref-Deb2002fast" role="doc-biblioref">Deb et al. 2002</a>)</span> to optimise our target distribution parameters. NSGA-II is a popular and efficient multi-objective evolutionary algorithm that is well-suited for problems with multiple, potentially conflicting objectives.</p>
<p>The algorithm works as follows<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<ol type="1">
<li>Initialize a population of candidate solutions, each representing a set of target distribution parameters <span class="math inline">(\xi, \Omega, \alpha)</span>.</li>
<li>Evaluate each candidate solution using the two objective functions defined above.</li>
<li>Perform non-dominated sorting to rank the solutions based on Pareto dominance.</li>
<li>Calculate crowding distance for each solution to maintain diversity in the population.</li>
<li>Select parent solutions using tournament selection based on non-domination rank and crowding distance.</li>
<li>Create offspring solutions using crossover and mutation operators, ensuring that the constraints on the parameters are maintained.</li>
<li>Combine parent and offspring populations and select the best solutions to form the next generation.</li>
<li>Repeat steps 2-7 for a specified number of generations or until a termination criterion is met.</li>
</ol>
<p>The NSGA-II algorithm is implemented using the Python library <code>pymoo v0.6.1.3</code> <span class="citation" data-cites="pymoo">(<a href="#ref-pymoo" role="doc-biblioref">Blank and Deb 2020</a>)</span>. The population size is set to 150, and the algorithm runs for 100 generations. In <code>pymoo</code>, each objective function is supposed to be minimised, so when implementing the algorithm and in the results, <span class="math inline">-f_1</span> and <span class="math inline">-f_2</span> are used. After running the NSGA-II algorithm, we obtain a set of non-dominated solutions representing the Pareto front, shown in <a href="#fig-pymoo-parks" class="quarto-xref">Figure&nbsp;3</a> (a). Each solution on the Pareto front represents a trade-off between the two objectives: maximising the rank correlation (<span class="math inline">f_1</span>) and maximising the weighted sum of SPI scores (<span class="math inline">f_2</span>). The Pareto front allows us to visualise and analyse the range of possible solutions, from those that prioritise ranking consistency to those that emphasise high-SPI scores for top-ranked soundscapes.</p>
<div class="quarto-embed-nb-cell">
<div id="fig-pymoo-parks" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pymoo-parks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-pymoo-parks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-pymoo-parks-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-pymoo-parks-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/notebooks-TargetOptimization-fig-pymoo-parks-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-pymoo-parks">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-pymoo-parks-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Multi-objective optimization Pareto front. The selected solution is indicated in red.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-pymoo-parks" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-pymoo-parks-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-pymoo-parks-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/notebooks-TargetOptimization-fig-pymoo-parks-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-pymoo-parks">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-pymoo-parks-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) SCM distribution of the derived target distribution.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pymoo-parks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: NSGA-II optimization to learn the MSN parameters which produce the Park ranking.
</figcaption>
</figure>
</div>
<a class="quarto-notebook-link" id="nblink-2" href="notebooks/TargetOptimization-preview.html#cell-fig-pymoo-parks">Source: Supplementary Material for: Soundscape Perception Indices (SPI) </a></div>
<p>For this demonstration, we opt for the second method, selecting the solution closest to the ideal point in the normalised objective space. This approach provides a balance between ranking consistency and high SPI scores for top-ranked soundscapes. Once the optimal solution is selected, we can sample from the MSN distribution and plot the derived target distribution, shown in <a href="#fig-pymoo-parks" class="quarto-xref">Figure&nbsp;3</a>.</p>
<p><span class="math display">
\textup{tgt}_{\textup{park}} \sim  \left\{\begin{matrix}
    \xi&amp;=&amp;[0.694, 0.406] \\
    \Omega&amp;=&amp;\begin{bmatrix}
        0.157 &amp; 0.040 \\
        0.040 &amp; 0.255
    \end{bmatrix} \\
    \alpha&amp;=&amp;[5.054, -37.671]
\end{matrix}\right.
</span></p>
<p>The resulting <span class="math inline">\text{tgt}_{\text{park}}</span>, with the MSN parameters given above, exhibits some expected characteristics: it is almost entirely pleasant, with a long uneventful tail into the calm quadrant, but somewhat unexpectedly the mode is slightly vibrant. What should be made clear about this demonstration is that we are not presenting this as a reference target to be used in the future - this section is meant as a demonstration of a method which can be used to derive a target from an <em>a priori</em> ranking. In this case, the <em>a priori</em> ranking was created by the authors from their experience of the locations in the ISD. To truly be called an empirical reference target, the ranking would need to be arrived at empirically, via some other metric (e.g.&nbsp;health or productivity ratings of the areas) or through an experiment such as paired-choice comparisons.</p>
<p>It is these reference targets with an empirical backing which would ideally form agreed upon standards and benchmarks in the field against which new soundscapes would be compared. The best methods for empirically determining the ideal soundscape distribution for a given context will no doubt remain a topic of debate and development in the coming years.</p>
</section>
</section>
</section>
<section id="sec-discussion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Discussion</h1>
<p>The development of Bespoke and Reference context-dependent SPIs represents a significant step towards enabling more comprehensive and effective applications of the soundscape approach. By providing a unified framework for defining these indices, the potential for quantifying and comparing soundscape quality across diverse contexts and applications is unlocked, while still ensuring that the multi-dimensional and context-driven aspects of soundscape quality are considered.</p>
<section id="applications-of-the-spi-framework" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="applications-of-the-spi-framework"><span class="header-section-number">5.1</span> Applications of the SPI framework</h2>
<p>The proposed framework offers several key advantages. First, it acknowledges the inherent context-dependent nature of soundscape perception, allowing for the creation of indices tailored to specific use cases or design goals through the use of bespoke targets. This flexibility ensures that the resulting SPIs accurately capture the desired soundscape perception for the given application, enabling targeted interventions and optimisations.</p>
<p>Second, the inclusion of reference targets facilitates cross-comparisons and benchmarking, enabling a common language and understanding of soundscape quality across different domains. By calculating the distance between a given soundscape and these widely recognized references, stakeholders can identify areas for improvement and prioritize interventions accordingly, aligning their efforts with collectively recognized standards of desirable or undesirable soundscapes.</p>
<p>We expect that this would then expand into collections of SPI targets. As an example, imagine trying to define a soundscape perception index that could be applied across an entire city. A single index is insufficient, because each type of place within the city (e.g.&nbsp;parks, plazas, residential areas) has different requirements for its soundscape. Therefore, each place type would need its own soundscape target.</p>
<p>In this example, these sets of targets would correspond to different types of places within the city (e.g.&nbsp;a single target for parks, a target for plazas etc.). When applying this “urban typology” set of targets, the soundscape of each location being assessed would be scored against its relevant target (i.e how well does a specific park perform in comparison to a reference park target). This results in a single score for each location that can be compared against all other locations, regardless of whether or not they are the same type of place, allowing for different soundscapes to be compared on a common scale. This system ensures that context (in this case, the typology of a space) is brought into the assessment, allowing soundscapes to be scored against the most appropriate target. Enabling these context dependent assessments to be expressed on a common scale can facilitate additional use cases such as soundscape mapping, which requires a single scale to be applied across an entire city.</p>
<p>This set of targets made up of e.g.&nbsp;parks, plazas etc. is just one example of an application of reference SPIs. Other examples could include a demographics SPI, where different targets are set for respondents from different demographic groups, or a “use case” SPI with different targets set for different intended purposes of spaces (e.g.&nbsp;recreation, restoration, socialising). We encourage users of the SPI to define both their own single reference targets that can be added these suites of targets for use by others, and their own new sets of reference.</p>
<p><span class="citation" data-cites="Kogan2018Green">(<a href="#ref-Kogan2018Green" role="doc-biblioref">Kogan et al. 2018, fig. 6</a>)</span>, in fact displays a startlingly similar concept, showing the locations of the three categories of traffic noise dominance (‘traffic noise’, ‘balanced’, and ‘natural’) plotted in the circumplex perceptual model. It can be clearly seen in this plot that the GSI categories create their own clusters within the circumplex.</p>
<p>Although it is expected that the target distribution would usually represent the ideal or goal soundscape perception, it is also possible to define target distributions that represent undesirable or suboptimal soundscape perceptions. For instance, in a soundscape mapping context, it may be beneficial to map and identify chaotic soundscapes across a city in order to better target areas for soundscape interventions. In this case, the target distribution would be set in the chaotic quadrant and a higher SPI would indicate a closer alignment with the target distribution. This flexibility allows the SPI to be applied to a wide range of contexts and applications, enabling the quantification and comparison of soundscape quality across diverse scenarios.</p>
</section>
<section id="connecting-with-soundscape-data" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="connecting-with-soundscape-data"><span class="header-section-number">5.2</span> Connecting with soundscape data</h2>
<p>Unlike previous soundscape indices (see <a href="#sec-existing-soundscape-indices" class="quarto-xref">Section&nbsp;2.1</a>), SPI does not include any direct connection to soundscape indicators such as the sound level, spectral content, etc. Its basis in perceptual descriptor data effective allows the analysis and quantification of soundscape information to be modularised, separating the task of calculating a single index from the complex task of predicting soundscape perception from objective data. The modularisation of soundscape data analysis allows the entire pipeline from environmental data collection through to soundscape index scoring to remain flexible. Following the soundscape engineering paradigm laid out in <span class="citation" data-cites="Mitchell2023conceptual">Mitchell et al. (<a href="#ref-Mitchell2023conceptual" role="doc-biblioref">2023</a>)</span>, the connection between soundscape indicators, through descriptors, to indices can be made by predictive soundscape models. These models are trained on increasingly large scale datasets and generally designed to predict soundscape descriptors, including the SCM attributes <span class="citation" data-cites="Ooi2022Probably">Hou et al. (<a href="#ref-Hou2024Soundscape" role="doc-biblioref">2024</a>)</span>. With the complex and multidimensional nature of soundscape perception and with the rapid progression in machine learning techniques and applications, an index framework should be able to integrate new and improved models. By separating the prediction of perceptual descriptors based on objective metrics from the calculation of the single value index itself, the SPI framework allows for these predictive models and for the creation of new indices to advance independently.</p>
</section>
<section id="comparison-with-existing-soundscape-indices" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="comparison-with-existing-soundscape-indices"><span class="header-section-number">5.3</span> Comparison with existing soundscape indices</h2>
<p>The SPI framework represents a unique approach to soundscape assessment, building upon and differentiating itself from previous indices in several key ways. Firstly, the SPI framework is fundamentally perception-focused. By referring to the “Soundscape Perception Index”, we aim to highlight the unique and perception-focussed nature of this index framework. The SPI core method operates entirely within the perception data space, with no direct reference to acoustic or other indicators. Perceptual data (or predicted perceptual data) are the only operant factors of the SPI method. The aim of SPI is to combine multidimensional perception data and context (including design goals) into a single metric.</p>
<p>The SPI framework shares this important characteristic with indices like the Soundscape Diversity Index (SDI) <span class="citation" data-cites="Liu2014Effects">(<a href="#ref-Liu2014Effects" role="doc-biblioref">Liu et al. 2014</a>)</span> and the Harmonious Degree of Sound Sources (SHD) <span class="citation" data-cites="Guo2023Harmonious">(<a href="#ref-Guo2023Harmonious" role="doc-biblioref">Guo et al. 2023</a>)</span> in that they all prioritize perception as the primary input for assessment. Both SDI and SHD, however, focus on the perception of sound sources that can be observed in an acoustic environment, and their relationships. While these indices offer valuable insights into specific aspects of soundscape perception, they are somewhat limited in their scope and adaptability. The SPI framework builds upon these efforts by incorporating the full dimensionality of the soundscape circumplex model and allowing for context-sensitive assessments through bespoke and reference targets. This approach enables the SPI to address a wider range of soundscape evaluation needs while maintaining the crucial focus on perceptual data that distinguishes these methods from purely acoustic measurements.</p>
<p>Furthermore, the SPI framework is designed to be generalisable, extensible, and adaptable. Unlike previous indices that often represent a single target in a particular context, the SPI framework allows for scoring soundscapes against any goal defined by the user. This flexibility makes it applicable across a wide range of contexts and design objectives, from urban planning and acoustic design to research and policy development.</p>
</section>
<section id="limitations" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="limitations"><span class="header-section-number">5.4</span> Considerations and future work</h2>
<p>Several considerations should be noted when defining an SPI target. First, the target distribution should be representative of the desired soundscape perception for the given application. This requires a clear understanding of the context, objectives, and constraints of the project, as well as the preferences and expectations of stakeholders and end-users. Second, the temporal and spatial scales of the target distribution should align with the soundscape assessment being conducted. What constitutes the actual spatial bounds of ‘a soundscape’, or indeed of ‘a place’, is a complex question which will depend on the context of the assessment. For example, a park soundscape may be defined by the boundaries of the park itself, or it may extend to include the surrounding urban environment or be restricted to a certain distance from a feature of interest in the park<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The temporal scale of the assessment is also important, as soundscape quality can vary throughout the day and across different seasons. Increasing the spatial bounds of what is considered the soundscape under examination (e.g.&nbsp;a single position vs a 25<span class="math inline">m^2</span> area vs an entire park) or extending the temporal scale will almost certainly result in a distribution with a larger variance. What scales are appropriate for a given assessment will depend on the context and objectives of the project, but they should be considered when defining the target distribution. Applying a target distribution that is too broad or too narrow for the context of the assessment may result in inaccurate or misleading SPI scores. As the circumplex distribution first described in <span class="citation" data-cites="Mitchell2022How">Mitchell, Aletta, and Kang (<a href="#ref-Mitchell2022How" role="doc-biblioref">2022</a>)</span> and further formalised here develops, we are hopeful that a better understanding of the relationship between temporal and spatial scales and the parameters of the distribution will emerge and will contribute to an increased understanding of what constitutes `the soundscape of a place’ and how this should be reflected in its ideal perception distribution.</p>
<p>Various other distance metrics were considered when developing the SPI method. The simplest method is to define a single point target, rather than a target distribution, and calculate a normalized mean Euclidean distance between points in the test distribution and the target point. While this is conceptually simple and requires defining only a single coordinate point as a target, rather than the MSN parameters described in <a href="#sec-circumplex-distribution" class="quarto-xref">Section&nbsp;3.2</a>, the shape and spread of a soundscape distribution is itself an important factor in describing the collective perception of a soundscape and would not be captured by this method <span class="citation" data-cites="Mitchell2022How">(<a href="#ref-Mitchell2022How" role="doc-biblioref">Mitchell, Aletta, and Kang 2022</a>)</span>.</p>
<p>An additional method which was considered, was to consider a target as an ellipse (or, indeed any other shape) drawn in the circumplex space (similar to the simplified median decile curves proposed in <span class="citation" data-cites="Mitchell2022How">Mitchell, Aletta, and Kang (<a href="#ref-Mitchell2022How" role="doc-biblioref">2022</a>)</span>). An SPI score would then be calculated based on the percentage of responses which fall within the space defined by the ellipse. Again, this is conceptually quite simple and defining the ellipse targets is straightforward. However, this method has an important flaw - it is easy to artificially inflate or deflate the scores merely by changing the area of the ellipse. The larger the ellipse, the higher all SPI scores will be, regardless of whether the sample distribution is wide or narrow. This would also limit cross-comparability between targets. As can be seen in <a href="#tbl-ex-spis" class="quarto-xref">Table&nbsp;3</a>, defining a target distribution with a larger spread (i.e.&nbsp;<span class="math inline">\text{tgt}_1</span>) does not automatically result in higher SPI scores across the board as it would with the ellipse target method. By defining the SPI as a true target-test distribution comparison we ensure that the SPI always accurately reflects the similarity between the perception of a soundscape and its target, both in terms of its location in the circumplex and the shape of the data.</p>
<p>As noted in <a href="#sec-targets" class="quarto-xref">Section&nbsp;4.2.1</a>, although a methodology for deriving targets is presented, the <em>a priori</em> ranking we use for the demonstration was not itself arrived at empirically. Hence the park target cannot be considered a true reference target. A key piece of future work is to use experimental methods such as paired-choice comparisons to arrive at a well-defined ranking which can then produce a true reference target.</p>
</section>
</section>
<section id="conclusion" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Conclusion</h1>
<p>The ERC-funded Soundscape Indices (SSID) project was started mostly with the ambition to derive soundscape indices that could serve as numerical/quantifiable tools <span class="citation" data-cites="Kang2019Towards">(<a href="#ref-Kang2019Towards" role="doc-biblioref">Kang et al. 2019</a>)</span>, to better inform urban sound planning and design decisions. Any soundscape researcher having ever made an attempt at defining “the” soundscape quality index will know what a challenging, even impossible, task this is. Some may even argue that trying to reduce soundscape quality to a single-value quantity, and deriving any soundscape index, could be what philosophers would call a <em>contradictio in adjecto</em>, as the soundscape approach intrinsically advocates for a multi-dimensional characterization of the acoustic environments that we experience in our lives. For these reasons, we felt that it was necessary to take a step back and create instead a framework tailored for the field specifically that could easily be adapted to different contexts and capture the multi-faceted aspects of the soundscape of a place.</p>
<p>The proposed framework addresses the existing gap in quantifying multi-dimensional soundscape perception, facilitating a broader application of the soundscape approach in areas such as urban planning, environmental management, acoustic design, and policy development. Through the creation of bespoke indices tailored to specific design goals and the utilization of reference targets for benchmarking, this framework empowers stakeholders and decision-makers to make informed choices and prioritize soundscape improvements aligned with their unique objectives and constraints.</p>
<p>Furthermore, the grounding of the SPI framework in the soundscape circumplex model ensures a robust theoretical foundation, capturing the multi-dimensional nature of soundscape perception. The use of a distance metric enables quantitative assessments and comparisons, fostering a common language and understanding of soundscape quality across different domains. This shared understanding facilitates knowledge exchange, collaborative efforts, and the development of best practices within the field. As the SPI framework continues to be explored and refined, future research should focus on validating and expanding the range of reference targets, as well as investigating the potential for incorporating additional dimensions and factors that influence soundscape perception. The integration of emerging technologies (such as virtual, mixed, and augmented reality) may also provide new avenues for immersive soundscape evaluation and index development. Additionally, the application of the framework in diverse real-world scenarios, ranging from urban planning and environmental management to acoustic design and policy development, will provide valuable insights and contribute to the ongoing refinement and adaptation of the SPI framework.</p>
<p>In many ways, the proposed SPI framework is not so conceptually different from the whole idea of decibel-based set of indicators that the Soundscape Indices (SSID) project itself is trying to “overcome”. There is no such thing as a single noise indicator (<em>L</em>) to univocally describe sound levels in all circumstances; rather, different noise indicators are defined for different scenarios and temporal or spectral requirements (e.g., <span class="math inline">L_{den}</span>, <span class="math inline">L_{Aeq, T}</span>, etc.), based on testing needs. The decibel (dB) is the unit for all of them, but A-weighted equivalent sound levels for a one-hour interval cannot be directly compared with whole-day indicators with penalties. We are trying to achieve the same with the SPI to provide a way of defining different indices for different contexts, while maintaining a consistent framework.</p>
<p>Ultimately, for the SPI approach to succeed, collaboration with stakeholders, end-users, and experts from various domains will be crucial in ensuring the framework’s relevance and applicability across a wide range of contexts.</p>
</section>
<section id="acknowledgements" class="level1 unnumbered">
<h1 class="unnumbered">Acknowledgements</h1>
<p>This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (Grant No.&nbsp;740696, project title Soundscape Indices - SSID). More information and related publications can be found at the CORDIS webpage of the project<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</section>
<section id="data-and-code-availability" class="level1 unnumbered">
<h1 class="unnumbered">Data and Code Availability</h1>
<p>The data used in this paper are drawn from the publicly available International Soundscape Database (ISD v1.0.1-alpha.1) <span class="citation" data-cites="Mitchell2024International">Mitchell et al. (<a href="#ref-Mitchell2024International" role="doc-biblioref">2024</a>)</span> available on Zenodo<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. The code to recreate the figures in this paper can be found on this paper’s Github page<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
</section>
<section id="author-contributions" class="level1 unnumbered">
<h1 class="unnumbered">Author contributions</h1>
<p><strong>AM</strong>: Conceptualization, Methodology, Software, Writing-Original Draft, Writing-Review &amp; Editing, Visualization. <strong>FA</strong>: Conceptualization, Methodology, Writing-Review &amp; Editing. <strong>TO</strong>: Conceptualization, Writing-Review &amp; Editing. <strong>JK</strong>: Conceptualization, Supervision, Funding acquisition.</p>
</section>
<section id="references" class="level1" data-number="7">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">7 References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Aletta2015Soundscape" class="csl-entry" role="listitem">
Aletta, Francesco, and Jian Kang. 2015. <span>“<span class="nocase">Soundscape approach integrating noise mapping techniques: a case study in Brighton, UK</span>.”</span> <em>Noise Mapping</em> 2 (1): 1–12. <a href="https://doi.org/10.1515/noise-2015-0001">https://doi.org/10.1515/noise-2015-0001</a>.
</div>
<div id="ref-Aletta2016Soundscape" class="csl-entry" role="listitem">
Aletta, Francesco, Jian Kang, and Östen Axelsson. 2016. <span>“<span class="nocase">Soundscape descriptors and a conceptual framework for developing predictive soundscape models</span>.”</span> <em>Landscape and Urban Planning</em> 149 (July): 65–74. <a href="https://doi.org/10.1016/j.landurbplan.2016.02.001">https://doi.org/10.1016/j.landurbplan.2016.02.001</a>.
</div>
<div id="ref-Aletta2024Soundscape" class="csl-entry" role="listitem">
Aletta, Francesco, Andrew Mitchell, Tin Oberman, Jian Kang, Sara Khelil, Tallal Abdel Karim Bouzir, Djihed Berkouk, et al. 2024. <span>“Soundscape Descriptors in Eighteen Languages: Translation and Validation Through Listening Experiments.”</span> <em>Applied Acoustics</em>. https://doi.org/<a href="https://doi.org/10.1016/j.apacoust.2024.110109">https://doi.org/10.1016/j.apacoust.2024.110109</a>.
</div>
<div id="ref-Aletta2018Associations" class="csl-entry" role="listitem">
Aletta, Francesco, Tin Oberman, and Jian Kang. 2018. <span>“<span class="nocase">Associations between Positive Health-Related Effects and Soundscapes Perceptual Constructs : A Systematic Review</span>.”</span> <em>International Journal of Environmental Research and Public Health</em> 15 (October): 1–15. <a href="https://doi.org/10.3390/ijerph15112392">https://doi.org/10.3390/ijerph15112392</a>.
</div>
<div id="ref-Aletta2023Adoption" class="csl-entry" role="listitem">
Aletta, Francesco, and Simone Torresin. 2023. <span>“Adoption of <span>ISO/TS</span> 12913-2:2018 Protocols for Data Collection from Individuals in Soundscape Studies: <span>A</span>n Overview of the Literature.”</span> <em>Current Pollution Reports</em>, October. <a href="https://doi.org/10.1007/s40726-023-00283-6">https://doi.org/10.1007/s40726-023-00283-6</a>.
</div>
<div id="ref-Axelsson2015How" class="csl-entry" role="listitem">
Axelsson, Östen. 2015. <span>“How to Measure Soundscape Quality.”</span> In <em>Proceedings of Euronoise 2015 :</em>, 1477–81. Stockholm University, Perception; psychophysics; Nederlands Akoestisch Genootschap; ABAV - Belgian Acoustical Society.
</div>
<div id="ref-Axelsson2010principal" class="csl-entry" role="listitem">
Axelsson, Östen, Mats E. Nilsson, and Birgitta Berglund. 2010. <span>“<span class="nocase">A principal components model of soundscape perception</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 128 (5): 2836–46. <a href="https://doi.org/10.1121/1.3493436">https://doi.org/10.1121/1.3493436</a>.
</div>
<div id="ref-Axelsson2012Swedish" class="csl-entry" role="listitem">
Axelsson, Östen, Mats E. Nilsson, and Birgitta Berglund. 2012. <span>“The <span>S</span>wedish Soundscape-Quality Protocol.”</span> In <em>The Journal of the Acoustical Society of America</em>, 131:3476–76. 4. Acoustical Society of America (<span>ASA</span>). <a href="https://doi.org/10.1121/1.4709112">https://doi.org/10.1121/1.4709112</a>.
</div>
<div id="ref-Azzalini2021R" class="csl-entry" role="listitem">
Azzalini, A. 2021. <span>“<span class="nocase">The R package sn: The Skew-Normal and Related Distributions such as the Skew-t and the SUN</span>.”</span> Università degli Studi di Padova, Italia. <a href="https://cran.r-project.org/package=sn">https://cran.r-project.org/package=sn</a>.
</div>
<div id="ref-Azzalini1999Statistical" class="csl-entry" role="listitem">
Azzalini, A., and A. Capitanio. 1999. <span>“Statistical Applications of the Multivariate Skew Normal Distribution.”</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 61 (3): 579–602. <a href="https://doi.org/10.1111/1467-9868.00194">https://doi.org/10.1111/1467-9868.00194</a>.
</div>
<div id="ref-Azzalini2005Skew" class="csl-entry" role="listitem">
Azzalini, Adelchi. 2005. <span>“The Skew-Normal Distribution and Related Multivariate Families.”</span> <em>Scandinavian Journal of Statistics</em> 32 (2): 159–88. <a href="https://doi.org/10.1111/j.1467-9469.2005.00426.x">https://doi.org/10.1111/j.1467-9469.2005.00426.x</a>.
</div>
<div id="ref-Azzalini2016How" class="csl-entry" role="listitem">
———. 2016. <span>“How to Sample from the <span>SN</span> and Related Distributions When We Want to Fix Skewness and Other Cumulants.”</span> <a href="http://azzalini.stat.unipd.it/SN/how_to_sample.pdf">http://azzalini.stat.unipd.it/SN/how_to_sample.pdf</a>.
</div>
<div id="ref-Azzalini1996Multivariate" class="csl-entry" role="listitem">
Azzalini, A., and A. Dalla Valle. 1996. <span>“The Multivariate Skew-Normal Distribution.”</span> <em>Biometrika</em> 83 (4): 715–26. <a href="http://www.jstor.org/stable/2337278">http://www.jstor.org/stable/2337278</a>.
</div>
<div id="ref-Berglund1999Guidelines" class="csl-entry" role="listitem">
Berglund, Birgitta, Thomas Lindvall, and Dietrich H. Schwela. 1999. <span>“Guidelines for Community Noise.”</span> Research report. World Health Organization; World Health Organization, Geneva.
</div>
<div id="ref-pymoo" class="csl-entry" role="listitem">
Blank, J., and K. Deb. 2020. <span>“Pymoo: Multi-Objective Optimization in Python.”</span> <em>IEEE Access</em> 8: 89497–509.
</div>
<div id="ref-Blauert1997Sound" class="csl-entry" role="listitem">
Blauert, Jens, and Ute Jekosch. 1997. <span>“Sound-Quality Evaluation a Multi-Layered Problem.”</span> <em>Acta Acustica United with Acustica</em> 83 (5): 747–53. <a href="https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00005">https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00005</a>.
</div>
<div id="ref-Cao2020Red" class="csl-entry" role="listitem">
Cao, Xinhao, Qi Meng, and Jian Kang. 2020. <span>“Red Soundscape Index (RSI): An Index with the Potential to Assess Soundscape Quality.”</span> In <em>INTER-NOISE and NOISE-CON Congress and Conference Proceedings</em>, 261:3527–39. 3. Institute of Noise Control Engineering.
</div>
<div id="ref-Chakravati1967Handbook" class="csl-entry" role="listitem">
Chakravati, Laha, and Roy. 1967. <em>Handbook of Methods of Applied Statistics</em>. Vol. 1. John Wiley; Sons.
</div>
<div id="ref-Chen2023Natural" class="csl-entry" role="listitem">
Chen, Xiaochao, and Jian Kang. 2023. <span>“Natural Sounds Can Encourage Social Interactions in Urban Parks.”</span> <em>Landscape and Urban Planning</em> 239 (November): 104870. <a href="https://doi.org/10.1016/j.landurbplan.2023.104870">https://doi.org/10.1016/j.landurbplan.2023.104870</a>.
</div>
<div id="ref-Deb2002fast" class="csl-entry" role="listitem">
Deb, Kalyanmoy, Amrit Pratap, Sameer Agarwal, and T. Meyarivan. 2002. <span>“A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II.”</span> Article. <em>IEEE Transactions on Evolutionary Computation</em> 6 (2): 182–97. <a href="https://doi.org/10.1109/4235.996017">https://doi.org/10.1109/4235.996017</a>.
</div>
<div id="ref-EuropeanUnion2002Directive" class="csl-entry" role="listitem">
European Union. 2002. <em><span class="nocase">Directive 2002/49/EC of the European Parliament and of the Council of 25 June 2002 relating to the assessment and management of environmental noise</span></em>.
</div>
<div id="ref-Fasano1987multidimensional" class="csl-entry" role="listitem">
Fasano, G., and A. Franceschini. 1987. <span>“A Multidimensional Version of the Kolmogorov–Smirnov Test.”</span> <em>Monthly Notices of the Royal Astronomical Society</em> 225 (1): 155–70. <a href="https://doi.org/10.1093/mnras/225.1.155">https://doi.org/10.1093/mnras/225.1.155</a>.
</div>
<div id="ref-Fastl2006Psychoacoustic" class="csl-entry" role="listitem">
Fastl, Hugo. 2006. <span>“Psychoacoustic Basis of Sound Quality Evaluation and Sound Engineering.”</span> In <em>The Thirteenth International Congress on Sound and Vibration</em>. Vienna.
</div>
<div id="ref-Fiebig2018Does" class="csl-entry" role="listitem">
Fiebig, André. 2018. <span>“<span class="nocase">Does it make a difference to have soundscape standards ?</span>”</span> <em>Proceedings - Euronoise 2018</em>, no. June (June): 6. <a href="https://www.euronoise2018.eu/docs/papers/482_Euronoise2018.pdf">https://www.euronoise2018.eu/docs/papers/482_Euronoise2018.pdf</a>.
</div>
<div id="ref-Fletcher1933Loudness" class="csl-entry" role="listitem">
Fletcher, Harvey, and W. A. Munson. 1933. <span>“Loudness, Its Definition, Measurement and Calculation*.”</span> <em>Bell System Technical Journal</em> 12 (4): 377–430. <a href="https://doi.org/10.1002/j.1538-7305.1933.tb00403.x">https://doi.org/10.1002/j.1538-7305.1933.tb00403.x</a>.
</div>
<div id="ref-Guo2023Harmonious" class="csl-entry" role="listitem">
Guo, Xuan, Jiang Liu, Zhu Chen, and Xin-Chen Hong. 2023. <span>“Harmonious Degree of Sound Sources Influencing Visiting Experience in Kulangsu Scenic Area, China.”</span> <em>Forests</em> 14 (1): 138. <a href="https://doi.org/10.3390/f14010138">https://doi.org/10.3390/f14010138</a>.
</div>
<div id="ref-Guski1997Psychological" class="csl-entry" role="listitem">
Guski, Rainer. 1997. <span>“Psychological Methods for Evaluating Sound Quality and Assessing Acoustic Information.”</span> <em>Acta Acustica United with Acustica</em> 83 (5): 765–74. <a href="https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00007">https://www.ingentaconnect.com/content/dav/aaua/1997/00000083/00000005/art00007</a>.
</div>
<div id="ref-Hellman1987Why" class="csl-entry" role="listitem">
Hellman, Rhona, and Eberhard Zwicker. 1987. <span>“Why Can a Decrease in dB(a) Produce an Increase in Loudness?”</span> <em>The Journal of the Acoustical Society of America</em> 82 (5): 1700–1705. <a href="https://doi.org/10.1121/1.395162">https://doi.org/10.1121/1.395162</a>.
</div>
<div id="ref-Hou2024Soundscape" class="csl-entry" role="listitem">
Hou, Yuanbo, Qiaoqiao Ren, Andrew Mitchell, Wenwu Wang, Jian Kang, Tony Belpaeme, and Dick Botteldooren. 2024. <span>“Soundscape Captioning Using Sound Affective Quality Network and Large Language Model.”</span> arXiv. <a href="https://doi.org/10.48550/ARXIV.2406.05914">https://doi.org/10.48550/ARXIV.2406.05914</a>.
</div>
<div id="ref-ISO12913Part2" class="csl-entry" role="listitem">
ISO/TS 12913-2:2018. 2018. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 2: <span>Data</span> Collection and Reporting Requirements.”</span>
</div>
<div id="ref-ISO12913Part3" class="csl-entry" role="listitem">
ISO/TS 12913-3:2019. 2019. <span>“<span>Acoustics</span> – <span>Soundscape</span> – <span>Part</span> 3: <span>Data</span> Analysis.”</span>
</div>
<div id="ref-Kang2006Urban" class="csl-entry" role="listitem">
Kang, Jian. 2006. <em>Urban <span>S</span>ound <span>E</span>nvironment</em>. <span>CRC</span> Press. <a href="https://doi.org/10.1201/9781482265613">https://doi.org/10.1201/9781482265613</a>.
</div>
<div id="ref-Kang2023Soundscape" class="csl-entry" role="listitem">
———. 2023. <span>“Soundscape in City and Built Environment: Current Developments and Design Potentials.”</span> <em>City and Built Environment</em> 1 (1): 1.
</div>
<div id="ref-Kang2018Impact" class="csl-entry" role="listitem">
Kang, Jian, and Francesco Aletta. 2018. <span>“<span class="nocase">The Impact and Outreach of Soundscape Research</span>.”</span> <em>Environments</em> 5 (5): 58. <a href="https://doi.org/10.3390/environments5050058">https://doi.org/10.3390/environments5050058</a>.
</div>
<div id="ref-Kang2019Towards" class="csl-entry" role="listitem">
Kang, Jian, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Andrew Mitchell. 2019. <span>“<span class="nocase">Towards soundscape indices</span>.”</span> In <em>Proceedings of the 23rd International Congress on Acoustics</em>, integrating 4th EAA Euroregio 2019 : 9-13 September 2019:2488–95. Aachen: RWTH Aachen University. <a href="https://doi.org/10.18154/RWTH-CONV-239249">https://doi.org/10.18154/RWTH-CONV-239249</a>.
</div>
<div id="ref-Kang2023Supportive" class="csl-entry" role="listitem">
Kang, Jian, Francesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Huan Tong, Simone Torresin, Chunyang Xu, Tingting Yang, and Xiaochao Chen. 2023. <span>“Supportive Soundscapes Are Crucial for Sustainable Environments.”</span> <em>Science of The Total Environment</em> 855 (January): 158868. <a href="https://doi.org/10.1016/j.scitotenv.2022.158868">https://doi.org/10.1016/j.scitotenv.2022.158868</a>.
</div>
<div id="ref-Kang2016Soundscape" class="csl-entry" role="listitem">
Kang, Jian, and Brigitte Schulte-Fortkamp, eds. 2016. <em>Soundscape and the <span>B</span>uilt <span>E</span>nvironment</em>. Boca Raton, FL: CRC Press.
</div>
<div id="ref-Kogan2018Green" class="csl-entry" role="listitem">
Kogan, Pablo, Jorge P. Arenas, Fernando Bermejo, María Hinalaf, and Bruno Turra. 2018. <span>“<span class="nocase">A Green Soundscape Index (GSI): The potential of assessing the perceived balance between natural sound and traffic noise</span>.”</span> <em>Science of The Total Environment</em> 642 (November): 463–72. <a href="https://doi.org/10.1016/j.scitotenv.2018.06.023">https://doi.org/10.1016/j.scitotenv.2018.06.023</a>.
</div>
<div id="ref-Kryter1994Handbook" class="csl-entry" role="listitem">
Kryter, Karl D. 1994. <em>The <span>H</span>andbook of <span>H</span>earing and the <span>E</span>ffects of <span>N</span>oise</em>. London, UK: Academic Press.
</div>
<div id="ref-Lionello2020systematic" class="csl-entry" role="listitem">
Lionello, Matteo, Francesco Aletta, and Jian Kang. 2020. <span>“<span class="nocase">A systematic review of prediction models for the experience of urban soundscapes</span>.”</span> <em>Applied Acoustics</em> 170 (June). <a href="https://doi.org/10.1016/j.apacoust.2020.107479">https://doi.org/10.1016/j.apacoust.2020.107479</a>.
</div>
<div id="ref-Liu2014Effects" class="csl-entry" role="listitem">
Liu, Jiang, Jian Kang, Holger Behm, and Tao Luo. 2014. <span>“Effects of Landscape on Soundscape Perception: Soundwalks in City Parks.”</span> <em>Landscape and Urban Planning</em> 123 (March): 30–40. <a href="https://doi.org/10.1016/j.landurbplan.2013.12.003">https://doi.org/10.1016/j.landurbplan.2013.12.003</a>.
</div>
<div id="ref-Mitchell2022Predictive" class="csl-entry" role="listitem">
Mitchell, Andrew. 2022. <span>“Predictive <span>M</span>odelling of <span>C</span>omplex <span>U</span>rban <span>S</span>oundscapes: <span>E</span>nabling an Engineering Approach to Soundscape Design.”</span> PhD Thesis, University College London. <a href="https://doi.org/10.13140/RG.2.2.15590.50245">https://doi.org/10.13140/RG.2.2.15590.50245</a>.
</div>
<div id="ref-Mitchell2022How" class="csl-entry" role="listitem">
Mitchell, Andrew, Francesco Aletta, and Jian Kang. 2022. <span>“How to Analyse and Represent Quantitative Soundscape Data.”</span> <em>JASA Express Letters</em> 2 (3): 037201. <a href="https://doi.org/10.1121/10.0009794">https://doi.org/10.1121/10.0009794</a>.
</div>
<div id="ref-Mitchell2023conceptual" class="csl-entry" role="listitem">
Mitchell, Andrew, Francesco Aletta, Tin Oberman, Mercede Erfanian, and Jian Kang. 2023. <span>“A Conceptual Framework for the Practical Use of Predictive Models and <span>S</span>oundscape <span>I</span>ndices: <span>G</span>oals, Constraints, and Applications.”</span> In <em>INTER-NOISE 2023 Conference</em>. Chiba, Greater Tokyo.
</div>
<div id="ref-Mitchell2024International" class="csl-entry" role="listitem">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, Xiang Fang, and Jian Kang. 2024. <span>“<span class="nocase">The International Soundscape Database: An integrated multimedia database of urban soundscape surveys – questionnaires with acoustical and contextual information</span>.”</span> Zenodo. <a href="https://doi.org/10.5281/zenodo.10672568">https://doi.org/10.5281/zenodo.10672568</a>.
</div>
<div id="ref-Mitchell2020Soundscape" class="csl-entry" role="listitem">
Mitchell, Andrew, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. 2020. <span>“<span class="nocase">The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information</span>.”</span> <em>Applied Sciences</em> 10 (7): 2397. <a href="https://doi.org/10.3390/app10072397">https://doi.org/10.3390/app10072397</a>.
</div>
<div id="ref-Ooi2022Probably" class="csl-entry" role="listitem">
Ooi, Kenneth, Karn N. Watcharasupat, Bhan Lam, Zhen-Ting Ong, and Woon-Seng Gan. 2022. <span>“Probably Pleasant? A Neural-Probabilistic Approach to Automatic Masker Selection for Urban Soundscape Augmentation.”</span> In <em><span>ICASSP</span> 2022 - 2022 <span>IEEE</span> International Conference on Acoustics, Speech and Signal Processing (<span>ICASSP</span>)</em>. <span>IEEE</span>. <a href="https://doi.org/10.1109/icassp43922.2022.9746897">https://doi.org/10.1109/icassp43922.2022.9746897</a>.
</div>
<div id="ref-Parmanen2007weighted" class="csl-entry" role="listitem">
Parmanen, Juhani. 2007. <span>“A-Weighted Sound Pressure Level as a Loudness/Annoyance Indicator for Environmental Sounds – Could It Be Improved?”</span> <em>Applied Acoustics</em> 68 (1): 58–70. <a href="https://doi.org/10.1016/j.apacoust.2006.02.004">https://doi.org/10.1016/j.apacoust.2006.02.004</a>.
</div>
<div id="ref-RCT2018R" class="csl-entry" role="listitem">
R Core Team. 2018. <em><span>R</span>: <span>A</span> <span>L</span>anguage and <span>E</span>nvironment for <span>S</span>tatistical <span>C</span>omputing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-Russell1980circumplex" class="csl-entry" role="listitem">
Russell, James A. 1980. <span>“A Circumplex Model of Affect.”</span> <em>Journal of Personality and Social Psychology</em> 39 (6): 1161. <a href="https://doi.org/10.1037/h0077714">https://doi.org/10.1037/h0077714</a>.
</div>
<div id="ref-SchulteFortkamp2023Soundscapes" class="csl-entry" role="listitem">
Schulte-Fortkamp, Brigitte, André Fiebig, Joseph A. Sisneros, Arthur N. Popper, and Richard R. Fay, eds. 2023. <em>Soundscapes: <span>H</span>umans and <span>T</span>heir <span>A</span>coustic <span>E</span>nvironment</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-031-22779-0">https://doi.org/10.1007/978-3-031-22779-0</a>.
</div>
<div id="ref-SchulteFortkamp2013Introduction" class="csl-entry" role="listitem">
Schulte-Fortkamp, Brigitte, and Jian Kang. 2013. <span>“<span class="nocase">Introduction to the special issue on soundscapes</span>.”</span> <em>The Journal of the Acoustical Society of America</em> 134 (1): 765–66. <a href="https://doi.org/10.1121/1.4810760">https://doi.org/10.1121/1.4810760</a>.
</div>
<div id="ref-Xiang2023Soundscape" class="csl-entry" role="listitem">
Xiang, Yi, Qi Meng, Xueyong Zhang, Mengmeng Li, Da Yang, and Yue Wu. 2023. <span>“<span class="nocase">Soundscape diversity: Evaluation indices of the sound environment in urban green spaces–Effectiveness, role, and interpretation</span>.”</span> <em>Ecological Indicators</em> 154: 110725.
</div>
<div id="ref-Xu2023frequency" class="csl-entry" role="listitem">
Xu, Zhi-yong, Lei Chen, Bryan C. Pijanowski, and Zhao Zhao. 2023. <span>“A Frequency-Dependent Acoustic Diversity Index: A Revision to a Classic Acoustic Index for Soundscape Ecological Research.”</span> <em>Ecological Indicators</em> 155 (November): 110940. <a href="https://doi.org/10.1016/j.ecolind.2023.110940">https://doi.org/10.1016/j.ecolind.2023.110940</a>.
</div>
<div id="ref-Yang2022Effects" class="csl-entry" role="listitem">
Yang, Da, Xinhao Cao, and Qi Meng. 2022. <span>“Effects of a Human Sound-Based Index on the Soundscapes of Urban Open Spaces.”</span> <em>Science of The Total Environment</em> 802 (January): 149869. <a href="https://doi.org/10.1016/j.scitotenv.2021.149869">https://doi.org/10.1016/j.scitotenv.2021.149869</a>.
</div>
<div id="ref-Zwicker2007Psychoacoustics" class="csl-entry" role="listitem">
Zwicker, Eberhard, and Hugo Fastl. 2007. <em><span class="nocase">Psychoacoustics: facts and models</span></em>. Third ed. Berlin ; New York: Springer. <a href="https://doi.org/10.1007/978-3-540-68888-4">https://doi.org/10.1007/978-3-540-68888-4</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>It is important to note that the parameters which appear in the density expression (<span class="math inline">\xi, \Omega, \alpha</span>) are what are called ‘direct parameters’ (DP). They directly parameterise an MSN density and are typically only estimated by fitting an MSN to a sample. The more familiar and interpretable components (mean, standard deviation, and skewness) are termed the centred parameters (CP). It is possible to move from one parameterization to another, however “while any choice of the DP components is admissible, the same is not true for CP”; i.e.&nbsp;we can always move DP <span class="math inline">\rightarrow</span> CP but not always CP <span class="math inline">\rightarrow</span> DP. In this context, it is most important for readers not to confuse the location parameter <span class="math inline">\xi</span> with the sample mean <span class="math inline">\mu</span>. A more complete explanation of these parameterizations can be found in <span class="citation" data-cites="Azzalini2016How">Adelchi Azzalini (<a href="#ref-Azzalini2016How" role="doc-biblioref">2016</a>)</span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Further technical details of the multi-objective optimisation procedure and the relevant code can be found in the Supplementary Material.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>For instance, the SSID Protocol, which produced the data used in this paper, attempted to address this by considering its spatial bounds for what constitutes one location to be “an ‘environmental unit’ wherein the environmental factors are consistent and is typically perceived to constitute a single distinct area”, noting that “the exact dimensions and delineation of the environmental unit will vary depending on the characteristics of the space” <span class="citation" data-cites="Mitchell2020Soundscape">(<a href="#ref-Mitchell2020Soundscape" role="doc-biblioref">Mitchell et al. 2020</a>)</span><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>See <a href="https://cordis.europa.eu/project/id/740696/factsheet" class="uri">https://cordis.europa.eu/project/id/740696/factsheet</a> (Last viewed 2024-05-28).<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>See <a href="https://doi.org/10.5281/zenodo.10672568" class="uri">https://doi.org/10.5281/zenodo.10672568</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>See <a href="https://github.com/MitchellAcoustics/J2401_JASA_SSID-Single-Index" class="uri">https://github.com/MitchellAcoustics/J2401_JASA_SSID-Single-Index</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{mitchell2024,
  author = {Mitchell, Andrew and Aletta, Francesco and Oberman, Tin and
    Kang, Jian},
  title = {Soundscape {Perception} {Indices} {(SPI):} {Developing}
    Context-Dependent Single Value Scores of Multidimensional Soundscape
    Perceptual Quality},
  journal = {Journal of the Acoustical Society of America},
  date = {2024-10-28},
  url = {https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/},
  langid = {en},
  abstract = {The soundscape approach provides a basis for considering
    the holistic perception of sound environments, in context. While
    steady advancements have been made in methods for assessment and
    analysis, a gap exists for comparing soundscapes and quantifying
    improvements in the multi-dimensional perception of a soundscape. To
    this end, there is a need for the creation of single value indices
    to compare soundscape quality which incorporate context, aural
    diversity, and specific design goals for a given application. Just
    as a variety of decibel-based indices have been developed for
    various purposes (e.g. \$L\_\{Aeq\}\$, \$L\_\{Ceq\}\$,
    \$L\_\{90\}\$, \$L\_\{den\}\$, etc.), the soundscape approach
    requires the ability to create novel indices for different uses,
    which share a common language and understanding. We therefore
    propose a unified framework for creating bespoke and reference
    single index measures of soundscape perception, allowing for new
    metrics to be defined in the future. This framework is based on a
    four-step test-target paradigm wherein a desired soundscape
    perception is defined as a target distribution within the soundscape
    circumplex and the 2D Kolmogorov-Smirnov distance is used to test an
    assessed soundscape against this target. Applications and
    implications of this framework are discussed and a multi-objective
    optimisation method for empirically defining perception indices is
    proposed.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-mitchell2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Mitchell, Andrew, Francesco Aletta, Tin Oberman, and Jian Kang. 2024.
<span>“Soundscape Perception Indices (SPI): Developing Context-Dependent
Single Value Scores of Multidimensional Soundscape Perceptual Quality
.”</span> <em>Journal of the Acoustical Society of America</em>,
October. <a href="https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/">https://drandrewmitchell.com/research/papers/2024-10-30_JASA1112_SPI/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/drandrewmitchell\.com\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>